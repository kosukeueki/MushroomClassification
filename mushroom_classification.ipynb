{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisikan nama kolom dataframe\n",
    "name_list=['Class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "           'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring',\n",
    "           'stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type',\n",
    "           'veil-color','ring-number','ring-type','spore-print-color','population','habitat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "train=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",names=name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                       0\n",
       "cap-shape                   0\n",
       "cap-surface                 0\n",
       "cap-color                   0\n",
       "bruises                     0\n",
       "odor                        0\n",
       "gill-attachment             0\n",
       "gill-spacing                0\n",
       "gill-size                   0\n",
       "gill-color                  0\n",
       "stalk-shape                 0\n",
       "stalk-root                  0\n",
       "stalk-surface-above-ring    0\n",
       "stalk-surface-below-ring    0\n",
       "stalk-color-above-ring      0\n",
       "stalk-color-below-ring      0\n",
       "veil-type                   0\n",
       "veil-color                  0\n",
       "ring-number                 0\n",
       "ring-type                   0\n",
       "spore-print-color           0\n",
       "population                  0\n",
       "habitat                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cek missing value\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Class'].value_counts().sort_index().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "for col in train.columns:\n",
    "    train[col] = labelencoder.fit_transform(train[col])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  ...  stalk-surface-below-ring  \\\n",
       "0             0          1           4  ...                         2   \n",
       "1             0          0           4  ...                         2   \n",
       "2             0          0           5  ...                         2   \n",
       "3             0          1           5  ...                         2   \n",
       "4             1          0           4  ...                         2   \n",
       "\n",
       "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
       "0                       7                       7          0           2   \n",
       "1                       7                       7          0           2   \n",
       "2                       7                       7          0           2   \n",
       "3                       7                       7          0           2   \n",
       "4                       7                       7          0           2   \n",
       "\n",
       "   ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0            1          4                  2           3        5  \n",
       "1            1          4                  3           2        1  \n",
       "2            1          4                  3           2        3  \n",
       "3            1          4                  2           3        5  \n",
       "4            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x='Class', y='stalk-color-above-ring', \n",
    "                data=train)\n",
    "ax = sns.stripplot(x=\"Class\", y='stalk-color-above-ring',\n",
    "                   data=train, jitter=True,\n",
    "                   edgecolor=\"gray\")\n",
    "plt.title(\"Class w.r.t stalkcolor above ring\",fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0          5            2          4        1     6                1   \n",
       "1          5            2          9        1     0                1   \n",
       "2          0            2          8        1     3                1   \n",
       "3          5            3          8        1     6                1   \n",
       "4          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "0             0          1           4            0  ...   \n",
       "1             0          0           4            0  ...   \n",
       "2             0          0           5            0  ...   \n",
       "3             0          1           5            0  ...   \n",
       "4             1          0           4            1  ...   \n",
       "\n",
       "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
       "0                         2                       7                       7   \n",
       "1                         2                       7                       7   \n",
       "2                         2                       7                       7   \n",
       "3                         2                       7                       7   \n",
       "4                         2                       7                       7   \n",
       "\n",
       "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
       "0          0           2            1          4                  2   \n",
       "1          0           2            1          4                  3   \n",
       "2          0           2            1          4                  3   \n",
       "3          0           2            1          4                  2   \n",
       "4          0           2            1          0                  3   \n",
       "\n",
       "   population  habitat  \n",
       "0           3        5  \n",
       "1           2        1  \n",
       "2           2        3  \n",
       "3           3        5  \n",
       "4           0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=train.drop(\"Class\",axis=1)\n",
    "outcomes=train[\"Class\"].values\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dan definisikan train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, outcomes, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest        100.00 (+/-) 0.00 \n"
     ]
    }
   ],
   "source": [
    "#buat model dengan algoritma random forest\n",
    "model=RandomForestClassifier(n_estimators=5)\n",
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "cv_result = cross_val_score(model,X_train,Y_train, cv = kfold,scoring = \"accuracy\")\n",
    "results=[\"Random Forest\",cv_result.mean(),cv_result.std()]\n",
    "\n",
    "print('{:20s} {:2.2f} (+/-) {:2.2f} '.format(results[0] , results[1] * 100, results[2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [  15  944]]\n",
      "99.26144756277697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1072\n",
      "           1       1.00      0.98      0.99       959\n",
      "\n",
      "    accuracy                           0.99      2031\n",
      "   macro avg       0.99      0.99      0.99      2031\n",
      "weighted avg       0.99      0.99      0.99      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#buatmodel random forest\n",
    "final_model = RandomForestClassifier(n_estimators=100,max_features='auto',bootstrap=True,oob_score=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1046   26]\n",
      " [   8  951]]\n",
      "98.3259478089611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1072\n",
      "           1       0.97      0.99      0.98       959\n",
      "\n",
      "    accuracy                           0.98      2031\n",
      "   macro avg       0.98      0.98      0.98      2031\n",
      "weighted avg       0.98      0.98      0.98      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#final model random forest classifier\n",
    "final_model = RandomForestClassifier(n_estimators=1,max_features=None,bootstrap=False,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1068    4]\n",
      " [   8  951]]\n",
      "99.40915805022156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1072\n",
      "           1       1.00      0.99      0.99       959\n",
      "\n",
      "    accuracy                           0.99      2031\n",
      "   macro avg       0.99      0.99      0.99      2031\n",
      "weighted avg       0.99      0.99      0.99      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100,max_features=None,bootstrap=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1072\n",
      "           1       1.00      1.00      1.00       959\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=5,subsample=0.632,colsample_bytree=0.375)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1046   26]\n",
      " [   8  951]]\n",
      "98.3259478089611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1072\n",
      "           1       0.97      0.99      0.98       959\n",
      "\n",
      "    accuracy                           0.98      2031\n",
      "   macro avg       0.98      0.98      0.98      2031\n",
      "weighted avg       0.98      0.98      0.98      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#buat model dengan XGB Classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=1,num_boost_round=1,max_depth=5,subsample=1,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1072\n",
      "           1       1.00      1.00      1.00       959\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=2,subsample=0.632,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/brgx21guns/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras import optimizers\n",
    "history=History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 23:07:35.295517 140680406255424 deprecation_wrapper.py:119] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 23:07:35.351344 140680406255424 deprecation_wrapper.py:119] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 23:07:35.356802 140680406255424 deprecation_wrapper.py:119] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0804 23:07:35.417606 140680406255424 deprecation_wrapper.py:119] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0804 23:07:35.447552 140680406255424 deprecation.py:506] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 23:07:36.172272 140680406255424 deprecation_wrapper.py:119] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 23:07:36.194258 140680406255424 deprecation_wrapper.py:119] From /home/brgx21guns/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(128, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(128, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(len(np.unique(Y_train)), activation='softmax'))\n",
    "    \n",
    "m.compile(\n",
    "    optimizer=optimizers.adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "W0804 23:07:36.651624 140680406255424 deprecation.py:323] From /home/brgx21guns/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5483 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 0.7749 - acc: 0.5194 - val_loss: 0.6729 - val_acc: 0.5016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67293, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7057 - acc: 0.5568 - val_loss: 0.6090 - val_acc: 0.8049\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67293 to 0.60895, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6186 - acc: 0.6595 - val_loss: 0.4987 - val_acc: 0.8131\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60895 to 0.49870, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.5128 - acc: 0.7673 - val_loss: 0.4109 - val_acc: 0.8459\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49870 to 0.41089, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.4333 - acc: 0.8171 - val_loss: 0.3635 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41089 to 0.36355, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4071 - acc: 0.8377 - val_loss: 0.3261 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36355 to 0.32607, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.3738 - acc: 0.8523 - val_loss: 0.2977 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32607 to 0.29773, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3522 - acc: 0.8601 - val_loss: 0.2737 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.29773 to 0.27365, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3265 - acc: 0.8774 - val_loss: 0.2560 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.27365 to 0.25600, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3075 - acc: 0.8818 - val_loss: 0.2445 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.25600 to 0.24446, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.2903 - acc: 0.8918 - val_loss: 0.2302 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.24446 to 0.23024, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.2816 - acc: 0.8957 - val_loss: 0.2238 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.23024 to 0.22383, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.2771 - acc: 0.8986 - val_loss: 0.2156 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.22383 to 0.21562, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.2689 - acc: 0.9021 - val_loss: 0.2100 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.21562 to 0.21004, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.2582 - acc: 0.9042 - val_loss: 0.2031 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.21004 to 0.20305, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2518 - acc: 0.9068 - val_loss: 0.1975 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.20305 to 0.19754, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2496 - acc: 0.9121 - val_loss: 0.1924 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.19754 to 0.19244, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2357 - acc: 0.9176 - val_loss: 0.1890 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.19244 to 0.18898, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2349 - acc: 0.9125 - val_loss: 0.1846 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.18898 to 0.18460, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2301 - acc: 0.9185 - val_loss: 0.1795 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.18460 to 0.17952, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2238 - acc: 0.9179 - val_loss: 0.1742 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17952 to 0.17424, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2182 - acc: 0.9183 - val_loss: 0.1704 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.17424 to 0.17041, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2071 - acc: 0.9234 - val_loss: 0.1642 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.17041 to 0.16415, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2043 - acc: 0.9212 - val_loss: 0.1592 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.16415 to 0.15925, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.1956 - acc: 0.9241 - val_loss: 0.1531 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15925 to 0.15307, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.1968 - acc: 0.9245 - val_loss: 0.1473 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.15307 to 0.14728, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.1904 - acc: 0.9300 - val_loss: 0.1423 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.14728 to 0.14235, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.1800 - acc: 0.9307 - val_loss: 0.1347 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14235 to 0.13471, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.1778 - acc: 0.9327 - val_loss: 0.1312 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13471 to 0.13119, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.1682 - acc: 0.9331 - val_loss: 0.1234 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13119 to 0.12336, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1712 - acc: 0.9365 - val_loss: 0.1166 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12336 to 0.11663, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.1582 - acc: 0.9400 - val_loss: 0.1114 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11663 to 0.11143, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.1552 - acc: 0.9387 - val_loss: 0.1055 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.11143 to 0.10548, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1492 - acc: 0.9400 - val_loss: 0.0990 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.10548 to 0.09905, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.1431 - acc: 0.9446 - val_loss: 0.0964 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.09905 to 0.09643, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9457 - val_loss: 0.0896 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09643 to 0.08957, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.1267 - acc: 0.9491 - val_loss: 0.0859 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08957 to 0.08594, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9497 - val_loss: 0.0864 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08594\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1226 - acc: 0.9535 - val_loss: 0.0816 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.08594 to 0.08160, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1091 - acc: 0.9581 - val_loss: 0.0757 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08160 to 0.07566, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1210 - acc: 0.9537 - val_loss: 0.0669 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.07566 to 0.06693, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1217 - acc: 0.9520 - val_loss: 0.0653 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.06693 to 0.06529, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9584 - val_loss: 0.0617 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.06529 to 0.06174, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9632 - val_loss: 0.0603 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.06174 to 0.06034, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9639 - val_loss: 0.0604 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06034\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9624 - val_loss: 0.0504 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.06034 to 0.05041, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9653 - val_loss: 0.0498 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05041 to 0.04981, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0852 - acc: 0.9661 - val_loss: 0.0495 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.04981 to 0.04949, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0924 - acc: 0.9664 - val_loss: 0.0479 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04949 to 0.04794, saving model to best.model\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0862 - acc: 0.9677 - val_loss: 0.0468 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04794 to 0.04684, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9686 - val_loss: 0.0392 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04684 to 0.03924, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0822 - acc: 0.9695 - val_loss: 0.0358 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.03924 to 0.03576, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9688 - val_loss: 0.0392 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03576\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0779 - acc: 0.9706 - val_loss: 0.0330 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03576 to 0.03303, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9710 - val_loss: 0.0339 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.03303\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9717 - val_loss: 0.0338 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.03303\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0705 - acc: 0.9743 - val_loss: 0.0370 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03303\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0767 - acc: 0.9730 - val_loss: 0.0292 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.03303 to 0.02918, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9714 - val_loss: 0.0276 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02918 to 0.02756, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0618 - acc: 0.9763 - val_loss: 0.0281 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02756\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0642 - acc: 0.9745 - val_loss: 0.0236 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02756 to 0.02355, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9745 - val_loss: 0.0239 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02355\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0550 - acc: 0.9799 - val_loss: 0.0236 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02355\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9776 - val_loss: 0.0227 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.02355 to 0.02270, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0559 - acc: 0.9779 - val_loss: 0.0215 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.02270 to 0.02146, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9767 - val_loss: 0.0207 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.02146 to 0.02074, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9801 - val_loss: 0.0233 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02074\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0562 - acc: 0.9783 - val_loss: 0.0228 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02074\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9774 - val_loss: 0.0180 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.02074 to 0.01803, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9799 - val_loss: 0.0188 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.01803\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9781 - val_loss: 0.0175 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.01803 to 0.01745, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9798 - val_loss: 0.0162 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.01745 to 0.01621, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9838 - val_loss: 0.0197 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.01621\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0499 - acc: 0.9803 - val_loss: 0.0178 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.01621\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9845 - val_loss: 0.0158 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.01621 to 0.01580, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9805 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.01580 to 0.01423, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9790 - val_loss: 0.0141 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.01423 to 0.01412, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9819 - val_loss: 0.0143 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.01412\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9836 - val_loss: 0.0144 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.01412\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9825 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.01412 to 0.01263, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9818 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.01263\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9827 - val_loss: 0.0118 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.01263 to 0.01177, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9832 - val_loss: 0.0114 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.01177 to 0.01142, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9843 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.01142\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9841 - val_loss: 0.0107 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.01142 to 0.01071, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0388 - acc: 0.9852 - val_loss: 0.0137 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.01071\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0388 - acc: 0.9856 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.01071 to 0.01067, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9850 - val_loss: 0.0100 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.01067 to 0.01002, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9849 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.01002\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0359 - acc: 0.9849 - val_loss: 0.0090 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.01002 to 0.00899, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9854 - val_loss: 0.0093 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00899\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9854 - val_loss: 0.0082 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00899 to 0.00824, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9863 - val_loss: 0.0086 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00824\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0326 - acc: 0.9876 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00824\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0307 - acc: 0.9891 - val_loss: 0.0083 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00824\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9867 - val_loss: 0.0080 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00824 to 0.00797, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9863 - val_loss: 0.0117 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00797\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9861 - val_loss: 0.0072 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00797 to 0.00717, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0305 - acc: 0.9883 - val_loss: 0.0074 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00717\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0087 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00717\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9891 - val_loss: 0.0081 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00717\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9876 - val_loss: 0.0085 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00717\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0312 - acc: 0.9885 - val_loss: 0.0075 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00717\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0328 - acc: 0.9883 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00717 to 0.00638, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0289 - acc: 0.9896 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00638\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0264 - acc: 0.9894 - val_loss: 0.0067 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00638\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0274 - acc: 0.9900 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00638 to 0.00627, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9869 - val_loss: 0.0067 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00627\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0288 - acc: 0.9891 - val_loss: 0.0076 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00627\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9889 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00627 to 0.00577, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9885 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00577 to 0.00563, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0261 - acc: 0.9903 - val_loss: 0.0066 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00563\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0269 - acc: 0.9889 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00563 to 0.00544, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9898 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00544\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9889 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00544\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9909 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00544 to 0.00524, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0298 - acc: 0.9869 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00524 to 0.00489, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9911 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00489 to 0.00476, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0266 - acc: 0.9892 - val_loss: 0.0075 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00476\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00476\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9900 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00476\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00476\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9887 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00476\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00476\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0215 - acc: 0.9922 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00476\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0251 - acc: 0.9929 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00476 to 0.00439, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9902 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00439\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9940 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00439 to 0.00418, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9892 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00418\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9903 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00418\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9912 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00418\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9922 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00418 to 0.00407, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9905 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00407 to 0.00387, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9905 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00387 to 0.00376, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9914 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00376\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00376\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9920 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00376 to 0.00374, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0208 - acc: 0.9933 - val_loss: 0.0044 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00374\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9912 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00374 to 0.00361, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0211 - acc: 0.9927 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00361 to 0.00344, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9923 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00344\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9923 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00344 to 0.00344, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00344\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0186 - acc: 0.9925 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00344 to 0.00312, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0182 - acc: 0.9938 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00312 to 0.00303, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9922 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00303 to 0.00290, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0248 - acc: 0.9889 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00290\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9927 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00290\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9923 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00290\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0183 - acc: 0.9923 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00290\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0165 - acc: 0.9936 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00290\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9925 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00290\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00290\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9933 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00290 to 0.00285, saving model to best.model\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0191 - acc: 0.9936 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00285 to 0.00273, saving model to best.model\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9934 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00273 to 0.00247, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9933 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00247\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0026 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00247\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0147 - acc: 0.9940 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00247\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0176 - acc: 0.9934 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00247 to 0.00236, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00236\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0200 - acc: 0.9927 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00236\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0146 - acc: 0.9942 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00236\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9947 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00236 to 0.00220, saving model to best.model\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9936 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00220 to 0.00219, saving model to best.model\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9936 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00219\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9951 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00219 to 0.00194, saving model to best.model\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9949 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00194\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00194\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0159 - acc: 0.9936 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00194\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9938 - val_loss: 0.0039 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00194\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0141 - acc: 0.9938 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00194\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9929 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00194\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00194\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9940 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00194\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9947 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00194\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9936 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00194\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9942 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00194\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9942 - val_loss: 0.0036 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00194\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9945 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00194\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00194\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9943 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00194\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00194\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00194\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0124 - acc: 0.9945 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00194 to 0.00187, saving model to best.model\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9953 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00187\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00187 to 0.00171, saving model to best.model\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9949 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00171\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9940 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00171\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9956 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00171\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9956 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00171 to 0.00169, saving model to best.model\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9956 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00169 to 0.00142, saving model to best.model\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00142\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9943 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00142\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0134 - acc: 0.9949 - val_loss: 0.0029 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00142\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00142 to 0.00137, saving model to best.model\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00137\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9951 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00137\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00137\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9964 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00137\n"
     ]
    }
   ],
   "source": [
    "hist=m.fit(\n",
    "    # lakukan training pada dataset\n",
    "    X_train.values, \n",
    "    # target class one hot encoding\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        history,\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9bn48c8zM0kme0ISAoQlAUFARIGA+9IqCmpxraLVqq2ivdfWbl61tdZ6f12svV5vW+tuq9VqXdBSxbXuBZSwyL6EPQGSELLvk3l+f5whDDGEBDIzSeZ5v155Zeac75l5cpKcZ77L+X5FVTHGGBO9XJEOwBhjTGRZIjDGmChnicAYY6KcJQJjjIlylgiMMSbKWSIwxpgoZ4nAmC4Skb+IyP/rYtmtInL2kb6OMeFgicAYY6KcJQJjjIlylghMvxJokrlNRFaISJ2IPCki2SLypojUiMh7IpIeVH6WiKwWkUoR+VBExgXtmyQiSwPH/R3wtnuvC0RkeeDYBSIy8TBjvlFECkVkr4jME5Ehge0iIv8rIqUiUi0iK0VkQmDfeSKyJhBbsYj8+LBOmDFYIjD906XAdGAM8DXgTeAnQBbO3/z3AERkDPA88P3AvvnAP0UkVkRigdeAvwIDgJcCr0vg2EnAU8BNQAbwKDBPROK6E6iIfBX4NXA5MBjYBrwQ2H0OcHrg50gNlCkP7HsSuElVk4EJwPvdeV9jglkiMP3RH1S1RFWLgU+Az1R1mao2Aq8CkwLlrgDeUNV3VbUF+B0QD5wMnAjEAA+qaouqvgwsDnqPOcCjqvqZqraq6tNAU+C47vgG8JSqLlXVJuBO4CQRyQVagGRgLCCqulZVdwWOawHGi0iKqlao6tJuvq8xbSwRmP6oJOhxQwfPkwKPh+B8AgdAVf3ADiAnsK9YD5yVcVvQ4xHAjwLNQpUiUgkMCxzXHe1jqMX51J+jqu8DfwQeAkpF5DERSQkUvRQ4D9gmIh+JyEndfF9j2lgiMNFsJ84FHXDa5HEu5sXALiAnsG2f4UGPdwC/VNW0oK8EVX3+CGNIxGlqKgZQ1d+r6hRgPE4T0W2B7YtV9UJgIE4T1ovdfF9j2lgiMNHsReB8ETlLRGKAH+E07ywAFgI+4HsiEiMilwDTgo59HLhZRE4IdOomisj5IpLczRieB64XkeMD/Qu/wmnK2ioiUwOvHwPUAY2AP9CH8Q0RSQ00aVUD/iM4DybKWSIwUUtV1wNXA38A9uB0LH9NVZtVtRm4BLgO2IvTnzA36NgC4EacppsKoDBQtrsxvAf8DHgFpxYyCpgd2J2Ck3AqcJqPyoH7A/uuAbaKSDVwM05fgzGHRWxhGmOMiW5WIzDGmChnicAYY6KcJQJjjIlylgiMMSbKeSIdQHdlZmZqbm5upMMwxpg+ZcmSJXtUNaujfSFNBCIyA/g/wA08oaq/abd/OPA0kBYoc4eqzu/sNXNzcykoKAhRxMYY0z+JyLaD7QtZ05CIuHFujZ+Jc1fklSIyvl2xu4AXVXUSztjpP4UqHmOMMR0LZR/BNKBQVTcHbs55AbiwXRnFuWkGnNkVd4YwHmOMMR0IZSLIwZmPZZ+iwLZg9wBXi0gRzhTA3+3ohURkjogUiEhBWVlZKGI1xpioFenO4iuBv6jq/wRmT/yriEwIzALZRlUfAx4DyM/P/9Kt0C0tLRQVFdHY2BiWoCPF6/UydOhQYmJiIh2KMaYfCWUiKMaZyXGfoYFtwb4NzABQ1YUi4gUygdLuvFFRURHJycnk5uZy4GSR/YeqUl5eTlFREXl5eZEOxxjTj4SyaWgxMFpE8gKrPc0G5rUrsx04CyCwRKAX6HbbT2NjIxkZGf02CQCICBkZGf2+1mOMCb+QJQJV9QG3AG8Da3FGB60WkXtFZFag2I+AG0XkC5zpeK/Tw5wFrz8ngX2i4Wc0xoRfSPsIAvcEzG+37e6gx2uAU0IZwz51TT5qGlvITvHaBdUYY4JEzRQT9c2tlNY00erv+Wm3Kysr+dOfun8LxHnnnUdlZWWPx2OMMd0RNYnA43ZqAb4wJgKfz9fpcfPnzyctLa3H4zHGmO6I9PDRsPG4nEQQihrBHXfcwaZNmzj++OOJiYnB6/WSnp7OunXr2LBhAxdddBE7duygsbGRW2+9lTlz5gD7p8uora1l5syZnHrqqSxYsICcnBz+8Y9/EB8f3+OxGmNMe/0uEfzin6tZs7P6S9v9qjQ0t+KNceN2da+PYPyQFH7+tWMOuv83v/kNq1atYvny5Xz44Yecf/75rFq1qm2Y51NPPcWAAQNoaGhg6tSpXHrppWRkZBzwGhs3buT555/n8ccf5/LLL+eVV17h6quv7lacxhhzOPpdIjiYfR3EzqCk0HYWT5s27YCx/r///e959dVXAdixYwcbN278UiLIy8vj+OOPB2DKlCls3bo1pDEaY8w+/S4RHOyTu6qysriK7BQv2SnekMaQmJjY9vjDDz/kvffeY+HChSQkJHDmmWd2eC9AXFxc22O3201DQ0NIYzTGmH2iprNYRPC4BF+r/9CFuyk5OZmampoO91VVVZGenk5CQgLr1q1j0aJFPf7+xhhzJPpdjaAzbpcrJKOGMjIyOOWUU5gwYQLx8fFkZ2e37ZsxYwaPPPII48aN4+ijj+bEE0/s8fc3xpgjIYd5I2/E5Ofna/uFadauXcu4ceMOeeymslpQGDUwKVThhVxXf1ZjjAkmIktUNb+jfVHTNATOENJQ1AiMMaYvi65E4Hbh8/d8H4ExxvRl0ZUIXEKrX/H3seYwY4wJpahLBBCau4uNMaaviq5E4HZ+3FAMITXGmL4quhKBK3QTzxljTF8VnYmgtWcTweFOQw3w4IMPUl9f36PxGGNMd4Q0EYjIDBFZLyKFInJHB/v/V0SWB742iEhIJ+cP1VTUlgiMMX1ZyO4sFhE38BAwHSgCFovIvMCqZACo6g+Cyn8XmBSqeABcIohIjw8hDZ6Gevr06QwcOJAXX3yRpqYmLr74Yn7xi19QV1fH5ZdfTlFREa2trfzsZz+jpKSEnTt38pWvfIXMzEw++OCDHo3LGGO6IpRTTEwDClV1M4CIvABcCKw5SPkrgZ8f8bu+eQfsXtnhLgFGNvucJiKPu+uvOehYmPmbg+4Onob6nXfe4eWXX+bzzz9HVZk1axYff/wxZWVlDBkyhDfeeANw5iBKTU3lgQce4IMPPiAzM7M7P6UxxvSYUDYN5QA7gp4XBbZ9iYiMAPKA9w+yf46IFIhIQVlZ2REFJQKh7Cp+5513eOedd5g0aRKTJ09m3bp1bNy4kWOPPZZ3332X22+/nU8++YTU1NQQRmGMMV3XWyadmw28rKqtHe1U1ceAx8CZa6jTV+rkkzvArtJaEBiVFZr5hlSVO++8k5tuuulL+5YuXcr8+fO56667OOuss7j77rtDEoMxxnRHKGsExcCwoOdDA9s6Mht4PoSxtHEH7i7uScHTUJ977rk89dRT1NbWAlBcXExpaSk7d+4kISGBq6++mttuu42lS5d+6VhjjImEUNYIFgOjRSQPJwHMBq5qX0hExgLpwMIQxtLG7RJaW3o2EQRPQz1z5kyuuuoqTjrpJACSkpJ49tlnKSws5LbbbsPlchETE8PDDz8MwJw5c5gxYwZDhgyxzmJjTESEdBpqETkPeBBwA0+p6i9F5F6gQFXnBcrcA3hV9UvDSztyJNNQA+ysbGBvXTMTcvpmG71NQ22MORydTUMd0j4CVZ0PzG+37e52z+8JZQzteVyCX52J51wS2rWLjTGmL4ieO4ub66G2BLdNPGeMMQfoN4ngkE1czbVQvROPODeT9cVE0NdWkzPG9A39IhF4vV7Ky8s7v1C6nFYwD84I1b6WCFSV8vJyvF5vpEMxxvQzveU+giMydOhQioqK6PRmM18j1JbSEq+U1EPr3li8Md24u7gX8Hq9DB06NNJhGGP6mX6RCGJiYsjLy+u8UOk6eOVyys59mFnzUvmfrx/HpRPtomqMMf2iaahLkgY631r2AlDZ0BLJaIwxpteInkQQnw6uGLxNexCBKksExhgDRFMiEIGkbKSulBRvDFX1zZGOyBhjeoXoSQTgNA/VlpCWEGNNQ8YYExBliSAbaktIjY+xpiFjjAmIskQwEGpLSY2PobLeEoExxkDUJYJsqCsjzeuyGoExxgREWSIYCOpnSGy9JQJjjAmIskSQDcAQdzVVDS02d48xxhB1icC5qWygVNHqV2qbfBEOyBhjIi8qE8EAKgG7qcwYYyDaEkGikwjSWp1pJqxGYIwxIU4EIjJDRNaLSKGIdLgUpYhcLiJrRGS1iPwtlPEQlwQxiST5ygGoabREYIwxIZt9VETcwEPAdKAIWCwi81R1TVCZ0cCdwCmqWiEiA0MVT5v4NLytdQDUWiIwxpiQ1gimAYWqullVm4EXgAvblbkReEhVKwBUtTSE8TjikokLJILqRusjMMaYUCaCHGBH0POiwLZgY4AxIvJvEVkkIjM6eiERmSMiBSJS0OniM10Rl0zMvhqB9REYY0zEO4s9wGjgTOBK4HERSWtfSFUfU9V8Vc3Pyso6sneMS8bTUgtYH4ExxkBoE0ExMCzo+dDAtmBFwDxVbVHVLcAGnMQQOnHJuJprcbvE+giMMYbQJoLFwGgRyRORWGA2MK9dmddwagOISCZOU9HmEMYEcclIUw1JcR5qrI/AGGNClwhU1QfcArwNrAVeVNXVInKviMwKFHsbKBeRNcAHwG2qWh6qmACIS4HmWicRWB+BMcaEdvF6VZ0PzG+37e6gxwr8MPAVHnHJ0FRDSqrL+giMMYbIdxaHX2wSoGTG+ayPwBhjiMZEEJcMQFZsiw0fNcYYojgRZHiarLPYGGOIykSQAsAAT6PVCIwxhqhMBE6NIM3TSLX1ERhjTBQnAmmk2eenydca4YCMMSayojYRpLgaAZuB1BhjojYRJNEA2MRzxhgTtYkgkXrAJp4zxpjoSwTuGPB4iVenRmCJwBgT7aIvEQDEJRPv31cjsHsJjDHRLWoTQawtTmOMMYAlAmsaMsZEvShNBCltq5RZjcAYE+2iNBE4q5TFemwqamOMidpEQFM1ybZKmTHGhDYRiMgMEVkvIoUickcH+68TkTIRWR74uiGU8bTZtzhNfIzNN2SMiXohW6FMRNzAQ8B0nEXqF4vIPFVd067o31X1llDF0aHYJGiqIS3DQ2V9c1jf2hhjeptQ1gimAYWqullVm4EXgAtD+H5dF5cM/hay4oW9dZYIjDHRLZSJIAfYEfS8KLCtvUtFZIWIvCwiw0IYz36BNQkGeZuorLc+AmNMdIt0Z/E/gVxVnQi8CzzdUSERmSMiBSJSUFZWduTv6k0FYFBsMxXWNGSMiXKhTATFQPAn/KGBbW1UtVxVmwJPnwCmdPRCqvqYquaran5WVtaRRxafDsDAmAbqm1tpbLE1CYwx0SuUiWAxMFpE8kQkFpgNzAsuICKDg57OAtaGMJ794tMAyHA7dxdb85AxJpqFbNSQqvpE5BbgbcANPKWqq0XkXqBAVecB3xORWYAP2AtcF6p4DhCoEaRLPZBORX0zg1K9YXlrY4zpbUKWCABUdT4wv922u4Me3wncGcoYOuR1agSpODUC6ycwxkSzSHcWR0agaSiJGgAq6qxpyBgTvaIzEbhjIDaJhNZAIrAagTEmikVnIgCIT8frcxKB3V1sjIlm0ZsIvGm4GytJjHWz15qGjDFRLHoTQXwaNFaSlhBrNQJjTFSL7kTQUEF6Yoz1ERhjoloUJ4J0aKgkPSGWvXZDmTEmikVvIvAGagTWNGSMiXLRmwji06G1iSyvnwqbitoYE8WiOBE4N5UNim2kutGHr9Uf4YCMMSYyojgRBGYg9dQDUNlg/QTGmOgUvYkgMN9QpqcBgJLqxkhGY4wxERO9iSBQIzgq2akJfLGjKpLRGGNMxERxInBqBANjGshIjGXJtooIB2SMMZERvYkg0DQkDZVMHpHOkm17IxyQMcZERvQmgrgUEBc0VpI/Ip2t5fXsqW069HHGGNPPRG8icLmcRewbKpgywukvWGrNQ8aYKNSlRCAit4pIijieFJGlInJOF46bISLrRaRQRO7opNylIqIikt+d4I9YQibUlTEhJ5VYt8v6CYwxUamrNYJvqWo1cA6QDlwD/KazA0TEDTwEzATGA1eKyPgOyiUDtwKfdSPunpE2HCq3441xM35ICst3VIY9BGOMibSuJgIJfD8P+Kuqrg7adjDTgEJV3ayqzcALwIUdlPtv4D4g/AP5A4kAYNzgFNaX1KCqYQ/DGGMiqauJYImIvIOTCN4OfIo/1JwMOcCOoOdFgW1tRGQyMExV3+jshURkjogUiEhBWVlZF0PugrThUF8OTbWMG5xMZX0LJdXWYWyMiS5dTQTfBu4ApqpqPRADXH8kbywiLuAB4EeHKquqj6lqvqrmZ2VlHcnbHih9hPO9cjtjB6UAsHZ3dc+9vjHG9AFdTQQnAetVtVJErgbuAg51K24xMCzo+dDAtn2SgQnAhyKyFTgRmBfWDuO0/Yng6EHJAKzdZYnAGBNdupoIHgbqReQ4nE/wm4BnDnHMYmC0iOSJSCwwG5i3b6eqVqlqpqrmqmousAiYpaoF3f0hDlvacOd75XZS42PISYtn3a6asL29Mcb0Bl1NBD51elEvBP6oqg/hfKI/KFX1AbcAbwNrgRdVdbWI3Csis44k6B6TmAWeeKjcBsDYQcmss6YhY0yU8XSxXI2I3IkzbPS0QPt+zKEOUtX5wPx22+4+SNkzuxhLzxEJjBwKJILByXy4oYwmXytxHnfYwzHGmEjoao3gCqAJ536C3Tjt/feHLKpwChpCOnZQCq1+ZcPu2ggHZYwx4dOlRBC4+D8HpIrIBUCjqh6qj6BvSBsOFU6NID/XmWpiwaY9kYzIGGPCqqtTTFwOfA58Hbgc+ExELgtlYGGTPgIaK6GxisGp8YzJTuLjjT14r4IxxvRyXW0a+inOPQTXquo3ce4a/lnowgqjfUNIK7YCcMaYLBZvqaC+2Re5mIwxJoy6mghcqloa9Ly8G8f2bpljnO9lGwA4fUwWza1+Ptts6xMYY6JDVy/mb4nI2yJynYhcB7xBu9FAfVbGKGddgj3rAZiaOwBvjIuPNljzkDEmOnRp+Kiq3iYilwKnBDY9pqqvhi6sMPLEQXoelDmJwBvjZmruABZuKo9wYMYYEx5dvY8AVX0FeCWEsURO1tGwZ0Pb02m5A3jgvQ1U1beQmnDI2yWMMaZP67RpSERqRKS6g68aEek/t+BmjoHyTdDqdBDn5w5AFZZut4VqjDH9X6eJQFWTVTWlg69kVU0JV5AhlzkG/C1tI4eOH5aGxyUs3modxsaY/q9/jPw5UllHO98DHcbxsW6OyUmlYKvVCIwx/Z8lAoDM0c73QIcxQP6IdL4oqqTJ1xqhoIwxJjwsEQB4UyF58AGJYGpuOk0+PyuLDrXsgjHG9G2WCPbJngC7V7Q9PWlkJm6X8K91pZ0cZIwxfZ8lgn1ypkDpWmhyFqZJTYjhxJEDeGf17ggHZowxoWWJYJ+cKYDCri/aNp17zCA2ldVRWGrTUhtj+q+QJgIRmSEi60WkUETu6GD/zSKyUkSWi8inIjI+lPF0Kmey8714Sdum6eOzAXhnjdUKjDH9V8gSgYi4gYeAmcB44MoOLvR/U9VjVfV44LfAA6GK55ASM52ZSIMSweDUeI4bmsrbqywRGGP6r1DWCKYBhaq6WVWbgRdw1jxuo6rBdycnAhrCeA4tZwoULz1g03nHDuaLoiq2l9dHKChjjAmtUCaCHGBH0POiwLYDiMh/isgmnBrB90IYz6HlTIGqHVC7f6TQBccNAeCfK3ZGKipjjAmpiHcWq+pDqjoKuB24q6MyIjJHRApEpKCsLITTQw+d6nzfvqhtU05aPFNz05m33BKBMaZ/CmUiKAaGBT0fGth2MC8AF3W0Q1UfU9V8Vc3PysrqwRDbGTIJPPGw7d8HbP7acUNYX1LDmp39Z549Y4zZJ5SJYDEwWkTyRCQWmA3MCy4gIqODnp4PbAxhPIfmiYXhJ8DWTw/YfMHEISR7Pdz9j1W0+iPbjWGMMT0tZIlAVX3ALcDbwFrgRVVdLSL3isisQLFbRGS1iCwHfghcG6p4umzEqVCyGur3zzw6IDGWey88hoJtFTzy0aYIBmeMMT2vywvTHA5VnU+7JS1V9e6gx7eG8v0PS+6pgMK2BTDugrbNFx2fw3trS7n/7fWUVDfy0/PHEedxRy5OY4zpISFNBH1SzmTweJ3moaBEICI8eMXxDEn18vgnW2hpVX59ybERDNQYY3pGxEcN9TqeOBh+IhS+C3pgf0CM28VPzx/PzWeM4vnPt/O6DSk1xvQDlgg6Mv5CKC+EklUd7v7ROWM4flgaP5m7koq65jAHZ4wxPcsSQUfGzQJxw6q5He6Ocbu479KJ1Db5+L9/RXagkzHGHClLBB1JzIS802H13C81D+1z9KBkZk8bzrOLttnspMaYPs0SwcFMuMRZzL5o8UGL/ODsMSTGebjxmQLKaprCF5sxxvQgSwQHM/4iiE+Hj3570CJZyXE8dV0+u6saufzRhTyzcCuNLbbGsTGmb7FEcDDeFDjlVmf0UNDcQ+1NGTGAJ6/LJ87j4u5/rOZX89eGMUhjjDlylgg6M20OJA6ED37VabGTR2Xy1vdP57IpQ3mpoIiqhpYwBWiMMUfOEkFnYhPhpP+ALR856xkfwvWn5NLQ0spLBTsOWdYYY3oLSwSHMvla507jzx8/ZNFjhqQyLW8Aj3y0mXvmrWZFUWUYAjTGmCNjieBQEgbAhMvgixegseqQxe+cOZaByXH8ffEOLnt4IS9a7cAY08tZIuiKaTdCSx3M+y74Ox8VNGl4OvNvPY0Fd3yVqXnp/NfLK3jsY5ux1BjTe1ki6Iohx8M5v4Q1/4A3ftSlQ9ITY3n6+mmcf+xgfjV/HY/a9NXGmF7KZh/tqpNvgboy+PeDMPwkOO6KQx7icbv4v9nHIwK/fnMdCtx8xqjQx2qMMd1gNYLu+OrPYPjJ8MYPoWx9lw7xuF08eMXxfO24IfzmzXUsKNwT4iCNMaZ7LBF0h9sDlz4OMfHw5/Ng1xddOszjdnH/ZRPJSYvn12+uw2/LXRpjepGQJgIRmSEi60WkUETu6GD/D0VkjYisEJF/iciIUMbTI1KHwvVvOUNKn/4a7Ona7KPeGDc/nD6GlcVVvLTERhIZY3qPkCUCEXEDDwEzgfHAlSIyvl2xZUC+qk4EXgYOPrFPb5J5FFz/Brhj4bnLoK5rzT0XTcph4tBUbn9lJbMfW0h5rU1UZ4yJvFDWCKYBhaq6WVWbgReAC4MLqOoHqlofeLoIGBrCeHpWei7Mfh5qdsNTM5yZSg/B7RL+Puck7r5gPEu3V/KTV1eiB5nm2hhjwiWUiSAHCG4DKQpsO5hvA292tENE5ohIgYgUlJWV9WCIR2jYVLjmVWc00RPTYeeyQx4SH+vmW6fm8eNzxvD26hK+8+xSbnymgLW7qsMQsDHGfFmv6CwWkauBfOD+jvar6mOqmq+q+VlZWeEN7lBGnAzffsdZ6/jP58MXfz/oYjbBvn3qSE45KoN/F+7hs83lXPPk52zdUxeGgI0x5kChTATFwLCg50MD2w4gImcDPwVmqWrfbDTPOhq+/S4MHAevzoE/z4S9Wzo9xO0Snv32Cay45xzm/sfJ+FW54ZkCWlr9YQraGGMcoUwEi4HRIpInIrHAbGBecAERmQQ8ipMESkMYS+ilDHaSwaw/QMkaePR0WPvPTg8REUSEowYmc9+lEyksreXZRdvCFLAxxjhClghU1QfcArwNrAVeVNXVInKviMwKFLsfSAJeEpHlIjLvIC/XN7hcMPmbcPMnkDka/n4NLPhjl5qKzh43kFOPyuR/393AquIq60Q2xoSN9LULTn5+vhYUFEQ6jENraYC5c2DtPJh6A8y4z7khrRMbSmq4+KF/U9fcyhljsnjquqm4XRKmgI0x/ZmILFHV/I729YrO4n4pJh6+/jSc/D1Y/AQ8Mwv2FHZ6yJjsZD69/avcetZoPtpQxt8+20Zdk4+ymr7ZdWKM6RusRhAOy/8Gb94BrU1w5fMw6qudFldVrnnyc5bvqMTjdmoEn/zXV0j2xoQjWmNMP2Q1gkg7/iq45XPIOAqevwq2ftppcRHhvy+agNsljMlOprK+hec/3x6mYI0x0cYSQbgkD4JrXoO0YfDXi2HZc50Wz8tMZPnd03nxppM4aWQGT366hWafDS01xvQ8SwThlJQF33rbWc/gH/8Bnz7YaXERp1no5jNHUVLdxG0vf0FxZUM4IjXGRBFLBOGWMACungsTLoX3fn7IZABw+uhMbjpjJG+u3M05D3xEwda9YQjUGBMtLBFEgtsDFz/W5WQgItw5cxzv//gMslO8XPfnxSzZVhGmYI0x/Z0lgkhpnwzeuQv8rZ0eMjQ9gb/deCKZSbFc+9TnLNtuycAYc+QsEUTSvmQw9UZY8Ad46Trwd94hPCjVy/NzTiQjKZZvPvU5m8pqwxOrMabfskQQaW4PnP87mH6vcxfyJ/9zyEMGp8bz3A0nEOt2ceMzBVQ3toQhUGNMf2WJoLc4+Xsw8Qr44Jfw4X3OFBWdGJqewEPfmMy28np+MndlmII0xvRHlgh6CxG44EE45mL48FfwxNnQ3Pn6BCeOzOAHZ4/m9RW7eGPFrjAFaozpbywR9CaxCfD1P8Psv0HJavjn9w85c+nNZ4zi2JxU7pi7gjvnruTjDWU2c6kxplssEfRGY8+Hr/wUVr4Iix7utKjH7eKPV03ixJEZvP7FTr751Oec9/tPqaxvxtfq5+UlRfz6zbW8t6YkTMEbY/qazudFNpFz2o9g9xfw9k+c6SkmXHLQoiMyEnn8m/k0+Vp5bVkxt7+ykuc+206s28Uv568F4OXEIhYdfRYxbsv9xpgD2VWht3K54JLHYfiJMPdGWPrXQx4S53FzxdThnD4mi78s2MqjH2/ilKMyeOKb+ZTXNfP+ur69CJwxJjQsEfRmMfFw1YuQexrMu6VL01EA3HBqHmU1TeypbeaH08dw5tFZZCXH8UGkMGYAABqqSURBVFJBUYgDNsb0RSFNBCIyQ0TWi0ihiNzRwf7TRWSpiPhE5LJQxtJneVPgGy/BhMucO5AP0WcAcNroTI7NSeWssQOZMmIAHreLSybn8MH6UnZXNYYhaGNMXxKyRCAibuAhYCYwHrhSRMa3K7YduA74W6ji6BfcMXDxozBuFrx1Byx+stPiIsJLN5/Ew1dPadt25dTheFzCTc8uoa7JF+qIjTF9SChrBNOAQlXdrKrNwAvAhcEFVHWrqq4AbKL9Q3F74NInYcwMeOOH8NadUHnwxWq8MW5iPft/vbmZifzxqsmsLKrkuj9/zrbyOlYVV/H6ip0sKNyD329DTo2JVqEcNZQD7Ah6XgSccDgvJCJzgDkAw4cPP/LI+ipPrLMO8us/gM8ehYI/w7X/hGFTu3T49PHZPDh7Ej+Zu5Iz7v/wgH3fP3s03z97DC2tfhtZZEyU6RP/8ar6mKrmq2p+VlZWpMOJrBgvXPwwfG+ZM6z0+SugbEOXD5913BDe+cHpfOfMUdx/2UTe+v5pnDV2IE9+soWFm8qZ8t/vctdrK+2mNGOiSCgTQTEwLOj50MA20xPSR8A3XnbuPH70NHjrJ/DePbDl40MeOiQtnttnjOXr+cMYOyiFH597NDVNPr7xxCJaWpVnF23nnnmrLRkYEyVCmQgWA6NFJE9EYoHZwLwQvl/0yTwKbv4UxpwLix5yhpc+PQs+/t0hp6YINm5wChdMHEysx8WLN53EDafm8fTCbfxq/loWbirnxcU7qA3qYC6raaKhufO1E4wxfYeE8lOfiJwHPAi4gadU9Zcici9QoKrzRGQq8CqQDjQCu1X1mM5eMz8/XwsKCkIWc5/lawK/D/55K6x8CU74Dsz4tTOZXRc0+VqprG8hO8WLqnLPvNU8vXBb2/7U+BhmThiECLxUUMS0vAE8d8MJbesqN/laifO4Q/KjGWOOnIgsUdX8jvaFdIoJVZ0PzG+37e6gx4txmozMkfLEAXHO3ciJWbDoT84NaWf/vEuHx3ncZKc4F3IR4Z5ZxzBqYBJpCbEMTvXy539v4c1Vu6lt8jEtdwALNpXzytJiLpsylGcWbuUX/1zD7KnD+K8ZY0mNjwndz2mM6XEhrRGEgtUIukAV5n0Xlv0Vrn0d8k7rkZf1+5Umn584j4uvP7qQjSU1nD4mi9dX7OLo7GQ2ltZw3LA05n7n5LaagjGmd+isRtAnRg2ZbhKBmffBgJHw2ndg1VxorDril3W5hPhYNy6XcP9lE5mQk8q/C/dw3rGDmPfdU/jVxceybHslb63a3QM/hDEmXKxG0J/tWAx/uxwa9kL8APjqXTDhUohPC8nbtfqVGQ9+TJPPz8isRFYWVaHAA5cfx5lHD+z02Kr6FgrLapgyYkBIYjMm2lmNIFoNmwo/3gjXvwUDxzt3JN+XC/cfBQ9OhG0LevTt3C7h9hlj2b63nnW7apg+PpvU+BjunLuSkupG/rpwKyuLqvhsczln3P8Bv3lzHX6/Ul7bxOWPLuTShxfyxY7KHo3JGHNoViOIFqrOhX/bv6F6J2x81+lM/s4C547lHrRlTx3D0uPxuF0s2VbBZY8sIMblornVmUnEJc4opIr6FsYOSqa8rpnqhhZiPS7yR6Tz5+un4Wv1U7CtgrzMRLJTvAe8flV9C5v21DIwOY6ctHjrjzCmCzqrEVgiiFYb3naajabdBGPPg4QMSMmBhJ5vmrnvrXV8unEPd8wcy5JtFeyqauTO88byj2XFzF1WzMDkOL596kgWb93L/W+v5/yJg1lQuIeK+hbGD07hn989lb11zXhcQkurn1l//De7q51ZVAelePl6/lB+cPYYXC5LCMYcjCUC07EXr4U1rx24bcBIGDoVjp4Jx1wc1nBqm3x89XcfUt/cytnjBjIkLZ4/fbiJa08awT++2Emzz09WchxlNU386uJjqWny8dH6Ut5bW8oFEwdz36UT2Vhay0/mruSrYwdyy1ePwhtj9zYYA5YIzMH4/bBnPdTvhfpy2LsJigpgx+dQVwqXPAETvx7WkGoanSaiOI8bVeWqxz9j4eZyhqbHc9ywNN5dU8IfrpzEuccMajvm0Y828es315Hi9dDk8xMf66ayvoXhAxL4yXnjKCytYe2uGs48OovzJw4mIdZWaDXRxxKB6Z7WFmeqip3L4JpXYWg+rPg7DJkE2Z3e+N3jtuyp4+EPC/nB9DEMTo3H1+rH08HsqMu2V/DEJ1tobGnlt5dNZH1JDXe9torNZXUAZCbFsae2iYHJcXzr1DwS4zxsKq2lqKKB3IwEzh6fzYkjM7ocV6tfKa5oYNgA66MwfYMlAtN9NSXwxNlQtR2Sh0DNTvCmOtNeJ2ZBSwPs3QKf/M4ZkXT+/3R5OotwafK18taq3Rw1MInxg1P4fMte7ntrHUu3OyOT4mPcDE2PZ0dFPY0tfo4bmkptk4+MxDgmj0hnwaY9DEyO45cXH9vWYb1kWwVPfbqF99eV0tDSyrdOyePurx243lJpTSOp8TGdTrnR7PPjdglu69cwYWKJwByephr4+H4oXgrHXQkf/Aqq2617HJcCTdVOIph6Q2Ti7AZVpaymCYABibF43C4aW1r568JtvL5iJ9kpXmf46+4aJg5NZWNJLd4YF5dNGcqWPfW8t7aEFK+HC4/PoaK+mddX7OIbJwxny546puYOIDMplntfX0N6Qixnj89mdXEVk4anc9u5R5MY5zRJlVY3MvuxRcS4XTz+zXyGZyR0Of5mn/+ABYeM6SpLBKZnVGyFZc9CUjbEJTvzG42ZAX+/BjZ/AKPPcUYetTTAybfAwHGRjviw1Tf7SIj1UFhayy/fWMOnhXuI87j5zpmjuO7kXBLjPLS0+rnmyc9YtHkveZmJbNnjNEOdelQmrX5lyfYKxg1OYUVRJYNTvFx7ci6DUr386YNN7KioJ8btwu9XjslJIdkbQ6zHxemjMxmTnczGklpeX7mL7eV1DEr1MnPCYPyq/Pat9VwxdRg//9p4tu+tZ0BiLMne/XM71TS2cMPTBYzISOBXFx/bYTMawNLtFWwsqeHscdlkJMWF5ZyayLJEYEKroQLe/39Q+J7z2N8K6ofJ33RmRPV4neakzDGQdTSkjXCW3ty1AooWO0NXR33FaXrqpWqbfAi0farfp7GllbKaJoYNSGDp9grW767h8vxhuF2CqiIiLN66l9++tY7FWysASIx18/g38xmSFs/v39/I9vJ6apt8VDe0sLOqse21h6bHc9zQNDaV1bJudw0AuRkJbC2v59icVFYWV5GZFMv08YOYv3IXwwbEE+dxs2x7BX6FmRMG8aNzxvDh+jJeWVrMWWMHct0pudQ1+bjgD59S0+jD4xJ+MH0MN50+khXFVRRVNOD1uDh9TNYBI66afK2UVDV1u09k9c4qXiooYlNZLbd85ShO6EY/jOlZlghMeNXshldvcm5gi00CXyO01O/f7451VlcLXnM5bQRc9CfncWIWZIwGl8vph1j/pjOkNWeKs62P2rKnjmafn9zMhA77D1SVlcVVlFQ3MSIjgdEDk9ouuku2VVDd0MIZY7K4/ZUVvL5iF9efksvCzeV8saOS6eOzWbOrmh17G3jg8uPYW9fML+evbVuWYkx2EhtLa4l1u8hIjKWuuZXfXzmJlwp28PqKXcTHuGlo2b/GRLLXgzfGja/VT15mIhtKaqlt8pGZFIc3xkVVfQveWDeJsW4SYj0kxrk579jBXH9KHhV1zRRVNLBudzU/fW0VLoGkOA8Nza384apJDE6NxyVCemIMA5OdvpfGllY+2biH1TurqKhrZkRGIkleD5X1zSzdVsm0vAFcf0pu2/nwtfrZXd3I0u2VFJbWcuW0YQxOjT/s382+pN2fWSIwkddQCXs2wp4NzpDVvVtg2Akw7mvOsNXX/gNqdu0vH5cKg451agytTps+iQNhzDlw9HmQPQFQ547pfTWQjFHg6v/3Dagqza3+tiG2TT4/3hg3zT4/xZUN5GUmAlBc2cD7a0sYkhbPV8cOZPOeOh7/eDNvrtrNA5cfx1njslFVnvtsO1/sqOT0MVmMyU6mpLqR+Sud34UIFJbWkpeZyIScVJZtr0RVSUuIpcnXSl1TK/XNPnZWNrJmVzWXTM7hvTUlVDc6CxlNyx3AI9dMoaXVz2WPLGDH3oYDfpZxg1OI87goLHUSjQgkxnoOWAhp34ivK/KHcda4gXywvpRXlhbT7PO3lRmS6uUv35rGUVlJPPivjbz+xU4U+N5ZR3HxpKEUVdTzwLsbWLa9kolDUxmSFs+AhFiOH57GSwU7eG35TlK8MZw2OpMfTh/D0PR4Xioo4oXF2znnmEFMH59NU4ufGLcwMMXbNtV6XZOPvXXN5KTFd3pD46LN5QxO9TIiI/FL+1bvrOLt1SV85egsJg1PP7w/ii6wRGB6v9oy2PQ+JGY6CaGowBm+mn0MnPw92L0SNrzpTI3RVN3xa8QPgAF5UFXkjGQacTLEpzsd2t4UcHlgyV+cJqn862D8ReBNc+6ZSMru+l3VRQVQW+rckW0AZzjtj15czmvLdzJlRDo3npYHCF8Zm9VW+9lb18znW/aiqvgVtu+t59PCMlwiDB+QwIwJg5iaO4A4j4vyumYamltJiHWTnhDLfW+t49GPNwMQ63FxyaQcjhuWxthByXhcLr719GIq6poZk53Mml3VnHpUJlUNLawsruL0MVksKNyDyyWcMiqDtbtqKK9roqXVufZ5XMIlk3Pw+ZU3VuyiyecnOc5DTZOPIaneA5rrwJki5ZghqZTWNFJS7XxIGZmZyNnjs6msb2ZkVhKnHpXJ+MEpVDe28Lt31vPsou3Eul1cMXUYCbFuEOczzOqdVfy7sLzttScNT+OqacMREXZWNrCrqoHiykYSY91cMXUYp4/OOuw76COWCERkBvB/OCuUPaGqv2m3Pw54BpgClANXqOrWzl7TEkGU8zXD9oVOs5K4nI+sLo/TF7H5Q6dZKmUIFC9xah/t7atpbPu03Q6BrLFOzcKbCpmjnZpGS72z+ltsorO9sQpWz3UOOe5KOOpsqC6GncvBHeM0hTXXQXI2DDwGssc7icjvC9RcWgOPfU4yqSuD4Sc5tRlVqC1xYkge3Plw3NbAz5ue6yxZ2gv4Wv0s21HJ5OHpIRkWW1rdyK6qRoakxZOVfGAHd0l1I498tIlXlxVz8xmjuOn0kTT5/Hzv+WUs2FTO5fnDuOG0PIak7W8+Kq1pZPGWCsYOTmZUVhIAu6sambusiKKKBiYMSWX21GGsLK5iU1kt8TFuWvzKxpIaPt+ylyFp8YzOTiIx1sPcZcWsKq4iPSGWPbVOckiNj6GmsQW/wg2n5rG3rpnXlhe3deCrKqMHJnPWuIFcdcJw3l61mz8v2Mq28v3NqJlJseSkxVNc2cCe2mbunDmWm84YdVjnLyKJQETcwAZgOlCEs4bxlaq6JqjMfwATVfVmEZkNXKyqV3T2upYITJe1NDq1h8ZqaKqCploYfJwzDffulbB7FTRWOn0S5Ztg51Kn/6K+HPZudi7sMQnO6KjmOicJtDTClGudCfs+/h0Q+P9JG+58b6p1kkbNbvC3dD3WWOdCRHOt8z1+gPP+viZobXZGacUPcGotHq+T5Kp2OGWHTHbiUb9zM2BTjTORYGyS87PEJjod9e59kwvqAd8Ap0ktNgnikpzXF5czOWHDXqfWlDDAOQ+1Zc57pQxxvjdUOu+RPMiJURVivIHz5g2cu3onwXlTnTKtLc65aW12Hrc2O++3bzSaOwbccc53vw/KC53YU4eCKzBCqqMkecA2ARE0Ph2fJ4kY8TvnEnVee/tC5xzmTHZ+/+C8d2M11O1xYk0Y4Pzs/hYnhpI1kDESMo5yXqOl3jnXzXWQkIEmZiIuNyXVjXy6cQ+fbSlnUGo808dlc+xQZyCE369tn+gP6JdorofK7bTGJLC6LoUUbwyDUr1tHfbNPj9vrd7NtNwBDEo9cBLGropUIjgJuEdVzw08vxNAVX8dVObtQJmFIuIBdgNZ2klQlghMr1FV5PwDJ2RAYrvRMK0tTnIpXeMMp3V5nIuty+08FrdzXHwabP7IGZqrfucTvohzHOy/IDZVO1OBNFQ4ne/x6TDpGqffZfOHTlkRp2xcslNzaqpxLmZN1U4s/v2dwfsvmoHv/hbnZ2mupS1DxCY5TXUNlYGFjdTZ1tLg1GzaXsvlxN5rCQdmvRC/V9vvOvB7drloO8/7zrs7zknWzXVO8tnXDwbODZyeOCcJtiXLQMI877cw5brDiyxCaxbnADuCnhcBJxysjKr6RKQKyAD2BBcSkTnAHIDhw4eHKl5juie1k+W23TEwcKzzdShZRx9ZHGfcdmTHB/P7nYuSv9WpSey7cPlbA01kCU6zVH25k5Dikp2kVFe2f2SYr8l53NLgXLzccU5TWWO1k2jccc7wYXds4CvGef2a3c6FsbV5/wVQxJkI0e9zEq8qB1zU2z4zdrBNW504m2r2X3gRJ7aB42HwRKdJr6nGOb6x2qkRJWU72+r2OAnQHePcHzNogpNQq4qc+GLinZ8/Jn7/fF3+oKY/9e9vEgyOUdU5x75m5xzHJTs1kLThTqIvKnDKumICtaPAOXLHOM2NIdAnZt9S1ceAx8CpEUQ4HGP6L5cLXB0Mw3S5nSQAzkU8OfvA/Umdr0DXJRmH1/Z9RNJzu1d+0LEhCeMAJ9wU+vdoJ5SDsouBYUHPhwa2dVgm0DSUitNpbIwxJkxCmQgWA6NFJE9EYoHZwLx2ZeYB1wYeXwa831n/gDHGmJ4XsqahQJv/LcDbOMNHn1LV1SJyL1CgqvOAJ4G/ikghsBcnWRhjjAmjkPYRqOp8YH67bXcHPW4EwrvyiTHGmAP03YlbjDHG9AhLBMYYE+UsERhjTJSzRGCMMVGuz80+KiJlwLbDPDyTdnct9yK9NTaLq3ssru7rrbH1t7hGqGpWRzv6XCI4EiJScLC5NiKtt8ZmcXWPxdV9vTW2aIrLmoaMMSbKWSIwxpgoF22J4LFIB9CJ3hqbxdU9Flf39dbYoiauqOojMMYY82XRViMwxhjTjiUCY4yJclGTCERkhoisF5FCEbkjgnEME5EPRGSNiKwWkVsD2+8RkWIRWR74Oi8CsW0VkZWB9y8IbBsgIu+KyMbA9/Qwx3R00DlZLiLVIvL9SJ0vEXlKREpFZFXQtg7PkTh+H/ibWyEik8Mc1/0isi7w3q+KSFpge66INASdu0fCHNdBf3cicmfgfK0XkXNDFVcnsf09KK6tIrI8sD0s56yT60No/8ZUtd9/4UyDvQkYCcQCXwDjIxTLYGBy4HEysAEYD9wD/DjC52krkNlu22+BOwKP7wDui/DvcTcwIlLnCzgdmAysOtQ5As4D3sRZsPZE4LMwx3UO4Ak8vi8ortzgchE4Xx3+7gL/B18AcUBe4H/WHc7Y2u3/H+DucJ6zTq4PIf0bi5YawTSgUFU3q2oz8AJwYSQCUdVdqro08LgGWIuzdnNvdSHwdODx08BFEYzlLGCTqh7uneVHTFU/xlk7I9jBztGFwDPqWASkicjgcMWlqu+oqi/wdBHOKoFhdZDzdTAXAi+oapOqbgEKcf53wx6biAhwOfB8qN7/IDEd7PoQ0r+xaEkEOcCOoOdF9IKLr4jkApOAzwKbbglU754KdxNMgALviMgSEZkT2JatqrsCj3cD2R0fGhazOfAfM9Lna5+DnaPe9Hf3LZxPjvvkicgyEflIRE6LQDwd/e560/k6DShR1Y1B28J6ztpdH0L6NxYtiaDXEZEk4BXg+6paDTwMjAKOB3bhVEvD7VRVnQzMBP5TRE4P3qlOXTQi443FWe50FvBSYFNvOF9fEslzdDAi8lPABzwX2LQLGK6qk4AfAn8TkZQwhtQrf3ftXMmBHzrCes46uD60CcXfWLQkgmJgWNDzoYFtESEiMTi/5OdUdS6Aqpaoaquq+oHHCWGV+GBUtTjwvRR4NRBDyb6qZuB7abjjCpgJLFXVkkCMET9fQQ52jiL+dyci1wEXAN8IXEAINL2UBx4vwWmLHxOumDr53UX8fAGIiAe4BPj7vm3hPGcdXR8I8d9YtCSCxcBoEckLfLKcDcyLRCCBtscngbWq+kDQ9uB2vYuBVe2PDXFciSKSvO8xTkfjKpzzdG2g2LXAP8IZV5ADPqFF+ny1c7BzNA/4ZmBkx4lAVVD1PuREZAbwX8AsVa0P2p4lIu7A45HAaGBzGOM62O9uHjBbROJEJC8Q1+fhiivI2cA6VS3atyFc5+xg1wdC/TcW6l7w3vKF07u+ASeT/zSCcZyKU61bASwPfJ0H/BVYGdg+Dxgc5rhG4ozY+AJYve8cARnAv4CNwHvAgAics0SgHEgN2haR84WTjHYBLTjtsd8+2DnCGcnxUOBvbiWQH+a4CnHaj/f9nT0SKHtp4He8HFgKfC3McR30dwf8NHC+1gMzw/27DGz/C3Bzu7JhOWedXB9C+jdmU0wYY0yUi5amIWOMMQdhicAYY6KcJQJjjIlylgiMMSbKWSIwxpgoZ4nAmDASkTNF5PVIx2FMMEsExhgT5SwRGNMBEblaRD4PzD3/qIi4RaRWRP43ME/8v0QkK1D2eBFZJPvn/d83V/xRIvKeiHwhIktFZFTg5ZNE5GVx1gp4LnA3qTERY4nAmHZEZBxwBXCKqh4PtALfwLnDuUBVjwE+An4eOOQZ4HZVnYhzd+e+7c8BD6nqccDJOHexgjOj5Pdx5pkfCZwS8h/KmE54Ih2AMb3QWcAUYHHgw3o8ziRffvZPRPYsMFdEUoE0Vf0osP1p4KXAvE05qvoqgKo2AgRe73MNzGMjzgpYucCnof+xjOmYJQJjvkyAp1X1zgM2ivysXbnDnZ+lKehxK/Z/aCLMmoaM+bJ/AZeJyEBoWy92BM7/y2WBMlcBn6pqFVARtFDJNcBH6qwuVSQiFwVeI05EEsL6UxjTRfZJxJh2VHWNiNyFs1qbC2d2yv8E6oBpgX2lOP0I4EwL/EjgQr8ZuD6w/RrgURG5N/AaXw/jj2FMl9nso8Z0kYjUqmpSpOMwpqdZ05AxxkQ5qxEYY0yUsxqBMcZEOUsExhgT5SwRGGNMlLNEYIwxUc4SgTHGRLn/D7QhiKAELunxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_weights(\"best.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in m.predict(X_test.values).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1072\n",
      "           1       1.00      1.00      1.00       959\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
       "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
       "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
       "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:129: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5483 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      " - 5s - loss: 0.6732 - acc: 0.5780 - val_loss: 0.6023 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60230, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.5606 - acc: 0.8266 - val_loss: 0.5268 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60230 to 0.52681, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.4815 - acc: 0.8379 - val_loss: 0.4560 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52681 to 0.45601, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.4268 - acc: 0.8501 - val_loss: 0.4115 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45601 to 0.41145, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.3969 - acc: 0.8525 - val_loss: 0.3813 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41145 to 0.38129, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.3710 - acc: 0.8663 - val_loss: 0.3673 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38129 to 0.36733, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.3503 - acc: 0.8734 - val_loss: 0.3451 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36733 to 0.34507, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3323 - acc: 0.8773 - val_loss: 0.3319 - val_acc: 0.8803\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34507 to 0.33188, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.3189 - acc: 0.8802 - val_loss: 0.3156 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33188 to 0.31564, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3116 - acc: 0.8816 - val_loss: 0.3016 - val_acc: 0.8967\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31564 to 0.30155, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.2969 - acc: 0.8827 - val_loss: 0.2919 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30155 to 0.29191, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.2917 - acc: 0.8835 - val_loss: 0.2763 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29191 to 0.27634, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.2736 - acc: 0.8909 - val_loss: 0.2740 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27634 to 0.27402, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.2719 - acc: 0.8922 - val_loss: 0.2542 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27402 to 0.25415, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.2560 - acc: 0.8957 - val_loss: 0.2561 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25415\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2523 - acc: 0.8993 - val_loss: 0.2469 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25415 to 0.24686, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.2513 - acc: 0.9030 - val_loss: 0.2689 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24686\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.2426 - acc: 0.9046 - val_loss: 0.2196 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24686 to 0.21959, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2289 - acc: 0.9097 - val_loss: 0.2185 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.21959 to 0.21852, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2282 - acc: 0.9150 - val_loss: 0.2075 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21852 to 0.20747, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2197 - acc: 0.9167 - val_loss: 0.2087 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20747\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2183 - acc: 0.9163 - val_loss: 0.1963 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.20747 to 0.19632, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2123 - acc: 0.9229 - val_loss: 0.1920 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.19632 to 0.19197, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.2090 - acc: 0.9238 - val_loss: 0.1925 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19197\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2080 - acc: 0.9229 - val_loss: 0.1875 - val_acc: 0.9295\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19197 to 0.18752, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.2041 - acc: 0.9274 - val_loss: 0.1831 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.18752 to 0.18306, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2005 - acc: 0.9301 - val_loss: 0.1865 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.18306\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.1966 - acc: 0.9311 - val_loss: 0.1750 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18306 to 0.17499, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.1997 - acc: 0.9291 - val_loss: 0.1726 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17499 to 0.17257, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.1930 - acc: 0.9322 - val_loss: 0.1717 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.17257 to 0.17173, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1900 - acc: 0.9336 - val_loss: 0.1675 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17173 to 0.16755, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9353 - val_loss: 0.1639 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16755 to 0.16387, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.1920 - acc: 0.9345 - val_loss: 0.1780 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16387\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.1929 - acc: 0.9351 - val_loss: 0.1924 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16387\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1929 - acc: 0.9331 - val_loss: 0.1669 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16387\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1838 - acc: 0.9385 - val_loss: 0.1592 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16387 to 0.15922, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.1881 - acc: 0.9398 - val_loss: 0.1636 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15922\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1833 - acc: 0.9405 - val_loss: 0.1527 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15922 to 0.15267, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1778 - acc: 0.9418 - val_loss: 0.1507 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15267 to 0.15067, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1782 - acc: 0.9415 - val_loss: 0.1488 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15067 to 0.14876, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1769 - acc: 0.9407 - val_loss: 0.1479 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14876 to 0.14792, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1749 - acc: 0.9429 - val_loss: 0.1606 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14792\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1755 - acc: 0.9418 - val_loss: 0.1447 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14792 to 0.14466, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1709 - acc: 0.9451 - val_loss: 0.1496 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.14466\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1711 - acc: 0.9429 - val_loss: 0.1424 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14466 to 0.14241, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1763 - acc: 0.9398 - val_loss: 0.1426 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.14241\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1760 - acc: 0.9440 - val_loss: 0.1412 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14241 to 0.14124, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1691 - acc: 0.9460 - val_loss: 0.1372 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14124 to 0.13717, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1697 - acc: 0.9453 - val_loss: 0.1384 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.13717\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1643 - acc: 0.9484 - val_loss: 0.1393 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.13717\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9449 - val_loss: 0.1327 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13717 to 0.13267, saving model to best.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      " - 0s - loss: 0.1623 - acc: 0.9478 - val_loss: 0.1327 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.13267\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1591 - acc: 0.9477 - val_loss: 0.1295 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13267 to 0.12951, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.1602 - acc: 0.9495 - val_loss: 0.1295 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12951 to 0.12951, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1580 - acc: 0.9475 - val_loss: 0.1279 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12951 to 0.12787, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1580 - acc: 0.9488 - val_loss: 0.1265 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12787 to 0.12650, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1557 - acc: 0.9488 - val_loss: 0.1304 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12650\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1575 - acc: 0.9475 - val_loss: 0.1260 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12650 to 0.12605, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1538 - acc: 0.9491 - val_loss: 0.1238 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12605 to 0.12378, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.1608 - acc: 0.9442 - val_loss: 0.1223 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12378 to 0.12225, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1591 - acc: 0.9466 - val_loss: 0.1361 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.12225\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1640 - acc: 0.9440 - val_loss: 0.1297 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.12225\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1527 - acc: 0.9486 - val_loss: 0.1184 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12225 to 0.11839, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1464 - acc: 0.9504 - val_loss: 0.1185 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.11839\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1468 - acc: 0.9508 - val_loss: 0.1187 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.11839\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1435 - acc: 0.9520 - val_loss: 0.1158 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11839 to 0.11583, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1444 - acc: 0.9506 - val_loss: 0.1123 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.11583 to 0.11233, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1427 - acc: 0.9500 - val_loss: 0.1156 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.11233\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9513 - val_loss: 0.1127 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.11233\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1401 - acc: 0.9529 - val_loss: 0.1078 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.11233 to 0.10778, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9524 - val_loss: 0.1196 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10778\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9533 - val_loss: 0.1069 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.10778 to 0.10692, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9537 - val_loss: 0.1061 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.10692 to 0.10607, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1316 - acc: 0.9540 - val_loss: 0.1019 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.10607 to 0.10187, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1351 - acc: 0.9540 - val_loss: 0.1137 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10187\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1282 - acc: 0.9544 - val_loss: 0.0995 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.10187 to 0.09950, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9542 - val_loss: 0.1198 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.09950\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1379 - acc: 0.9508 - val_loss: 0.0990 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.09950 to 0.09904, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.1248 - acc: 0.9564 - val_loss: 0.0968 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.09904 to 0.09677, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1222 - acc: 0.9568 - val_loss: 0.1040 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.09677\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1251 - acc: 0.9562 - val_loss: 0.1056 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.09677\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.1279 - acc: 0.9551 - val_loss: 0.0903 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.09677 to 0.09029, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1173 - acc: 0.9575 - val_loss: 0.0892 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.09029 to 0.08916, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.1149 - acc: 0.9599 - val_loss: 0.0881 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.08916 to 0.08810, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9588 - val_loss: 0.0929 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08810\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9581 - val_loss: 0.0841 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.08810 to 0.08413, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1080 - acc: 0.9626 - val_loss: 0.0818 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.08413 to 0.08182, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1071 - acc: 0.9621 - val_loss: 0.0839 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08182\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1086 - acc: 0.9599 - val_loss: 0.0796 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.08182 to 0.07958, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0997 - acc: 0.9661 - val_loss: 0.0828 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.07958\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1004 - acc: 0.9624 - val_loss: 0.0754 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.07958 to 0.07537, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0986 - acc: 0.9652 - val_loss: 0.0758 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.07537\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0968 - acc: 0.9648 - val_loss: 0.0750 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.07537 to 0.07499, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0967 - acc: 0.9644 - val_loss: 0.0697 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.07499 to 0.06974, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0912 - acc: 0.9677 - val_loss: 0.0677 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06974 to 0.06770, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0918 - acc: 0.9681 - val_loss: 0.0668 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.06770 to 0.06681, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9725 - val_loss: 0.0660 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.06681 to 0.06596, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0828 - acc: 0.9699 - val_loss: 0.0804 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.06596\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9697 - val_loss: 0.0625 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.06596 to 0.06249, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9737 - val_loss: 0.0627 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.06249\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9763 - val_loss: 0.0575 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.06249 to 0.05753, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0716 - acc: 0.9750 - val_loss: 0.0573 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.05753 to 0.05729, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0695 - acc: 0.9757 - val_loss: 0.0544 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05729 to 0.05444, saving model to best.model\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0687 - acc: 0.9761 - val_loss: 0.0538 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05444 to 0.05381, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0657 - acc: 0.9785 - val_loss: 0.0517 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05381 to 0.05166, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0655 - acc: 0.9796 - val_loss: 0.0508 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.05166 to 0.05078, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0618 - acc: 0.9790 - val_loss: 0.0496 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.05078 to 0.04964, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0631 - acc: 0.9790 - val_loss: 0.0465 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04964 to 0.04651, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9814 - val_loss: 0.0482 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04651\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9834 - val_loss: 0.0455 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.04651 to 0.04555, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0546 - acc: 0.9845 - val_loss: 0.0472 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04555\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0506 - acc: 0.9871 - val_loss: 0.0448 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.04555 to 0.04479, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0516 - acc: 0.9845 - val_loss: 0.0428 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.04479 to 0.04276, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0475 - acc: 0.9889 - val_loss: 0.0385 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04276 to 0.03847, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9898 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03847 to 0.03742, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9905 - val_loss: 0.0375 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03742\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9912 - val_loss: 0.0375 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03742\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0415 - acc: 0.9916 - val_loss: 0.0350 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.03742 to 0.03495, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0397 - acc: 0.9918 - val_loss: 0.0370 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03495\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0402 - acc: 0.9903 - val_loss: 0.0323 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.03495 to 0.03230, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0368 - acc: 0.9927 - val_loss: 0.0321 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.03230 to 0.03212, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0374 - acc: 0.9898 - val_loss: 0.0315 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.03212 to 0.03145, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0367 - acc: 0.9920 - val_loss: 0.0321 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03145\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0342 - acc: 0.9933 - val_loss: 0.0295 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.03145 to 0.02950, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9905 - val_loss: 0.0437 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02950\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9916 - val_loss: 0.0275 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02950 to 0.02750, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9929 - val_loss: 0.0268 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02750 to 0.02682, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0288 - acc: 0.9942 - val_loss: 0.0287 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02682\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0280 - acc: 0.9940 - val_loss: 0.0290 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02682\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0281 - acc: 0.9938 - val_loss: 0.0238 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02682 to 0.02378, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0268 - acc: 0.9943 - val_loss: 0.0260 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02378\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9945 - val_loss: 0.0226 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02378 to 0.02263, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0259 - acc: 0.9940 - val_loss: 0.0229 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02263\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0236 - acc: 0.9953 - val_loss: 0.0275 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02263\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9953 - val_loss: 0.0218 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.02263 to 0.02185, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0222 - acc: 0.9962 - val_loss: 0.0217 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.02185 to 0.02167, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0218 - acc: 0.9956 - val_loss: 0.0210 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.02167 to 0.02104, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9953 - val_loss: 0.0248 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02104\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9956 - val_loss: 0.0250 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02104\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9953 - val_loss: 0.0205 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.02104 to 0.02048, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9962 - val_loss: 0.0194 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.02048 to 0.01939, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9964 - val_loss: 0.0181 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01939 to 0.01806, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0183 - acc: 0.9962 - val_loss: 0.0189 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01806\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9964 - val_loss: 0.0180 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.01806 to 0.01803, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9974 - val_loss: 0.0168 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.01803 to 0.01682, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9967 - val_loss: 0.0205 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01682\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9965 - val_loss: 0.0178 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01682\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9971 - val_loss: 0.0159 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01682 to 0.01589, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0156 - acc: 0.9971 - val_loss: 0.0188 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01589\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9965 - val_loss: 0.0191 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01589\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0147 - acc: 0.9976 - val_loss: 0.0155 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.01589 to 0.01547, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9976 - val_loss: 0.0143 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01547 to 0.01429, saving model to best.model\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9971 - val_loss: 0.0145 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01429\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0135 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01429 to 0.01420, saving model to best.model\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0184 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01420\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9980 - val_loss: 0.0131 - val_acc: 0.9984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00156: val_loss improved from 0.01420 to 0.01308, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9982 - val_loss: 0.0171 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01308\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0120 - acc: 0.9982 - val_loss: 0.0129 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.01308 to 0.01286, saving model to best.model\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0134 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01286\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0115 - acc: 0.9985 - val_loss: 0.0121 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.01286 to 0.01215, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0123 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01215\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9982 - val_loss: 0.0117 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.01215 to 0.01173, saving model to best.model\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9984 - val_loss: 0.0122 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01173\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9987 - val_loss: 0.0121 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01173\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9978 - val_loss: 0.0106 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.01173 to 0.01062, saving model to best.model\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9984 - val_loss: 0.0110 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01062\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9985 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01062\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9989 - val_loss: 0.0108 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.01062\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9989 - val_loss: 0.0105 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.01062 to 0.01046, saving model to best.model\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9987 - val_loss: 0.0122 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.01046\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9991 - val_loss: 0.0111 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01046\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0095 - acc: 0.9982 - val_loss: 0.0181 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.01046\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9987 - val_loss: 0.0105 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01046\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.01046 to 0.00936, saving model to best.model\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0081 - acc: 0.9987 - val_loss: 0.0107 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00936\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00936\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9982 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00936\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9989 - val_loss: 0.0087 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00936 to 0.00867, saving model to best.model\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0081 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00867 to 0.00806, saving model to best.model\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0112 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00806\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9985 - val_loss: 0.0086 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00806\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00806\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0073 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00806 to 0.00725, saving model to best.model\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0082 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00725\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9993 - val_loss: 0.0108 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00725\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0101 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00725\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0090 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00725\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00725\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0073 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00725\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0076 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00725\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00725 to 0.00627, saving model to best.model\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00627\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00627\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0071 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00627\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0078 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00627\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00627\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00627\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0112 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00627\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0090 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00627\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00627\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.models import Model\n",
    "import keras\n",
    "history = History()\n",
    "\n",
    "\n",
    "input_1 = Input(shape=(1,))\n",
    "input_2 = Input(shape=(1,))\n",
    "input_3 = Input(shape=(1,))\n",
    "input_4 = Input(shape=(1,))\n",
    "input_5 = Input(shape=(1,))\n",
    "input_6 = Input(shape=(1,))\n",
    "input_7 = Input(shape=(1,))\n",
    "input_8 = Input(shape=(1,))\n",
    "input_9 = Input(shape=(1,))\n",
    "input_10 = Input(shape=(1,))\n",
    "input_11 = Input(shape=(1,))\n",
    "input_12 = Input(shape=(1,))\n",
    "input_13 = Input(shape=(1,))\n",
    "input_14= Input(shape=(1,))\n",
    "input_15 = Input(shape=(1,))\n",
    "input_16 = Input(shape=(1,))\n",
    "input_17 = Input(shape=(1,))\n",
    "input_18 = Input(shape=(1,))\n",
    "input_19 = Input(shape=(1,))\n",
    "input_20= Input(shape=(1,))\n",
    "input_21= Input(shape=(1,))\n",
    "input_22 = Input(shape=(1,))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_1 = Dense(32, activation='sigmoid')(input_1)\n",
    "hidden_2 = Dense(32, activation='sigmoid')(input_2)\n",
    "hidden_3 = Dense(32, activation='sigmoid')(input_3)\n",
    "hidden_4 = Dense(32, activation='sigmoid')(input_4)\n",
    "hidden_5 = Dense(32, activation='sigmoid')(input_5)\n",
    "hidden_6 = Dense(32, activation='sigmoid')(input_6)\n",
    "hidden_7 = Dense(32, activation='sigmoid')(input_7)\n",
    "hidden_8 = Dense(32, activation='sigmoid')(input_8)\n",
    "hidden_9 = Dense(32, activation='sigmoid')(input_9)\n",
    "hidden_10 = Dense(32, activation='sigmoid')(input_10)\n",
    "hidden_11= Dense(32, activation='sigmoid')(input_11)\n",
    "hidden_12 = Dense(32, activation='sigmoid')(input_12)\n",
    "hidden_13= Dense(32, activation='sigmoid')(input_13)\n",
    "hidden_14= Dense(32, activation='sigmoid')(input_14)\n",
    "hidden_15= Dense(32, activation='sigmoid')(input_15)\n",
    "hidden_16= Dense(32, activation='sigmoid')(input_16)\n",
    "hidden_17= Dense(32, activation='sigmoid')(input_17)\n",
    "hidden_18= Dense(32, activation='sigmoid')(input_18)\n",
    "hidden_19= Dense(32, activation='sigmoid')(input_19)\n",
    "hidden_20= Dense(32, activation='sigmoid')(input_20)\n",
    "hidden_21= Dense(32, activation='sigmoid')(input_21)\n",
    "hidden_22= Dense(32, activation='sigmoid')(input_22)\n",
    "\n",
    "\n",
    "\n",
    "value_list=[X_train[['cap-shape']].values,\n",
    "            X_train[['cap-surface']].values,\n",
    "            X_train[['cap-color']].values,\n",
    "            X_train[['bruises']].values,\n",
    "            X_train[['odor']].values,\n",
    "            X_train[['gill-attachment']].values,\n",
    "            X_train[['gill-spacing']].values,\n",
    "            X_train[['gill-size']].values,\n",
    "            X_train[['gill-color']].values,\n",
    "            X_train[['stalk-shape']].values,\n",
    "            X_train[['stalk-root']].values,\n",
    "            X_train[['stalk-surface-above-ring']].values,\n",
    "            X_train[['stalk-surface-below-ring']].values,\n",
    "            X_train[['stalk-color-above-ring']].values,\n",
    "            X_train[['stalk-color-below-ring']].values,\n",
    "            X_train[['ring-number']].values,\n",
    "            X_train[['ring-type']].values,\n",
    "            X_train[['spore-print-color']].values,\n",
    "            X_train[['population']].values,\n",
    "            X_train[['habitat']].values,\n",
    "            X_train[['veil-type']].values,\n",
    "            X_train[['veil-color']].values,\n",
    "           ]\n",
    "\n",
    "value_list_test=[X_test[['cap-shape']].values,\n",
    "            X_test[['cap-surface']].values,\n",
    "            X_test[['cap-color']].values,\n",
    "            X_test[['bruises']].values,\n",
    "            X_test[['odor']].values,\n",
    "            X_test[['gill-attachment']].values,\n",
    "            X_test[['gill-spacing']].values,\n",
    "            X_test[['gill-size']].values,\n",
    "            X_test[['gill-color']].values,\n",
    "            X_test[['stalk-shape']].values,\n",
    "            X_test[['stalk-root']].values,\n",
    "            X_test[['stalk-surface-above-ring']].values,\n",
    "            X_test[['stalk-surface-below-ring']].values,\n",
    "            X_test[['stalk-color-above-ring']].values,\n",
    "            X_test[['stalk-color-below-ring']].values,\n",
    "            X_test[['ring-number']].values,\n",
    "            X_test[['ring-type']].values,\n",
    "            X_test[['spore-print-color']].values,\n",
    "            X_test[['population']].values,\n",
    "            X_test[['habitat']].values,\n",
    "            X_test[['veil-type']].values,\n",
    "            X_test[['veil-color']].values,\n",
    "           ]\n",
    "\n",
    "\n",
    "\n",
    "x = keras.layers.concatenate([hidden_1,hidden_2,hidden_3,hidden_4,hidden_5,hidden_6,hidden_7,hidden_8,\n",
    "                             hidden_9,hidden_10,hidden_11,hidden_12,hidden_13,hidden_14,hidden_15,hidden_16,\n",
    "                             hidden_17,hidden_18,hidden_19,hidden_20,hidden_21,hidden_22])\n",
    "\n",
    "x = Dense(96, activation='sigmoid')(x)\n",
    "output = Dense(len(np.unique(Y_train)), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_1,input_2,input_3,input_4,input_5,input_6,input_7,input_8,\n",
    "                     input_9,input_10,input_11,input_12,input_13,input_14,input_15,input_16,\n",
    "                     input_17,input_18,input_19,input_20,input_21,input_22], outputs=[output])\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "hist=model.fit(\n",
    "    value_list, \n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        history,\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256, \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best.model\")\n",
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in model.predict(value_list_test).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1071    1]\n",
      " [   3  956]]\n",
      "99.80305268340719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1072\n",
      "           1       1.00      1.00      1.00       959\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_val=train_test_split(train,test_size=0.25, random_state=10)\n",
    "X_val=data_val.drop(['Class'], axis=1).values\n",
    "y_val=data_val['Class'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_simple(data_train,X_val,y_val):\n",
    "    \n",
    "\n",
    "    data_train_new=data_train.sample(frac=0.632,replace=True)\n",
    "    X_train=data_train_new.drop(['Class'], axis=1).values\n",
    "    y_train=data_train_new['Class'].ravel()\n",
    "    \n",
    "    m = Sequential()\n",
    "    m.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='sigmoid'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='sigmoid'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "    \n",
    "    m.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    m.fit(\n",
    "    X_train, \n",
    "    pd.get_dummies(pd.DataFrame(y_train), columns=[0]).as_matrix(),\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=5),\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.2,\n",
    "    batch_size=256, \n",
    "    )\n",
    "    m.load_weights(\"best.model\")\n",
    "    mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    "    )\n",
    "    y_pred = [mapping[pred] for pred in m.predict(X_val).argmax(axis=1)]\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 7s - loss: 0.8096 - acc: 0.5186 - val_loss: 0.6779 - val_acc: 0.7225\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67792, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7543 - acc: 0.5096 - val_loss: 0.6641 - val_acc: 0.5034\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67792 to 0.66407, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7174 - acc: 0.5488 - val_loss: 0.6308 - val_acc: 0.7225\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66407 to 0.63075, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6712 - acc: 0.6002 - val_loss: 0.5822 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63075 to 0.58222, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6188 - acc: 0.6669 - val_loss: 0.5024 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58222 to 0.50241, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5454 - acc: 0.7346 - val_loss: 0.4270 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50241 to 0.42701, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4837 - acc: 0.7955 - val_loss: 0.3794 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42701 to 0.37944, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4459 - acc: 0.8076 - val_loss: 0.3523 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37944 to 0.35235, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4206 - acc: 0.8259 - val_loss: 0.3288 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35235 to 0.32881, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3912 - acc: 0.8393 - val_loss: 0.3123 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32881 to 0.31232, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3714 - acc: 0.8566 - val_loss: 0.2910 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31232 to 0.29105, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3540 - acc: 0.8651 - val_loss: 0.2757 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29105 to 0.27571, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3427 - acc: 0.8656 - val_loss: 0.2679 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27571 to 0.26794, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3346 - acc: 0.8739 - val_loss: 0.2538 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26794 to 0.25383, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3233 - acc: 0.8783 - val_loss: 0.2464 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25383 to 0.24638, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3082 - acc: 0.8843 - val_loss: 0.2408 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24638 to 0.24080, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3099 - acc: 0.8841 - val_loss: 0.2400 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24080 to 0.23996, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3030 - acc: 0.8895 - val_loss: 0.2359 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23996 to 0.23593, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2892 - acc: 0.8951 - val_loss: 0.2273 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23593 to 0.22729, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2850 - acc: 0.8960 - val_loss: 0.2204 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22729 to 0.22040, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2783 - acc: 0.8958 - val_loss: 0.2153 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22040 to 0.21531, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2759 - acc: 0.9009 - val_loss: 0.2142 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21531 to 0.21424, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2704 - acc: 0.9021 - val_loss: 0.2066 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21424 to 0.20660, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2621 - acc: 0.9043 - val_loss: 0.2043 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20660 to 0.20427, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2624 - acc: 0.9024 - val_loss: 0.1992 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20427 to 0.19916, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2606 - acc: 0.9038 - val_loss: 0.1939 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19916 to 0.19391, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2493 - acc: 0.9084 - val_loss: 0.1891 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19391 to 0.18908, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2512 - acc: 0.9058 - val_loss: 0.1852 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18908 to 0.18516, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2546 - acc: 0.9089 - val_loss: 0.1848 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.18516 to 0.18478, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2456 - acc: 0.9111 - val_loss: 0.1823 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18478 to 0.18228, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2391 - acc: 0.9167 - val_loss: 0.1752 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.18228 to 0.17523, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2379 - acc: 0.9179 - val_loss: 0.1787 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.17523\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2287 - acc: 0.9204 - val_loss: 0.1681 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17523 to 0.16805, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2319 - acc: 0.9187 - val_loss: 0.1648 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16805 to 0.16482, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2305 - acc: 0.9199 - val_loss: 0.1657 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16482\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2309 - acc: 0.9172 - val_loss: 0.1657 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16482\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2160 - acc: 0.9248 - val_loss: 0.1588 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16482 to 0.15881, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2190 - acc: 0.9245 - val_loss: 0.1558 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15881 to 0.15579, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2132 - acc: 0.9255 - val_loss: 0.1539 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15579 to 0.15393, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2144 - acc: 0.9228 - val_loss: 0.1483 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15393 to 0.14826, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1996 - acc: 0.9316 - val_loss: 0.1442 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14826 to 0.14423, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2036 - acc: 0.9272 - val_loss: 0.1434 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14423 to 0.14343, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1983 - acc: 0.9347 - val_loss: 0.1393 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14343 to 0.13926, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1957 - acc: 0.9299 - val_loss: 0.1394 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.13926\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1918 - acc: 0.9357 - val_loss: 0.1334 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13926 to 0.13336, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9311 - val_loss: 0.1311 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13336 to 0.13114, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1862 - acc: 0.9347 - val_loss: 0.1293 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13114 to 0.12926, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1860 - acc: 0.9330 - val_loss: 0.1250 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12926 to 0.12504, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1811 - acc: 0.9360 - val_loss: 0.1222 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12504 to 0.12225, saving model to best.model\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1751 - acc: 0.9367 - val_loss: 0.1198 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12225 to 0.11983, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1783 - acc: 0.9416 - val_loss: 0.1216 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.11983\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1742 - acc: 0.9403 - val_loss: 0.1155 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11983 to 0.11554, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1729 - acc: 0.9401 - val_loss: 0.1139 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11554 to 0.11386, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9411 - val_loss: 0.1114 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11386 to 0.11143, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1623 - acc: 0.9411 - val_loss: 0.1095 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11143 to 0.10948, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1537 - acc: 0.9450 - val_loss: 0.1072 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10948 to 0.10720, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1590 - acc: 0.9474 - val_loss: 0.1109 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10720\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1630 - acc: 0.9433 - val_loss: 0.1035 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10720 to 0.10347, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9503 - val_loss: 0.1030 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10347 to 0.10296, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1491 - acc: 0.9484 - val_loss: 0.1001 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10296 to 0.10011, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1485 - acc: 0.9469 - val_loss: 0.0983 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10011 to 0.09830, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9542 - val_loss: 0.1000 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.09830\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1533 - acc: 0.9484 - val_loss: 0.0941 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09830 to 0.09411, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9542 - val_loss: 0.0937 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09411 to 0.09372, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1342 - acc: 0.9545 - val_loss: 0.0902 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09372 to 0.09017, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1360 - acc: 0.9530 - val_loss: 0.0887 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09017 to 0.08868, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1352 - acc: 0.9518 - val_loss: 0.0860 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08868 to 0.08597, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1217 - acc: 0.9593 - val_loss: 0.0840 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08597 to 0.08399, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1326 - acc: 0.9540 - val_loss: 0.0926 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08399\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1318 - acc: 0.9542 - val_loss: 0.0839 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08399 to 0.08389, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1256 - acc: 0.9571 - val_loss: 0.0821 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08389 to 0.08215, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1140 - acc: 0.9627 - val_loss: 0.0798 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08215 to 0.07976, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1231 - acc: 0.9552 - val_loss: 0.0859 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07976\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1188 - acc: 0.9615 - val_loss: 0.0773 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.07976 to 0.07726, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1138 - acc: 0.9618 - val_loss: 0.0755 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07726 to 0.07551, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1155 - acc: 0.9603 - val_loss: 0.0728 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07551 to 0.07284, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1132 - acc: 0.9623 - val_loss: 0.0733 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07284\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1137 - acc: 0.9610 - val_loss: 0.0720 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07284 to 0.07200, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1067 - acc: 0.9615 - val_loss: 0.0702 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07200 to 0.07015, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1053 - acc: 0.9625 - val_loss: 0.0694 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07015 to 0.06940, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1073 - acc: 0.9649 - val_loss: 0.0722 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.06940\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9640 - val_loss: 0.0707 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.06940\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1025 - acc: 0.9652 - val_loss: 0.0673 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06940 to 0.06732, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0949 - acc: 0.9693 - val_loss: 0.0661 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06732 to 0.06613, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0943 - acc: 0.9669 - val_loss: 0.0650 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06613 to 0.06500, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0949 - acc: 0.9671 - val_loss: 0.0653 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06500\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1052 - acc: 0.9679 - val_loss: 0.0644 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06500 to 0.06435, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9671 - val_loss: 0.0652 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06435\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0969 - acc: 0.9701 - val_loss: 0.0611 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06435 to 0.06105, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1011 - acc: 0.9635 - val_loss: 0.0601 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06105 to 0.06013, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9710 - val_loss: 0.0614 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06013\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0948 - acc: 0.9683 - val_loss: 0.0594 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.06013 to 0.05943, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1022 - acc: 0.9606 - val_loss: 0.0669 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05943\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0941 - acc: 0.9686 - val_loss: 0.0571 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05943 to 0.05708, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0897 - acc: 0.9715 - val_loss: 0.0576 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05708\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9688 - val_loss: 0.0560 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05708 to 0.05600, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0872 - acc: 0.9710 - val_loss: 0.0553 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05600 to 0.05528, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0839 - acc: 0.9693 - val_loss: 0.0539 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.05528 to 0.05387, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0882 - acc: 0.9696 - val_loss: 0.0565 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05387\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9727 - val_loss: 0.0535 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05387 to 0.05353, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0858 - acc: 0.9710 - val_loss: 0.0533 - val_acc: 0.9854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00101: val_loss improved from 0.05353 to 0.05333, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9761 - val_loss: 0.0513 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.05333 to 0.05127, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0741 - acc: 0.9735 - val_loss: 0.0503 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05127 to 0.05027, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0825 - acc: 0.9725 - val_loss: 0.0511 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05027\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9725 - val_loss: 0.0492 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05027 to 0.04924, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9752 - val_loss: 0.0491 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04924 to 0.04908, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9742 - val_loss: 0.0459 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04908 to 0.04585, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0744 - acc: 0.9744 - val_loss: 0.0459 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04585\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0751 - acc: 0.9747 - val_loss: 0.0466 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04585\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9769 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.04585 to 0.04463, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9757 - val_loss: 0.0436 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.04463 to 0.04363, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0744 - acc: 0.9752 - val_loss: 0.0437 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04363\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0687 - acc: 0.9754 - val_loss: 0.0514 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04363\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0697 - acc: 0.9759 - val_loss: 0.0464 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04363\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9783 - val_loss: 0.0448 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04363\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0680 - acc: 0.9744 - val_loss: 0.0429 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.04363 to 0.04292, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9749 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.04292 to 0.04066, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9730 - val_loss: 0.0410 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04066\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9810 - val_loss: 0.0401 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.04066 to 0.04010, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9761 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.04010 to 0.03976, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9749 - val_loss: 0.0376 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.03976 to 0.03763, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9795 - val_loss: 0.0372 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.03763 to 0.03724, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9771 - val_loss: 0.0369 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.03724 to 0.03689, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9766 - val_loss: 0.0357 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.03689 to 0.03571, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9803 - val_loss: 0.0357 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.03571 to 0.03566, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0607 - acc: 0.9793 - val_loss: 0.0343 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.03566 to 0.03434, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9791 - val_loss: 0.0350 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03434\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9791 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03434\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9774 - val_loss: 0.0330 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.03434 to 0.03299, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9808 - val_loss: 0.0329 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.03299 to 0.03286, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9774 - val_loss: 0.0331 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03286\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9798 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.03286 to 0.03173, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9830 - val_loss: 0.0317 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.03173 to 0.03169, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9820 - val_loss: 0.0336 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03169\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9810 - val_loss: 0.0304 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.03169 to 0.03045, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0573 - acc: 0.9805 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03045\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9774 - val_loss: 0.0287 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.03045 to 0.02874, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9793 - val_loss: 0.0275 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.02874 to 0.02751, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9834 - val_loss: 0.0277 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02751\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9798 - val_loss: 0.0301 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02751\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9813 - val_loss: 0.0267 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.02751 to 0.02669, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9827 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02669\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9781 - val_loss: 0.0262 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.02669 to 0.02622, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9832 - val_loss: 0.0259 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.02622 to 0.02592, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9822 - val_loss: 0.0251 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.02592 to 0.02515, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0507 - acc: 0.9791 - val_loss: 0.0243 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.02515 to 0.02430, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9844 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.02430 to 0.02348, saving model to best.model\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9822 - val_loss: 0.0236 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02348\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9827 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02348\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0458 - acc: 0.9847 - val_loss: 0.0223 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.02348 to 0.02235, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9805 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02235\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9825 - val_loss: 0.0228 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02235\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9851 - val_loss: 0.0227 - val_acc: 0.9942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02235\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9847 - val_loss: 0.0236 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02235\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9825 - val_loss: 0.0226 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02235\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 8s - loss: 0.7906 - acc: 0.5069 - val_loss: 0.6790 - val_acc: 0.5326\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67897, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7398 - acc: 0.5264 - val_loss: 0.6600 - val_acc: 0.7361\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67897 to 0.65999, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6980 - acc: 0.5637 - val_loss: 0.6189 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65999 to 0.61894, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6566 - acc: 0.6138 - val_loss: 0.5510 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61894 to 0.55105, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5911 - acc: 0.6913 - val_loss: 0.4727 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55105 to 0.47268, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5117 - acc: 0.7580 - val_loss: 0.4004 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47268 to 0.40044, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4620 - acc: 0.7952 - val_loss: 0.3608 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40044 to 0.36082, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4247 - acc: 0.8171 - val_loss: 0.3338 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36082 to 0.33379, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3991 - acc: 0.8395 - val_loss: 0.3130 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33379 to 0.31296, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3748 - acc: 0.8559 - val_loss: 0.2957 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31296 to 0.29568, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3584 - acc: 0.8622 - val_loss: 0.2821 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29568 to 0.28207, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3481 - acc: 0.8624 - val_loss: 0.2815 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28207 to 0.28155, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3337 - acc: 0.8688 - val_loss: 0.2637 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28155 to 0.26367, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3252 - acc: 0.8804 - val_loss: 0.2559 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26367 to 0.25591, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3133 - acc: 0.8831 - val_loss: 0.2584 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25591\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3183 - acc: 0.8802 - val_loss: 0.2441 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25591 to 0.24408, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3041 - acc: 0.8858 - val_loss: 0.2480 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24408\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3000 - acc: 0.8919 - val_loss: 0.2359 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24408 to 0.23592, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2809 - acc: 0.8990 - val_loss: 0.2300 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23592 to 0.22997, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2831 - acc: 0.8943 - val_loss: 0.2269 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22997 to 0.22689, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2776 - acc: 0.9011 - val_loss: 0.2237 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22689 to 0.22371, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2722 - acc: 0.9063 - val_loss: 0.2179 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22371 to 0.21792, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2741 - acc: 0.9019 - val_loss: 0.2183 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.21792\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2647 - acc: 0.9070 - val_loss: 0.2158 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21792 to 0.21580, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2616 - acc: 0.9080 - val_loss: 0.2107 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21580 to 0.21069, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2535 - acc: 0.9077 - val_loss: 0.2067 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21069 to 0.20672, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2513 - acc: 0.9099 - val_loss: 0.2028 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20672 to 0.20283, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2412 - acc: 0.9126 - val_loss: 0.1993 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20283 to 0.19931, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2439 - acc: 0.9148 - val_loss: 0.1964 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19931 to 0.19638, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2411 - acc: 0.9131 - val_loss: 0.1949 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19638 to 0.19491, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2416 - acc: 0.9138 - val_loss: 0.1937 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19491 to 0.19367, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.2382 - acc: 0.9136 - val_loss: 0.1865 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19367 to 0.18650, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2302 - acc: 0.9131 - val_loss: 0.1830 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18650 to 0.18298, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.2206 - acc: 0.9209 - val_loss: 0.1817 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18298 to 0.18173, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2240 - acc: 0.9165 - val_loss: 0.1771 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18173 to 0.17707, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2194 - acc: 0.9184 - val_loss: 0.1734 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17707 to 0.17337, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2140 - acc: 0.9194 - val_loss: 0.1720 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17337 to 0.17202, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2102 - acc: 0.9209 - val_loss: 0.1663 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17202 to 0.16628, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2101 - acc: 0.9155 - val_loss: 0.1632 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16628 to 0.16318, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2000 - acc: 0.9248 - val_loss: 0.1591 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16318 to 0.15906, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2009 - acc: 0.9262 - val_loss: 0.1548 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15906 to 0.15485, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1913 - acc: 0.9240 - val_loss: 0.1510 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15485 to 0.15100, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1948 - acc: 0.9252 - val_loss: 0.1463 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15100 to 0.14632, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1832 - acc: 0.9287 - val_loss: 0.1422 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14632 to 0.14224, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1869 - acc: 0.9296 - val_loss: 0.1378 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14224 to 0.13780, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1752 - acc: 0.9321 - val_loss: 0.1351 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13780 to 0.13508, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1741 - acc: 0.9372 - val_loss: 0.1298 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13508 to 0.12985, saving model to best.model\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1718 - acc: 0.9318 - val_loss: 0.1261 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12985 to 0.12613, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1689 - acc: 0.9372 - val_loss: 0.1269 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.12613\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1624 - acc: 0.9391 - val_loss: 0.1212 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12613 to 0.12119, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1660 - acc: 0.9399 - val_loss: 0.1162 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12119 to 0.11618, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1493 - acc: 0.9425 - val_loss: 0.1132 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11618 to 0.11316, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1562 - acc: 0.9406 - val_loss: 0.1120 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11316 to 0.11204, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1484 - acc: 0.9442 - val_loss: 0.1106 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11204 to 0.11057, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1486 - acc: 0.9433 - val_loss: 0.1063 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11057 to 0.10631, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1478 - acc: 0.9433 - val_loss: 0.1027 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10631 to 0.10272, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1451 - acc: 0.9438 - val_loss: 0.1010 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10272 to 0.10100, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1398 - acc: 0.9486 - val_loss: 0.0988 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10100 to 0.09878, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1336 - acc: 0.9477 - val_loss: 0.0959 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09878 to 0.09586, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1352 - acc: 0.9479 - val_loss: 0.0928 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09586 to 0.09278, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9501 - val_loss: 0.0914 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09278 to 0.09137, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9545 - val_loss: 0.0887 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09137 to 0.08869, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1276 - acc: 0.9503 - val_loss: 0.0887 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08869 to 0.08867, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1275 - acc: 0.9503 - val_loss: 0.0847 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08867 to 0.08465, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1225 - acc: 0.9523 - val_loss: 0.0821 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08465 to 0.08206, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9513 - val_loss: 0.0816 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08206 to 0.08162, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9586 - val_loss: 0.0796 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08162 to 0.07963, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1158 - acc: 0.9554 - val_loss: 0.0767 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07963 to 0.07671, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1167 - acc: 0.9589 - val_loss: 0.0757 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07671 to 0.07570, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1169 - acc: 0.9547 - val_loss: 0.0722 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07570 to 0.07221, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1044 - acc: 0.9584 - val_loss: 0.0710 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07221 to 0.07100, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9581 - val_loss: 0.0683 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07100 to 0.06828, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9564 - val_loss: 0.0659 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06828 to 0.06593, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1023 - acc: 0.9598 - val_loss: 0.0640 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06593 to 0.06400, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9640 - val_loss: 0.0646 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06400\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1008 - acc: 0.9618 - val_loss: 0.0616 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06400 to 0.06164, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0989 - acc: 0.9610 - val_loss: 0.0615 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06164 to 0.06147, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0943 - acc: 0.9642 - val_loss: 0.0588 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06147 to 0.05881, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9652 - val_loss: 0.0570 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05881 to 0.05705, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9671 - val_loss: 0.0554 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05705 to 0.05544, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0947 - acc: 0.9623 - val_loss: 0.0555 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05544\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9645 - val_loss: 0.0547 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05544 to 0.05467, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9696 - val_loss: 0.0514 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05467 to 0.05137, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0917 - acc: 0.9640 - val_loss: 0.0505 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05137 to 0.05055, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9710 - val_loss: 0.0501 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05055 to 0.05007, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9652 - val_loss: 0.0488 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05007 to 0.04879, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9681 - val_loss: 0.0483 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04879 to 0.04832, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0889 - acc: 0.9671 - val_loss: 0.0470 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04832 to 0.04697, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9735 - val_loss: 0.0461 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04697 to 0.04610, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0769 - acc: 0.9710 - val_loss: 0.0448 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04610 to 0.04479, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9732 - val_loss: 0.0448 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04479\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9708 - val_loss: 0.0420 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04479 to 0.04202, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9732 - val_loss: 0.0412 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04202 to 0.04123, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9730 - val_loss: 0.0413 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04123\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0691 - acc: 0.9754 - val_loss: 0.0411 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04123 to 0.04114, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0705 - acc: 0.9727 - val_loss: 0.0378 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04114 to 0.03775, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9771 - val_loss: 0.0370 - val_acc: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_loss improved from 0.03775 to 0.03702, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9742 - val_loss: 0.0376 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03702\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9701 - val_loss: 0.0368 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03702 to 0.03675, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9744 - val_loss: 0.0353 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03675 to 0.03532, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9708 - val_loss: 0.0340 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03532 to 0.03398, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9754 - val_loss: 0.0367 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03398\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0634 - acc: 0.9735 - val_loss: 0.0345 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03398\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0613 - acc: 0.9771 - val_loss: 0.0327 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03398 to 0.03274, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0618 - acc: 0.9757 - val_loss: 0.0328 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03274\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0586 - acc: 0.9791 - val_loss: 0.0292 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03274 to 0.02916, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9764 - val_loss: 0.0332 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02916\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9735 - val_loss: 0.0309 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02916\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9754 - val_loss: 0.0327 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02916\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9744 - val_loss: 0.0289 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02916 to 0.02890, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9803 - val_loss: 0.0324 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02890\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9795 - val_loss: 0.0279 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02890 to 0.02786, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9825 - val_loss: 0.0305 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02786\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9771 - val_loss: 0.0269 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02786 to 0.02687, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9776 - val_loss: 0.0253 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02687 to 0.02534, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9800 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02534 to 0.02357, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9795 - val_loss: 0.0248 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02357\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9817 - val_loss: 0.0270 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02357\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0474 - acc: 0.9820 - val_loss: 0.0248 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02357\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9810 - val_loss: 0.0224 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02357 to 0.02237, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0528 - acc: 0.9771 - val_loss: 0.0234 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02237\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9788 - val_loss: 0.0258 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02237\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9808 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02237\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9800 - val_loss: 0.0217 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.02237 to 0.02167, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9817 - val_loss: 0.0231 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02167\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9854 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02167 to 0.02163, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0467 - acc: 0.9817 - val_loss: 0.0183 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02163 to 0.01828, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9825 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01828\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9859 - val_loss: 0.0204 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01828\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9851 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01828\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9825 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01828\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9820 - val_loss: 0.0193 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01828\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.8173 - acc: 0.4955 - val_loss: 0.6689 - val_acc: 0.5316\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66890, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7377 - acc: 0.5374 - val_loss: 0.6435 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66890 to 0.64354, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6962 - acc: 0.5693 - val_loss: 0.5968 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64354 to 0.59681, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6403 - acc: 0.6353 - val_loss: 0.5258 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59681 to 0.52580, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5743 - acc: 0.7044 - val_loss: 0.4464 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52580 to 0.44637, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5135 - acc: 0.7546 - val_loss: 0.3940 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44637 to 0.39396, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4636 - acc: 0.7947 - val_loss: 0.3640 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39396 to 0.36401, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4496 - acc: 0.8052 - val_loss: 0.3368 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36401 to 0.33681, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4165 - acc: 0.8283 - val_loss: 0.3172 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33681 to 0.31719, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3992 - acc: 0.8320 - val_loss: 0.2981 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31719 to 0.29807, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3870 - acc: 0.8439 - val_loss: 0.2840 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29807 to 0.28397, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3658 - acc: 0.8556 - val_loss: 0.2710 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28397 to 0.27097, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3423 - acc: 0.8605 - val_loss: 0.2570 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27097 to 0.25695, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3446 - acc: 0.8671 - val_loss: 0.2455 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25695 to 0.24549, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.3259 - acc: 0.8717 - val_loss: 0.2389 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24549 to 0.23893, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.3159 - acc: 0.8785 - val_loss: 0.2326 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.23893 to 0.23263, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.3081 - acc: 0.8748 - val_loss: 0.2212 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23263 to 0.22121, saving model to best.model\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3023 - acc: 0.8846 - val_loss: 0.2179 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22121 to 0.21793, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.2873 - acc: 0.8902 - val_loss: 0.2104 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.21793 to 0.21039, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.2863 - acc: 0.8931 - val_loss: 0.2096 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21039 to 0.20965, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.2837 - acc: 0.8985 - val_loss: 0.2017 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.20965 to 0.20170, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.2758 - acc: 0.8975 - val_loss: 0.1991 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.20170 to 0.19913, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2695 - acc: 0.9026 - val_loss: 0.1970 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.19913 to 0.19704, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2720 - acc: 0.9004 - val_loss: 0.1970 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19704 to 0.19700, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2612 - acc: 0.9011 - val_loss: 0.1907 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19700 to 0.19070, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.2592 - acc: 0.9028 - val_loss: 0.1887 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19070 to 0.18870, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.2475 - acc: 0.9109 - val_loss: 0.1897 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.18870\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2510 - acc: 0.9084 - val_loss: 0.1846 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18870 to 0.18460, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.2478 - acc: 0.9072 - val_loss: 0.1793 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.18460 to 0.17933, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.2407 - acc: 0.9094 - val_loss: 0.1818 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17933\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.2457 - acc: 0.9070 - val_loss: 0.1748 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17933 to 0.17476, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2348 - acc: 0.9119 - val_loss: 0.1741 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17476 to 0.17413, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2290 - acc: 0.9177 - val_loss: 0.1731 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17413 to 0.17311, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.2244 - acc: 0.9160 - val_loss: 0.1668 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17311 to 0.16680, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2304 - acc: 0.9155 - val_loss: 0.1637 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16680 to 0.16374, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.2147 - acc: 0.9231 - val_loss: 0.1637 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16374 to 0.16371, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.2208 - acc: 0.9209 - val_loss: 0.1601 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16371 to 0.16011, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2153 - acc: 0.9184 - val_loss: 0.1570 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16011 to 0.15701, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2130 - acc: 0.9228 - val_loss: 0.1586 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15701\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.2047 - acc: 0.9299 - val_loss: 0.1533 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15701 to 0.15330, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.2070 - acc: 0.9260 - val_loss: 0.1499 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15330 to 0.14995, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9270 - val_loss: 0.1477 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14995 to 0.14774, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1961 - acc: 0.9282 - val_loss: 0.1429 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14774 to 0.14287, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.1905 - acc: 0.9294 - val_loss: 0.1406 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14287 to 0.14062, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.1895 - acc: 0.9294 - val_loss: 0.1367 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14062 to 0.13671, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1801 - acc: 0.9301 - val_loss: 0.1349 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13671 to 0.13486, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1826 - acc: 0.9360 - val_loss: 0.1285 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13486 to 0.12853, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1754 - acc: 0.9321 - val_loss: 0.1252 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12853 to 0.12519, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.1764 - acc: 0.9350 - val_loss: 0.1214 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12519 to 0.12142, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1717 - acc: 0.9408 - val_loss: 0.1178 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12142 to 0.11775, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1669 - acc: 0.9347 - val_loss: 0.1150 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11775 to 0.11503, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.1685 - acc: 0.9374 - val_loss: 0.1142 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11503 to 0.11418, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1563 - acc: 0.9425 - val_loss: 0.1099 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11418 to 0.10989, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9408 - val_loss: 0.1059 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10989 to 0.10587, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1591 - acc: 0.9438 - val_loss: 0.1009 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10587 to 0.10094, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1442 - acc: 0.9464 - val_loss: 0.1026 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10094\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1595 - acc: 0.9435 - val_loss: 0.0971 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10094 to 0.09708, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.1438 - acc: 0.9481 - val_loss: 0.0944 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09708 to 0.09436, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.1401 - acc: 0.9474 - val_loss: 0.0897 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09436 to 0.08973, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.1422 - acc: 0.9481 - val_loss: 0.0845 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08973 to 0.08449, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.1330 - acc: 0.9496 - val_loss: 0.0820 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08449 to 0.08203, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.1358 - acc: 0.9484 - val_loss: 0.0795 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08203 to 0.07948, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.1402 - acc: 0.9469 - val_loss: 0.0786 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.07948 to 0.07861, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.1338 - acc: 0.9513 - val_loss: 0.0753 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07861 to 0.07529, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.1320 - acc: 0.9515 - val_loss: 0.0736 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07529 to 0.07362, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.1304 - acc: 0.9489 - val_loss: 0.0689 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07362 to 0.06894, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1274 - acc: 0.9554 - val_loss: 0.0667 - val_acc: 0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_loss improved from 0.06894 to 0.06667, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9550 - val_loss: 0.0659 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06667 to 0.06585, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1206 - acc: 0.9518 - val_loss: 0.0635 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06585 to 0.06349, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.1233 - acc: 0.9537 - val_loss: 0.0638 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06349\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.1158 - acc: 0.9547 - val_loss: 0.0610 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06349 to 0.06100, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.1102 - acc: 0.9584 - val_loss: 0.0570 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06100 to 0.05705, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.1149 - acc: 0.9603 - val_loss: 0.0551 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05705 to 0.05509, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.1065 - acc: 0.9601 - val_loss: 0.0534 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05509 to 0.05338, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1045 - acc: 0.9576 - val_loss: 0.0527 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05338 to 0.05271, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.1055 - acc: 0.9598 - val_loss: 0.0501 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05271 to 0.05008, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.1090 - acc: 0.9586 - val_loss: 0.0524 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05008\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.1047 - acc: 0.9603 - val_loss: 0.0477 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05008 to 0.04768, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0964 - acc: 0.9635 - val_loss: 0.0447 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04768 to 0.04475, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.1011 - acc: 0.9623 - val_loss: 0.0461 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04475\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0945 - acc: 0.9645 - val_loss: 0.0432 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04475 to 0.04316, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.1037 - acc: 0.9608 - val_loss: 0.0417 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04316 to 0.04172, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0993 - acc: 0.9635 - val_loss: 0.0404 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04172 to 0.04038, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0909 - acc: 0.9679 - val_loss: 0.0405 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04038\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1004 - acc: 0.9627 - val_loss: 0.0409 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04038\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9683 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04038 to 0.03658, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9693 - val_loss: 0.0377 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03658\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0896 - acc: 0.9671 - val_loss: 0.0367 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03658\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0843 - acc: 0.9683 - val_loss: 0.0340 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03658 to 0.03400, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9691 - val_loss: 0.0343 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03400\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9676 - val_loss: 0.0347 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03400\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0779 - acc: 0.9720 - val_loss: 0.0335 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03400 to 0.03346, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0865 - acc: 0.9698 - val_loss: 0.0320 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03346 to 0.03198, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0836 - acc: 0.9674 - val_loss: 0.0300 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03198 to 0.03003, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0789 - acc: 0.9698 - val_loss: 0.0290 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03003 to 0.02901, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0816 - acc: 0.9715 - val_loss: 0.0282 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.02901 to 0.02818, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9735 - val_loss: 0.0279 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02818 to 0.02794, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9686 - val_loss: 0.0271 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02794 to 0.02707, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0734 - acc: 0.9720 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.02707 to 0.02620, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0688 - acc: 0.9754 - val_loss: 0.0244 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02620 to 0.02444, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0719 - acc: 0.9713 - val_loss: 0.0235 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.02444 to 0.02355, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0779 - acc: 0.9696 - val_loss: 0.0252 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02355\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0850 - acc: 0.9708 - val_loss: 0.0311 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02355\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0752 - acc: 0.9703 - val_loss: 0.0243 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02355\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9674 - val_loss: 0.0230 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02355 to 0.02298, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0724 - acc: 0.9749 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02298\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0707 - acc: 0.9747 - val_loss: 0.0238 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02298\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0706 - acc: 0.9718 - val_loss: 0.0221 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02298 to 0.02211, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0664 - acc: 0.9757 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02211 to 0.02026, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0601 - acc: 0.9774 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02026 to 0.01987, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9749 - val_loss: 0.0189 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.01987 to 0.01890, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0630 - acc: 0.9769 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01890\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9744 - val_loss: 0.0181 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.01890 to 0.01811, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9778 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01811\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9798 - val_loss: 0.0237 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01811\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0801 - acc: 0.9693 - val_loss: 0.0205 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.01811\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0578 - acc: 0.9791 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01811 to 0.01797, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0586 - acc: 0.9815 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01797\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0663 - acc: 0.9739 - val_loss: 0.0182 - val_acc: 0.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01797\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0621 - acc: 0.9764 - val_loss: 0.0185 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01797\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0626 - acc: 0.9774 - val_loss: 0.0158 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01797 to 0.01581, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9817 - val_loss: 0.0155 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01581 to 0.01550, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9791 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01550\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9800 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01550 to 0.01518, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0496 - acc: 0.9793 - val_loss: 0.0149 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01518 to 0.01485, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0459 - acc: 0.9825 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01485 to 0.01391, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0562 - acc: 0.9795 - val_loss: 0.0135 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01391 to 0.01354, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9803 - val_loss: 0.0134 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01354 to 0.01339, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9781 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01339\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9820 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01339 to 0.01269, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9798 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01269 to 0.01247, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0550 - acc: 0.9781 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01247 to 0.01215, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0431 - acc: 0.9830 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01215 to 0.01178, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0411 - acc: 0.9861 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01178 to 0.01134, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9832 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01134 to 0.01101, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9827 - val_loss: 0.0105 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01101 to 0.01053, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0466 - acc: 0.9815 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01053\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0444 - acc: 0.9842 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01053 to 0.00991, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0415 - acc: 0.9861 - val_loss: 0.0097 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00991 to 0.00970, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0383 - acc: 0.9849 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00970\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0451 - acc: 0.9832 - val_loss: 0.0103 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00970\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0374 - acc: 0.9866 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00970 to 0.00933, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0426 - acc: 0.9844 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00933\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9888 - val_loss: 0.0084 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00933 to 0.00838, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0401 - acc: 0.9861 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00838\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9830 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00838\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9813 - val_loss: 0.0103 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00838\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9842 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00838\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9817 - val_loss: 0.0089 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00838\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 10s - loss: 0.8027 - acc: 0.5123 - val_loss: 0.6669 - val_acc: 0.5355\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66688, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.7431 - acc: 0.5298 - val_loss: 0.6351 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66688 to 0.63507, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.6890 - acc: 0.5873 - val_loss: 0.5850 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63507 to 0.58499, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.6283 - acc: 0.6518 - val_loss: 0.5118 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58499 to 0.51180, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.5493 - acc: 0.7431 - val_loss: 0.4420 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51180 to 0.44204, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4895 - acc: 0.7857 - val_loss: 0.3963 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44204 to 0.39629, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4570 - acc: 0.8018 - val_loss: 0.3674 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39629 to 0.36735, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4435 - acc: 0.8191 - val_loss: 0.3462 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36735 to 0.34625, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4103 - acc: 0.8296 - val_loss: 0.3270 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34625 to 0.32696, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3885 - acc: 0.8478 - val_loss: 0.3121 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32696 to 0.31206, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3620 - acc: 0.8580 - val_loss: 0.3085 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31206 to 0.30847, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3559 - acc: 0.8590 - val_loss: 0.2870 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30847 to 0.28696, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3426 - acc: 0.8685 - val_loss: 0.2774 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28696 to 0.27737, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3260 - acc: 0.8727 - val_loss: 0.2706 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27737 to 0.27063, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3153 - acc: 0.8773 - val_loss: 0.2611 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27063 to 0.26109, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.3040 - acc: 0.8851 - val_loss: 0.2596 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26109 to 0.25961, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3028 - acc: 0.8899 - val_loss: 0.2436 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25961 to 0.24362, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3016 - acc: 0.8878 - val_loss: 0.2390 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24362 to 0.23905, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.2846 - acc: 0.8938 - val_loss: 0.2346 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23905 to 0.23464, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2744 - acc: 0.8963 - val_loss: 0.2290 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23464 to 0.22897, saving model to best.model\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2666 - acc: 0.9002 - val_loss: 0.2253 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22897 to 0.22528, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2597 - acc: 0.9038 - val_loss: 0.2179 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22528 to 0.21794, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.2561 - acc: 0.9063 - val_loss: 0.2113 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21794 to 0.21127, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2442 - acc: 0.9138 - val_loss: 0.2112 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21127 to 0.21116, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2545 - acc: 0.9053 - val_loss: 0.2026 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21116 to 0.20260, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2475 - acc: 0.9126 - val_loss: 0.1998 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20260 to 0.19982, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2453 - acc: 0.9099 - val_loss: 0.2011 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.19982\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2374 - acc: 0.9150 - val_loss: 0.1931 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19982 to 0.19309, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2317 - acc: 0.9177 - val_loss: 0.1850 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19309 to 0.18504, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2365 - acc: 0.9143 - val_loss: 0.1831 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18504 to 0.18306, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2312 - acc: 0.9211 - val_loss: 0.1797 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.18306 to 0.17967, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2291 - acc: 0.9140 - val_loss: 0.1749 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17967 to 0.17488, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2207 - acc: 0.9196 - val_loss: 0.1703 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17488 to 0.17029, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2130 - acc: 0.9196 - val_loss: 0.1663 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17029 to 0.16635, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2167 - acc: 0.9206 - val_loss: 0.1675 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16635\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2100 - acc: 0.9228 - val_loss: 0.1587 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16635 to 0.15867, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1967 - acc: 0.9279 - val_loss: 0.1599 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15867\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2011 - acc: 0.9272 - val_loss: 0.1589 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15867\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9262 - val_loss: 0.1497 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15867 to 0.14968, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1956 - acc: 0.9248 - val_loss: 0.1448 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14968 to 0.14484, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1905 - acc: 0.9304 - val_loss: 0.1406 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14484 to 0.14061, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9226 - val_loss: 0.1585 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14061\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1940 - acc: 0.9287 - val_loss: 0.1333 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14061 to 0.13329, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1809 - acc: 0.9355 - val_loss: 0.1305 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13329 to 0.13047, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1752 - acc: 0.9343 - val_loss: 0.1282 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13047 to 0.12823, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9308 - val_loss: 0.1251 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12823 to 0.12514, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1781 - acc: 0.9343 - val_loss: 0.1226 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12514 to 0.12259, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1761 - acc: 0.9335 - val_loss: 0.1224 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12259 to 0.12237, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9362 - val_loss: 0.1162 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12237 to 0.11623, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1651 - acc: 0.9360 - val_loss: 0.1124 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11623 to 0.11239, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1623 - acc: 0.9391 - val_loss: 0.1094 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11239 to 0.10940, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1587 - acc: 0.9403 - val_loss: 0.1068 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10940 to 0.10682, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1573 - acc: 0.9423 - val_loss: 0.1036 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10682 to 0.10362, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1550 - acc: 0.9421 - val_loss: 0.1005 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10362 to 0.10052, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9445 - val_loss: 0.0972 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10052 to 0.09716, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1458 - acc: 0.9430 - val_loss: 0.0946 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.09716 to 0.09460, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1424 - acc: 0.9472 - val_loss: 0.0911 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09460 to 0.09108, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1486 - acc: 0.9462 - val_loss: 0.0927 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.09108\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.1390 - acc: 0.9472 - val_loss: 0.0863 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09108 to 0.08632, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1412 - acc: 0.9467 - val_loss: 0.0842 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08632 to 0.08421, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.1320 - acc: 0.9498 - val_loss: 0.0831 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08421 to 0.08305, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1367 - acc: 0.9486 - val_loss: 0.0808 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08305 to 0.08077, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1379 - acc: 0.9479 - val_loss: 0.0786 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08077 to 0.07855, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1231 - acc: 0.9552 - val_loss: 0.0766 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07855 to 0.07664, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1263 - acc: 0.9545 - val_loss: 0.0748 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07664 to 0.07482, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1216 - acc: 0.9530 - val_loss: 0.0717 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07482 to 0.07165, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1267 - acc: 0.9506 - val_loss: 0.0697 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07165 to 0.06966, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1249 - acc: 0.9542 - val_loss: 0.0684 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06966 to 0.06845, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1103 - acc: 0.9581 - val_loss: 0.0684 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06845 to 0.06839, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1221 - acc: 0.9564 - val_loss: 0.0646 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06839 to 0.06457, saving model to best.model\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1143 - acc: 0.9581 - val_loss: 0.0633 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06457 to 0.06331, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1118 - acc: 0.9564 - val_loss: 0.0613 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06331 to 0.06128, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1093 - acc: 0.9574 - val_loss: 0.0596 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06128 to 0.05961, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1139 - acc: 0.9542 - val_loss: 0.0608 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05961\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1053 - acc: 0.9569 - val_loss: 0.0580 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05961 to 0.05804, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1131 - acc: 0.9562 - val_loss: 0.0616 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05804\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9608 - val_loss: 0.0566 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05804 to 0.05663, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9630 - val_loss: 0.0536 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05663 to 0.05360, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0904 - acc: 0.9625 - val_loss: 0.0511 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05360 to 0.05114, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0984 - acc: 0.9603 - val_loss: 0.0495 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05114 to 0.04954, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0944 - acc: 0.9657 - val_loss: 0.0490 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04954 to 0.04898, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9620 - val_loss: 0.0468 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04898 to 0.04680, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0895 - acc: 0.9679 - val_loss: 0.0450 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04680 to 0.04499, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0944 - acc: 0.9657 - val_loss: 0.0438 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04499 to 0.04376, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0824 - acc: 0.9674 - val_loss: 0.0421 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04376 to 0.04208, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9681 - val_loss: 0.0406 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04208 to 0.04061, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9676 - val_loss: 0.0392 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04061 to 0.03921, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9701 - val_loss: 0.0381 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03921 to 0.03815, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9698 - val_loss: 0.0377 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03815 to 0.03773, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9681 - val_loss: 0.0370 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03773 to 0.03704, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9652 - val_loss: 0.0373 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03704\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0832 - acc: 0.9696 - val_loss: 0.0359 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03704 to 0.03585, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9688 - val_loss: 0.0359 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03585\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0760 - acc: 0.9720 - val_loss: 0.0325 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03585 to 0.03249, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0780 - acc: 0.9703 - val_loss: 0.0332 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03249\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9747 - val_loss: 0.0314 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03249 to 0.03144, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9703 - val_loss: 0.0304 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03144 to 0.03044, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9766 - val_loss: 0.0310 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03044\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0724 - acc: 0.9735 - val_loss: 0.0289 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03044 to 0.02892, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9754 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02892 to 0.02856, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9705 - val_loss: 0.0287 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02856\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9761 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02856\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9739 - val_loss: 0.0273 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02856 to 0.02728, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9722 - val_loss: 0.0323 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02728\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9761 - val_loss: 0.0274 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02728\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0663 - acc: 0.9730 - val_loss: 0.0268 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02728 to 0.02678, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9744 - val_loss: 0.0284 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02678\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9749 - val_loss: 0.0250 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02678 to 0.02501, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0585 - acc: 0.9774 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02501 to 0.02461, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9747 - val_loss: 0.0261 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02461\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0565 - acc: 0.9781 - val_loss: 0.0232 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02461 to 0.02323, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9817 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02323 to 0.02292, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0618 - acc: 0.9783 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02292 to 0.02259, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9752 - val_loss: 0.0231 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02259\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9764 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02259 to 0.02192, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9813 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02192 to 0.02155, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9813 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02155\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9805 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02155 to 0.02060, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9808 - val_loss: 0.0229 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02060\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9800 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02060 to 0.01972, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0504 - acc: 0.9813 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01972\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9786 - val_loss: 0.0188 - val_acc: 0.9942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: val_loss improved from 0.01972 to 0.01880, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9759 - val_loss: 0.0230 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01880\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9817 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01880\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0488 - acc: 0.9810 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01880\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9798 - val_loss: 0.0195 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01880\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9822 - val_loss: 0.0179 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01880 to 0.01789, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9827 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01789 to 0.01774, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9827 - val_loss: 0.0176 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01774 to 0.01756, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9817 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01756\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9778 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01756 to 0.01741, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9817 - val_loss: 0.0184 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01741\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0444 - acc: 0.9827 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01741\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9842 - val_loss: 0.0156 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01741 to 0.01558, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0526 - acc: 0.9800 - val_loss: 0.0155 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01558 to 0.01547, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9825 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01547\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9839 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01547 to 0.01539, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9820 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01539\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9842 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01539\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9837 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01539\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9851 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01539 to 0.01463, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0395 - acc: 0.9859 - val_loss: 0.0171 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01463\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9832 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01463 to 0.01426, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0398 - acc: 0.9873 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01426\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9810 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01426\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9881 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01426 to 0.01386, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0388 - acc: 0.9864 - val_loss: 0.0168 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01386\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0366 - acc: 0.9881 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01386 to 0.01264, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0361 - acc: 0.9847 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01264\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9844 - val_loss: 0.0168 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01264\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9837 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01264\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0366 - acc: 0.9866 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01264\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0346 - acc: 0.9866 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01264\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 8s - loss: 0.7741 - acc: 0.5291 - val_loss: 0.6636 - val_acc: 0.7975\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66360, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7306 - acc: 0.5371 - val_loss: 0.6338 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66360 to 0.63378, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6756 - acc: 0.5953 - val_loss: 0.5792 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63378 to 0.57923, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6117 - acc: 0.6674 - val_loss: 0.5036 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57923 to 0.50364, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5394 - acc: 0.7280 - val_loss: 0.4406 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50364 to 0.44056, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4820 - acc: 0.7855 - val_loss: 0.3959 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44056 to 0.39594, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4627 - acc: 0.8018 - val_loss: 0.3698 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39594 to 0.36976, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4232 - acc: 0.8215 - val_loss: 0.3471 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36976 to 0.34713, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3990 - acc: 0.8303 - val_loss: 0.3275 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34713 to 0.32750, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3772 - acc: 0.8481 - val_loss: 0.3129 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32750 to 0.31288, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3729 - acc: 0.8488 - val_loss: 0.2964 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31288 to 0.29641, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3579 - acc: 0.8571 - val_loss: 0.2849 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29641 to 0.28486, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3408 - acc: 0.8615 - val_loss: 0.2767 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28486 to 0.27669, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3322 - acc: 0.8688 - val_loss: 0.2644 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27669 to 0.26444, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3156 - acc: 0.8710 - val_loss: 0.2560 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26444 to 0.25595, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3134 - acc: 0.8783 - val_loss: 0.2526 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25595 to 0.25265, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3041 - acc: 0.8856 - val_loss: 0.2472 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25265 to 0.24722, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2973 - acc: 0.8907 - val_loss: 0.2408 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24722 to 0.24081, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2931 - acc: 0.8875 - val_loss: 0.2342 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24081 to 0.23423, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2795 - acc: 0.8914 - val_loss: 0.2305 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23423 to 0.23047, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2772 - acc: 0.8926 - val_loss: 0.2280 - val_acc: 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: val_loss improved from 0.23047 to 0.22800, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2721 - acc: 0.8972 - val_loss: 0.2212 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22800 to 0.22125, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2630 - acc: 0.8965 - val_loss: 0.2174 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22125 to 0.21744, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2624 - acc: 0.9050 - val_loss: 0.2161 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21744 to 0.21614, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2788 - acc: 0.8929 - val_loss: 0.2218 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.21614\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2503 - acc: 0.9094 - val_loss: 0.2084 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21614 to 0.20841, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2520 - acc: 0.9016 - val_loss: 0.2057 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20841 to 0.20574, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2463 - acc: 0.9082 - val_loss: 0.2038 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20574 to 0.20379, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2418 - acc: 0.9104 - val_loss: 0.2010 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20379 to 0.20102, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2323 - acc: 0.9106 - val_loss: 0.1985 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20102 to 0.19850, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2381 - acc: 0.9092 - val_loss: 0.1968 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19850 to 0.19681, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2361 - acc: 0.9119 - val_loss: 0.1943 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19681 to 0.19427, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2334 - acc: 0.9123 - val_loss: 0.1919 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19427 to 0.19194, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2246 - acc: 0.9189 - val_loss: 0.1917 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19194 to 0.19171, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2222 - acc: 0.9153 - val_loss: 0.1858 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19171 to 0.18576, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2193 - acc: 0.9143 - val_loss: 0.1840 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18576 to 0.18405, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2241 - acc: 0.9145 - val_loss: 0.1821 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18405 to 0.18212, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2118 - acc: 0.9214 - val_loss: 0.1793 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18212 to 0.17932, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2108 - acc: 0.9194 - val_loss: 0.1777 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17932 to 0.17768, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2057 - acc: 0.9206 - val_loss: 0.1740 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17768 to 0.17398, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2115 - acc: 0.9196 - val_loss: 0.1714 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17398 to 0.17140, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2052 - acc: 0.9255 - val_loss: 0.1684 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17140 to 0.16843, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1980 - acc: 0.9274 - val_loss: 0.1656 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16843 to 0.16556, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1964 - acc: 0.9287 - val_loss: 0.1621 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16556 to 0.16207, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1997 - acc: 0.9182 - val_loss: 0.1593 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16207 to 0.15927, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9294 - val_loss: 0.1574 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15927 to 0.15738, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1839 - acc: 0.9294 - val_loss: 0.1537 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15738 to 0.15366, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9306 - val_loss: 0.1498 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15366 to 0.14975, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1821 - acc: 0.9367 - val_loss: 0.1488 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14975 to 0.14877, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1777 - acc: 0.9345 - val_loss: 0.1439 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14877 to 0.14391, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1704 - acc: 0.9379 - val_loss: 0.1402 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14391 to 0.14023, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1681 - acc: 0.9386 - val_loss: 0.1374 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14023 to 0.13739, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1707 - acc: 0.9338 - val_loss: 0.1338 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13739 to 0.13377, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1620 - acc: 0.9389 - val_loss: 0.1344 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.13377\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1595 - acc: 0.9384 - val_loss: 0.1290 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13377 to 0.12904, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1589 - acc: 0.9367 - val_loss: 0.1257 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12904 to 0.12572, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1565 - acc: 0.9418 - val_loss: 0.1229 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12572 to 0.12294, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1552 - acc: 0.9403 - val_loss: 0.1195 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12294 to 0.11946, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1547 - acc: 0.9408 - val_loss: 0.1178 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11946 to 0.11780, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1470 - acc: 0.9445 - val_loss: 0.1134 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11780 to 0.11336, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1441 - acc: 0.9440 - val_loss: 0.1107 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11336 to 0.11070, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1478 - acc: 0.9408 - val_loss: 0.1078 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11070 to 0.10782, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1352 - acc: 0.9496 - val_loss: 0.1045 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10782 to 0.10448, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1425 - acc: 0.9462 - val_loss: 0.1034 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10448 to 0.10336, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9481 - val_loss: 0.1038 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10336\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9506 - val_loss: 0.0972 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10336 to 0.09724, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1336 - acc: 0.9491 - val_loss: 0.0945 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09724 to 0.09451, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1309 - acc: 0.9506 - val_loss: 0.0941 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09451 to 0.09413, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1307 - acc: 0.9503 - val_loss: 0.0901 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09413 to 0.09013, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9508 - val_loss: 0.0876 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09013 to 0.08756, saving model to best.model\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1212 - acc: 0.9525 - val_loss: 0.0844 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08756 to 0.08443, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1158 - acc: 0.9542 - val_loss: 0.0832 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08443 to 0.08315, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1189 - acc: 0.9513 - val_loss: 0.0813 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08315 to 0.08126, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1168 - acc: 0.9567 - val_loss: 0.0786 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08126 to 0.07857, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1185 - acc: 0.9550 - val_loss: 0.0764 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07857 to 0.07642, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9569 - val_loss: 0.0765 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07642\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1072 - acc: 0.9571 - val_loss: 0.0716 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07642 to 0.07158, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1070 - acc: 0.9567 - val_loss: 0.0717 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07158\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1009 - acc: 0.9608 - val_loss: 0.0768 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07158\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1008 - acc: 0.9606 - val_loss: 0.0702 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07158 to 0.07025, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1128 - acc: 0.9552 - val_loss: 0.0690 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07025 to 0.06899, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1037 - acc: 0.9596 - val_loss: 0.0677 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06899 to 0.06769, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9625 - val_loss: 0.0648 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06769 to 0.06481, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0966 - acc: 0.9691 - val_loss: 0.0679 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06481\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0997 - acc: 0.9623 - val_loss: 0.0605 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06481 to 0.06045, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9645 - val_loss: 0.0614 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06045\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9635 - val_loss: 0.0582 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06045 to 0.05817, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0989 - acc: 0.9606 - val_loss: 0.0579 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05817 to 0.05788, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0924 - acc: 0.9647 - val_loss: 0.0557 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05788 to 0.05567, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9649 - val_loss: 0.0579 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05567\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0937 - acc: 0.9654 - val_loss: 0.0546 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05567 to 0.05460, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9666 - val_loss: 0.0532 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05460 to 0.05318, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0860 - acc: 0.9693 - val_loss: 0.0527 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05318 to 0.05271, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9693 - val_loss: 0.0494 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05271 to 0.04944, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0885 - acc: 0.9657 - val_loss: 0.0529 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04944\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9691 - val_loss: 0.0471 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04944 to 0.04707, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0810 - acc: 0.9671 - val_loss: 0.0485 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04707\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0799 - acc: 0.9686 - val_loss: 0.0459 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04707 to 0.04595, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9710 - val_loss: 0.0431 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04595 to 0.04315, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0760 - acc: 0.9708 - val_loss: 0.0419 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04315 to 0.04194, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9671 - val_loss: 0.0464 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04194\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9664 - val_loss: 0.0413 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04194 to 0.04127, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0704 - acc: 0.9749 - val_loss: 0.0435 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04127\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0774 - acc: 0.9688 - val_loss: 0.0407 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04127 to 0.04065, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0804 - acc: 0.9693 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.04065 to 0.03754, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0670 - acc: 0.9749 - val_loss: 0.0368 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03754 to 0.03682, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9679 - val_loss: 0.0356 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03682 to 0.03563, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0718 - acc: 0.9720 - val_loss: 0.0335 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03563 to 0.03354, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9761 - val_loss: 0.0353 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03354\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0632 - acc: 0.9776 - val_loss: 0.0344 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03354\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9778 - val_loss: 0.0333 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03354 to 0.03326, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0673 - acc: 0.9744 - val_loss: 0.0339 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03326\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0642 - acc: 0.9757 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03326 to 0.03176, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9730 - val_loss: 0.0316 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.03176 to 0.03158, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9744 - val_loss: 0.0306 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03158 to 0.03060, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9732 - val_loss: 0.0335 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03060\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0681 - acc: 0.9742 - val_loss: 0.0292 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.03060 to 0.02917, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9744 - val_loss: 0.0310 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02917\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0562 - acc: 0.9805 - val_loss: 0.0317 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02917\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9752 - val_loss: 0.0303 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02917\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9778 - val_loss: 0.0290 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02917 to 0.02901, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9737 - val_loss: 0.0319 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02901\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0589 - acc: 0.9781 - val_loss: 0.0274 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.02901 to 0.02744, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0565 - acc: 0.9788 - val_loss: 0.0294 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02744\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0673 - acc: 0.9766 - val_loss: 0.0262 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02744 to 0.02622, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9786 - val_loss: 0.0280 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02622\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0557 - acc: 0.9813 - val_loss: 0.0254 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02622 to 0.02544, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0489 - acc: 0.9808 - val_loss: 0.0252 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.02544 to 0.02515, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0537 - acc: 0.9786 - val_loss: 0.0242 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.02515 to 0.02424, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9822 - val_loss: 0.0217 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02424 to 0.02167, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9771 - val_loss: 0.0290 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02167\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9798 - val_loss: 0.0235 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02167\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0452 - acc: 0.9825 - val_loss: 0.0255 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02167\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9761 - val_loss: 0.0220 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02167\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0526 - acc: 0.9783 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02167\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 8s - loss: 0.7732 - acc: 0.5082 - val_loss: 0.6696 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66960, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7135 - acc: 0.5534 - val_loss: 0.6323 - val_acc: 0.7683\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66960 to 0.63233, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6716 - acc: 0.5946 - val_loss: 0.5742 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63233 to 0.57417, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6023 - acc: 0.6764 - val_loss: 0.4914 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57417 to 0.49145, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5231 - acc: 0.7499 - val_loss: 0.4185 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49145 to 0.41851, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4693 - acc: 0.7921 - val_loss: 0.3735 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41851 to 0.37347, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4280 - acc: 0.8176 - val_loss: 0.3429 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37347 to 0.34289, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4000 - acc: 0.8361 - val_loss: 0.3221 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34289 to 0.32212, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3830 - acc: 0.8464 - val_loss: 0.3040 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32212 to 0.30402, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3585 - acc: 0.8624 - val_loss: 0.2931 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30402 to 0.29310, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3413 - acc: 0.8705 - val_loss: 0.2806 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29310 to 0.28057, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3347 - acc: 0.8746 - val_loss: 0.2703 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28057 to 0.27031, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3243 - acc: 0.8795 - val_loss: 0.2629 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27031 to 0.26285, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3167 - acc: 0.8758 - val_loss: 0.2633 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26285\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3065 - acc: 0.8887 - val_loss: 0.2517 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26285 to 0.25170, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3040 - acc: 0.8875 - val_loss: 0.2474 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25170 to 0.24744, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2940 - acc: 0.8890 - val_loss: 0.2419 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24744 to 0.24194, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2777 - acc: 0.8985 - val_loss: 0.2386 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24194 to 0.23864, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2678 - acc: 0.9031 - val_loss: 0.2342 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23864 to 0.23416, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2711 - acc: 0.8972 - val_loss: 0.2304 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23416 to 0.23037, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2702 - acc: 0.9028 - val_loss: 0.2268 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23037 to 0.22682, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2525 - acc: 0.9116 - val_loss: 0.2257 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22682 to 0.22567, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2464 - acc: 0.9140 - val_loss: 0.2288 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.22567\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.2504 - acc: 0.9111 - val_loss: 0.2185 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22567 to 0.21850, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.2479 - acc: 0.9106 - val_loss: 0.2172 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21850 to 0.21719, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.2339 - acc: 0.9160 - val_loss: 0.2127 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21719 to 0.21267, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.2375 - acc: 0.9145 - val_loss: 0.2095 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21267 to 0.20949, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.2328 - acc: 0.9162 - val_loss: 0.2064 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20949 to 0.20642, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2361 - acc: 0.9182 - val_loss: 0.2042 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20642 to 0.20421, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9172 - val_loss: 0.2038 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20421 to 0.20376, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2174 - acc: 0.9228 - val_loss: 0.1996 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20376 to 0.19965, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2162 - acc: 0.9235 - val_loss: 0.1957 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19965 to 0.19570, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2145 - acc: 0.9255 - val_loss: 0.1942 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19570 to 0.19420, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2101 - acc: 0.9238 - val_loss: 0.1897 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19420 to 0.18968, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2095 - acc: 0.9231 - val_loss: 0.1853 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18968 to 0.18530, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.2053 - acc: 0.9248 - val_loss: 0.1839 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18530 to 0.18391, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2043 - acc: 0.9304 - val_loss: 0.1854 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.18391\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1928 - acc: 0.9335 - val_loss: 0.1799 - val_acc: 0.9377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 0.18391 to 0.17991, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.1895 - acc: 0.9360 - val_loss: 0.1781 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17991 to 0.17813, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1870 - acc: 0.9338 - val_loss: 0.1759 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17813 to 0.17588, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1931 - acc: 0.9350 - val_loss: 0.1742 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17588 to 0.17424, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.1850 - acc: 0.9350 - val_loss: 0.1723 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17424 to 0.17228, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.1808 - acc: 0.9396 - val_loss: 0.1689 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17228 to 0.16893, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.1785 - acc: 0.9413 - val_loss: 0.1658 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16893 to 0.16577, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1802 - acc: 0.9374 - val_loss: 0.1602 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16577 to 0.16024, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1727 - acc: 0.9450 - val_loss: 0.1594 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16024 to 0.15936, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.1763 - acc: 0.9401 - val_loss: 0.1586 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15936 to 0.15861, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.1632 - acc: 0.9464 - val_loss: 0.1608 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.15861\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.1757 - acc: 0.9391 - val_loss: 0.1557 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15861 to 0.15574, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1610 - acc: 0.9464 - val_loss: 0.1542 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15574 to 0.15423, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.1610 - acc: 0.9430 - val_loss: 0.1557 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.15423\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.1631 - acc: 0.9450 - val_loss: 0.1496 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15423 to 0.14964, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.1571 - acc: 0.9498 - val_loss: 0.1479 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14964 to 0.14794, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.1523 - acc: 0.9498 - val_loss: 0.1456 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14794 to 0.14560, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1508 - acc: 0.9491 - val_loss: 0.1443 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14560 to 0.14427, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1599 - acc: 0.9459 - val_loss: 0.1403 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.14427 to 0.14030, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1459 - acc: 0.9511 - val_loss: 0.1365 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.14030 to 0.13648, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1521 - acc: 0.9540 - val_loss: 0.1372 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.13648\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1418 - acc: 0.9518 - val_loss: 0.1330 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.13648 to 0.13301, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.1453 - acc: 0.9508 - val_loss: 0.1309 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.13301 to 0.13088, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1437 - acc: 0.9525 - val_loss: 0.1259 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13088 to 0.12586, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9513 - val_loss: 0.1254 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.12586 to 0.12542, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1377 - acc: 0.9559 - val_loss: 0.1238 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12542 to 0.12375, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1274 - acc: 0.9569 - val_loss: 0.1205 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.12375 to 0.12046, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1363 - acc: 0.9535 - val_loss: 0.1164 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.12046 to 0.11645, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9550 - val_loss: 0.1138 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11645 to 0.11382, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1254 - acc: 0.9586 - val_loss: 0.1119 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.11382 to 0.11188, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9598 - val_loss: 0.1098 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.11188 to 0.10981, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9564 - val_loss: 0.1059 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10981 to 0.10586, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9574 - val_loss: 0.1039 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.10586 to 0.10386, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9598 - val_loss: 0.1035 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.10386 to 0.10349, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1174 - acc: 0.9603 - val_loss: 0.1006 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.10349 to 0.10060, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1177 - acc: 0.9615 - val_loss: 0.0961 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.10060 to 0.09612, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1121 - acc: 0.9642 - val_loss: 0.0946 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.09612 to 0.09460, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9596 - val_loss: 0.0928 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.09460 to 0.09284, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1061 - acc: 0.9657 - val_loss: 0.0903 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.09284 to 0.09032, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1101 - acc: 0.9625 - val_loss: 0.0884 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.09032 to 0.08836, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9662 - val_loss: 0.0875 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.08836 to 0.08747, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1101 - acc: 0.9649 - val_loss: 0.0888 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08747\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1025 - acc: 0.9679 - val_loss: 0.0853 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.08747 to 0.08526, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1019 - acc: 0.9654 - val_loss: 0.0811 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.08526 to 0.08112, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1004 - acc: 0.9652 - val_loss: 0.0792 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.08112 to 0.07920, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0963 - acc: 0.9676 - val_loss: 0.0769 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07920 to 0.07695, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1029 - acc: 0.9669 - val_loss: 0.0766 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.07695 to 0.07658, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1048 - acc: 0.9657 - val_loss: 0.0744 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.07658 to 0.07440, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9640 - val_loss: 0.0726 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.07440 to 0.07257, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0968 - acc: 0.9693 - val_loss: 0.0731 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.07257\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0963 - acc: 0.9698 - val_loss: 0.0731 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.07257\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9664 - val_loss: 0.0693 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.07257 to 0.06926, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9669 - val_loss: 0.0693 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06926\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9676 - val_loss: 0.0665 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.06926 to 0.06654, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9698 - val_loss: 0.0642 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.06654 to 0.06420, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9698 - val_loss: 0.0635 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.06420 to 0.06351, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9688 - val_loss: 0.0640 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.06351\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9718 - val_loss: 0.0605 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06351 to 0.06052, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9703 - val_loss: 0.0627 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.06052\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9671 - val_loss: 0.0599 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.06052 to 0.05988, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9715 - val_loss: 0.0585 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.05988 to 0.05850, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9718 - val_loss: 0.0587 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05850\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0781 - acc: 0.9720 - val_loss: 0.0561 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05850 to 0.05614, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9686 - val_loss: 0.0529 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05614 to 0.05292, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9718 - val_loss: 0.0537 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05292\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9749 - val_loss: 0.0521 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05292 to 0.05209, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9739 - val_loss: 0.0510 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05209 to 0.05097, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9710 - val_loss: 0.0498 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05097 to 0.04977, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9708 - val_loss: 0.0466 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04977 to 0.04658, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9718 - val_loss: 0.0446 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04658 to 0.04457, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9749 - val_loss: 0.0429 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04457 to 0.04287, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9739 - val_loss: 0.0420 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.04287 to 0.04199, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9761 - val_loss: 0.0423 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04199\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9737 - val_loss: 0.0401 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.04199 to 0.04013, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9754 - val_loss: 0.0404 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04013\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9715 - val_loss: 0.0402 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04013\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0680 - acc: 0.9742 - val_loss: 0.0370 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04013 to 0.03700, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9749 - val_loss: 0.0416 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03700\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0681 - acc: 0.9730 - val_loss: 0.0371 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03700\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0695 - acc: 0.9754 - val_loss: 0.0366 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.03700 to 0.03663, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9761 - val_loss: 0.0335 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.03663 to 0.03350, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9766 - val_loss: 0.0343 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03350\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9778 - val_loss: 0.0327 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.03350 to 0.03267, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9776 - val_loss: 0.0320 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.03267 to 0.03195, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0615 - acc: 0.9776 - val_loss: 0.0331 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03195\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9800 - val_loss: 0.0283 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.03195 to 0.02826, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9749 - val_loss: 0.0272 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.02826 to 0.02724, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0551 - acc: 0.9822 - val_loss: 0.0252 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02724 to 0.02518, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9774 - val_loss: 0.0236 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02518 to 0.02364, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9778 - val_loss: 0.0239 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02364\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0628 - acc: 0.9778 - val_loss: 0.0256 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02364\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0670 - acc: 0.9788 - val_loss: 0.0258 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02364\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0548 - acc: 0.9813 - val_loss: 0.0229 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02364 to 0.02295, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9793 - val_loss: 0.0219 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02295 to 0.02194, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9795 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02194 to 0.02068, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9795 - val_loss: 0.0231 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02068\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9815 - val_loss: 0.0196 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.02068 to 0.01957, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9788 - val_loss: 0.0194 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01957 to 0.01942, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9752 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01942\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0557 - acc: 0.9793 - val_loss: 0.0182 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01942 to 0.01824, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9791 - val_loss: 0.0205 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01824\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9815 - val_loss: 0.0179 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01824 to 0.01795, saving model to best.model\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0494 - acc: 0.9830 - val_loss: 0.0170 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.01795 to 0.01698, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9842 - val_loss: 0.0163 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01698 to 0.01634, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9800 - val_loss: 0.0162 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01634 to 0.01619, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9757 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01619\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9805 - val_loss: 0.0197 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01619\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9820 - val_loss: 0.0169 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01619\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0458 - acc: 0.9864 - val_loss: 0.0149 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01619 to 0.01494, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9805 - val_loss: 0.0152 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01494\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9783 - val_loss: 0.0184 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01494\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9813 - val_loss: 0.0170 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01494\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0472 - acc: 0.9827 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.01494 to 0.01396, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0489 - acc: 0.9839 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.01396 to 0.01316, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9820 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01316\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9808 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01316 to 0.01207, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9817 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01207 to 0.01187, saving model to best.model\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9825 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01187\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9832 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.01187 to 0.01183, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0496 - acc: 0.9830 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01183\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0430 - acc: 0.9861 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01183\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9817 - val_loss: 0.0112 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.01183 to 0.01118, saving model to best.model\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0465 - acc: 0.9825 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.01118 to 0.01059, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9866 - val_loss: 0.0101 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.01059 to 0.01012, saving model to best.model\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9871 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.01012 to 0.00939, saving model to best.model\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0443 - acc: 0.9822 - val_loss: 0.0098 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00939\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0372 - acc: 0.9876 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00939 to 0.00928, saving model to best.model\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0424 - acc: 0.9851 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00928\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9844 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00928\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9798 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00928\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0397 - acc: 0.9849 - val_loss: 0.0099 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00928\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9834 - val_loss: 0.0095 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00928\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.8234 - acc: 0.5011 - val_loss: 0.6701 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67008, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7409 - acc: 0.5401 - val_loss: 0.6427 - val_acc: 0.7128\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67008 to 0.64272, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6937 - acc: 0.5683 - val_loss: 0.5955 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64272 to 0.59548, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6455 - acc: 0.6258 - val_loss: 0.5173 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59548 to 0.51728, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5585 - acc: 0.7185 - val_loss: 0.4375 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51728 to 0.43751, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4954 - acc: 0.7787 - val_loss: 0.3829 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43751 to 0.38293, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4426 - acc: 0.8057 - val_loss: 0.3426 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38293 to 0.34255, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4104 - acc: 0.8300 - val_loss: 0.3160 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34255 to 0.31601, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3915 - acc: 0.8430 - val_loss: 0.2971 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31601 to 0.29707, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3798 - acc: 0.8524 - val_loss: 0.2784 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.29707 to 0.27838, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3585 - acc: 0.8576 - val_loss: 0.2648 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27838 to 0.26476, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3464 - acc: 0.8583 - val_loss: 0.2540 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26476 to 0.25400, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3318 - acc: 0.8714 - val_loss: 0.2433 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25400 to 0.24331, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3186 - acc: 0.8766 - val_loss: 0.2323 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24331 to 0.23227, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3156 - acc: 0.8797 - val_loss: 0.2243 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.23227 to 0.22435, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3022 - acc: 0.8839 - val_loss: 0.2172 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22435 to 0.21719, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3017 - acc: 0.8873 - val_loss: 0.2141 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.21719 to 0.21413, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2952 - acc: 0.8929 - val_loss: 0.2041 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.21413 to 0.20405, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2780 - acc: 0.8948 - val_loss: 0.1993 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20405 to 0.19933, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2722 - acc: 0.9009 - val_loss: 0.1944 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.19933 to 0.19441, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2879 - acc: 0.8936 - val_loss: 0.1906 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.19441 to 0.19056, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2631 - acc: 0.9043 - val_loss: 0.1876 - val_acc: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_loss improved from 0.19056 to 0.18756, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2633 - acc: 0.9009 - val_loss: 0.1860 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.18756 to 0.18604, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2655 - acc: 0.9014 - val_loss: 0.1887 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.18604\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2533 - acc: 0.9082 - val_loss: 0.1791 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18604 to 0.17909, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2487 - acc: 0.9094 - val_loss: 0.1753 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17909 to 0.17534, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2462 - acc: 0.9097 - val_loss: 0.1712 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17534 to 0.17116, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2468 - acc: 0.9114 - val_loss: 0.1687 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.17116 to 0.16866, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2473 - acc: 0.9077 - val_loss: 0.1689 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16866\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2387 - acc: 0.9114 - val_loss: 0.1652 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16866 to 0.16518, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2318 - acc: 0.9131 - val_loss: 0.1601 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.16518 to 0.16010, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2354 - acc: 0.9104 - val_loss: 0.1565 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16010 to 0.15651, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2302 - acc: 0.9119 - val_loss: 0.1611 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15651\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2148 - acc: 0.9204 - val_loss: 0.1529 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.15651 to 0.15294, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2206 - acc: 0.9140 - val_loss: 0.1517 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.15294 to 0.15168, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2201 - acc: 0.9162 - val_loss: 0.1455 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15168 to 0.14553, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2063 - acc: 0.9221 - val_loss: 0.1408 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.14553 to 0.14077, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2085 - acc: 0.9162 - val_loss: 0.1362 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.14077 to 0.13622, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2102 - acc: 0.9199 - val_loss: 0.1340 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13622 to 0.13398, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9194 - val_loss: 0.1429 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.13398\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2018 - acc: 0.9218 - val_loss: 0.1337 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13398 to 0.13368, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2008 - acc: 0.9228 - val_loss: 0.1256 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.13368 to 0.12557, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9308 - val_loss: 0.1210 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.12557 to 0.12102, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9274 - val_loss: 0.1191 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.12102 to 0.11907, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1868 - acc: 0.9235 - val_loss: 0.1141 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.11907 to 0.11408, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1798 - acc: 0.9243 - val_loss: 0.1116 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11408 to 0.11158, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1743 - acc: 0.9308 - val_loss: 0.1157 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11158\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1717 - acc: 0.9306 - val_loss: 0.1086 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11158 to 0.10859, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1739 - acc: 0.9304 - val_loss: 0.1086 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10859\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1759 - acc: 0.9231 - val_loss: 0.1076 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10859 to 0.10758, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1712 - acc: 0.9326 - val_loss: 0.1023 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.10758 to 0.10228, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1606 - acc: 0.9355 - val_loss: 0.0975 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10228 to 0.09749, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9384 - val_loss: 0.0955 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.09749 to 0.09554, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9416 - val_loss: 0.0934 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.09554 to 0.09344, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1568 - acc: 0.9377 - val_loss: 0.0873 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.09344 to 0.08728, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1501 - acc: 0.9403 - val_loss: 0.0872 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08728 to 0.08721, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9440 - val_loss: 0.0840 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08721 to 0.08396, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1409 - acc: 0.9447 - val_loss: 0.0843 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.08396\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1399 - acc: 0.9450 - val_loss: 0.0773 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08396 to 0.07730, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1388 - acc: 0.9474 - val_loss: 0.0744 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07730 to 0.07440, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9467 - val_loss: 0.0732 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.07440 to 0.07317, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1340 - acc: 0.9425 - val_loss: 0.0710 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.07317 to 0.07098, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1331 - acc: 0.9506 - val_loss: 0.0706 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.07098 to 0.07059, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1317 - acc: 0.9469 - val_loss: 0.0660 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07059 to 0.06598, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1258 - acc: 0.9523 - val_loss: 0.0653 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06598 to 0.06532, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9518 - val_loss: 0.0629 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06532 to 0.06286, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9477 - val_loss: 0.0660 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06286\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1228 - acc: 0.9484 - val_loss: 0.0614 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06286 to 0.06137, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1176 - acc: 0.9542 - val_loss: 0.0581 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06137 to 0.05807, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9562 - val_loss: 0.0556 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.05807 to 0.05562, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1162 - acc: 0.9540 - val_loss: 0.0556 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.05562 to 0.05558, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1075 - acc: 0.9584 - val_loss: 0.0546 - val_acc: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_loss improved from 0.05558 to 0.05464, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9625 - val_loss: 0.0507 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05464 to 0.05066, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1125 - acc: 0.9557 - val_loss: 0.0517 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05066\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1037 - acc: 0.9598 - val_loss: 0.0476 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05066 to 0.04759, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1130 - acc: 0.9557 - val_loss: 0.0475 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.04759 to 0.04746, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9620 - val_loss: 0.0448 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.04746 to 0.04477, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1025 - acc: 0.9562 - val_loss: 0.0452 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04477\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0991 - acc: 0.9606 - val_loss: 0.0416 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04477 to 0.04159, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0977 - acc: 0.9576 - val_loss: 0.0424 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04159\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1007 - acc: 0.9618 - val_loss: 0.0419 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04159\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1033 - acc: 0.9640 - val_loss: 0.0394 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04159 to 0.03940, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0906 - acc: 0.9647 - val_loss: 0.0384 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03940 to 0.03841, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9662 - val_loss: 0.0388 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03841\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9659 - val_loss: 0.0355 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.03841 to 0.03549, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0864 - acc: 0.9671 - val_loss: 0.0353 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03549 to 0.03530, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9671 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.03530 to 0.03272, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0794 - acc: 0.9679 - val_loss: 0.0368 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03272\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0783 - acc: 0.9722 - val_loss: 0.0318 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03272 to 0.03180, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0856 - acc: 0.9669 - val_loss: 0.0308 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03180 to 0.03081, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9708 - val_loss: 0.0301 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03081 to 0.03006, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9718 - val_loss: 0.0292 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03006 to 0.02917, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0789 - acc: 0.9693 - val_loss: 0.0345 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02917\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0780 - acc: 0.9671 - val_loss: 0.0300 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02917\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9671 - val_loss: 0.0287 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.02917 to 0.02869, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9666 - val_loss: 0.0300 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02869\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9686 - val_loss: 0.0271 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02869 to 0.02708, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0780 - acc: 0.9713 - val_loss: 0.0267 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02708 to 0.02672, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9759 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02672\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0711 - acc: 0.9713 - val_loss: 0.0272 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02672\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9737 - val_loss: 0.0256 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.02672 to 0.02563, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9718 - val_loss: 0.0262 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02563\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9703 - val_loss: 0.0239 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02563 to 0.02394, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9725 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02394\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9747 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02394 to 0.02385, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0655 - acc: 0.9774 - val_loss: 0.0242 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02385\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9735 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02385 to 0.02162, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0657 - acc: 0.9754 - val_loss: 0.0209 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02162 to 0.02086, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9766 - val_loss: 0.0203 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02086 to 0.02027, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9737 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02027 to 0.02021, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0663 - acc: 0.9774 - val_loss: 0.0185 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02021 to 0.01848, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0550 - acc: 0.9769 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.01848 to 0.01803, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0607 - acc: 0.9747 - val_loss: 0.0180 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.01803 to 0.01800, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9715 - val_loss: 0.0184 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01800\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0628 - acc: 0.9754 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01800\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9769 - val_loss: 0.0177 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01800 to 0.01768, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9795 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01768 to 0.01739, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9764 - val_loss: 0.0175 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01739\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9757 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01739\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0495 - acc: 0.9832 - val_loss: 0.0184 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01739\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9754 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01739 to 0.01624, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9752 - val_loss: 0.0164 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01624\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9769 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01624 to 0.01589, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9815 - val_loss: 0.0155 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01589 to 0.01553, saving model to best.model\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0498 - acc: 0.9820 - val_loss: 0.0136 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01553 to 0.01359, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9776 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01359\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0553 - acc: 0.9781 - val_loss: 0.0136 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01359\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9769 - val_loss: 0.0139 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01359\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9813 - val_loss: 0.0154 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01359\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9788 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01359 to 0.01348, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9813 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01348\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9808 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01348 to 0.01254, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9778 - val_loss: 0.0132 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01254\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0470 - acc: 0.9810 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01254\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9837 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01254 to 0.01174, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9830 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01174\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9822 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01174 to 0.01125, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9839 - val_loss: 0.0106 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01125 to 0.01061, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9847 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01061 to 0.01017, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9832 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.01017 to 0.01012, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9830 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01012\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0458 - acc: 0.9820 - val_loss: 0.0100 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01012 to 0.00996, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9844 - val_loss: 0.0099 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00996 to 0.00993, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0437 - acc: 0.9832 - val_loss: 0.0092 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00993 to 0.00918, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0354 - acc: 0.9869 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00918\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0430 - acc: 0.9844 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00918 to 0.00878, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9851 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00878 to 0.00876, saving model to best.model\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9834 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00876 to 0.00850, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0437 - acc: 0.9827 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00850\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9849 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00850 to 0.00825, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9832 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00825\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9869 - val_loss: 0.0082 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00825 to 0.00824, saving model to best.model\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9854 - val_loss: 0.0086 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00824\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0409 - acc: 0.9834 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00824\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0377 - acc: 0.9851 - val_loss: 0.0099 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00824\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9815 - val_loss: 0.0079 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00824 to 0.00790, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9847 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00790\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0289 - acc: 0.9886 - val_loss: 0.0072 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00790 to 0.00721, saving model to best.model\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9864 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00721\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9839 - val_loss: 0.0070 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00721 to 0.00700, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9866 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00700\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0382 - acc: 0.9844 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00700\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0393 - acc: 0.9854 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00700\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9849 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00700 to 0.00683, saving model to best.model\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0397 - acc: 0.9844 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00683\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9837 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00683\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0328 - acc: 0.9878 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00683 to 0.00678, saving model to best.model\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9842 - val_loss: 0.0072 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00678\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0328 - acc: 0.9888 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00678 to 0.00677, saving model to best.model\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0372 - acc: 0.9854 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00677 to 0.00668, saving model to best.model\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9881 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00668 to 0.00647, saving model to best.model\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0329 - acc: 0.9888 - val_loss: 0.0059 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00647 to 0.00594, saving model to best.model\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9890 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00594 to 0.00581, saving model to best.model\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00581 to 0.00573, saving model to best.model\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0268 - acc: 0.9893 - val_loss: 0.0055 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00573 to 0.00549, saving model to best.model\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9878 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00549\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9878 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00549 to 0.00534, saving model to best.model\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0293 - acc: 0.9898 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00534\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0309 - acc: 0.9876 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00534 to 0.00516, saving model to best.model\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0360 - acc: 0.9854 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00516\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9859 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00516\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0291 - acc: 0.9881 - val_loss: 0.0055 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00516\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0297 - acc: 0.9881 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00516 to 0.00494, saving model to best.model\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9903 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00494\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0324 - acc: 0.9856 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00494\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0287 - acc: 0.9898 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00494\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0269 - acc: 0.9886 - val_loss: 0.0062 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00494\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9890 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00494 to 0.00469, saving model to best.model\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9912 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00469\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0218 - acc: 0.9912 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00469\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0250 - acc: 0.9910 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00469 to 0.00407, saving model to best.model\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9915 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00407 to 0.00389, saving model to best.model\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9893 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00389\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0285 - acc: 0.9895 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00389 to 0.00382, saving model to best.model\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9910 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00382\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0373 - acc: 0.9864 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00382\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9893 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00382\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0273 - acc: 0.9893 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00382\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9925 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00382\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.8783 - acc: 0.5060 - val_loss: 0.6791 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67909, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7843 - acc: 0.5233 - val_loss: 0.6607 - val_acc: 0.6222\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67909 to 0.66067, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7205 - acc: 0.5493 - val_loss: 0.6175 - val_acc: 0.8023\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66067 to 0.61755, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6752 - acc: 0.5978 - val_loss: 0.5609 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61755 to 0.56094, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6059 - acc: 0.6723 - val_loss: 0.4906 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56094 to 0.49064, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5337 - acc: 0.7346 - val_loss: 0.4234 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49064 to 0.42337, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4807 - acc: 0.7845 - val_loss: 0.3739 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42337 to 0.37389, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4444 - acc: 0.8115 - val_loss: 0.3429 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37389 to 0.34289, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4016 - acc: 0.8391 - val_loss: 0.3199 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34289 to 0.31988, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3819 - acc: 0.8522 - val_loss: 0.3028 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31988 to 0.30284, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3538 - acc: 0.8629 - val_loss: 0.2877 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30284 to 0.28773, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3378 - acc: 0.8717 - val_loss: 0.2794 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28773 to 0.27937, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3187 - acc: 0.8775 - val_loss: 0.2700 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27937 to 0.27004, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3220 - acc: 0.8792 - val_loss: 0.2650 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27004 to 0.26500, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3063 - acc: 0.8912 - val_loss: 0.2589 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26500 to 0.25893, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2948 - acc: 0.8934 - val_loss: 0.2533 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25893 to 0.25333, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2887 - acc: 0.8955 - val_loss: 0.2493 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25333 to 0.24934, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2704 - acc: 0.9024 - val_loss: 0.2464 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24934 to 0.24637, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2745 - acc: 0.8941 - val_loss: 0.2447 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24637 to 0.24472, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2634 - acc: 0.9109 - val_loss: 0.2403 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24472 to 0.24029, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2619 - acc: 0.9119 - val_loss: 0.2375 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24029 to 0.23755, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2614 - acc: 0.9087 - val_loss: 0.2385 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.23755\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2525 - acc: 0.9119 - val_loss: 0.2345 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23755 to 0.23449, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2513 - acc: 0.9128 - val_loss: 0.2307 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23449 to 0.23074, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2468 - acc: 0.9165 - val_loss: 0.2284 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23074 to 0.22836, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2376 - acc: 0.9206 - val_loss: 0.2240 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22836 to 0.22398, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2351 - acc: 0.9172 - val_loss: 0.2253 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22398\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2283 - acc: 0.9199 - val_loss: 0.2203 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22398 to 0.22034, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2278 - acc: 0.9248 - val_loss: 0.2172 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22034 to 0.21722, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2195 - acc: 0.9209 - val_loss: 0.2141 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21722 to 0.21413, saving model to best.model\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2275 - acc: 0.9235 - val_loss: 0.2181 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21413\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2212 - acc: 0.9245 - val_loss: 0.2095 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21413 to 0.20952, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2121 - acc: 0.9240 - val_loss: 0.2087 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20952 to 0.20867, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2098 - acc: 0.9279 - val_loss: 0.2012 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20867 to 0.20124, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9294 - val_loss: 0.1983 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20124 to 0.19834, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2007 - acc: 0.9272 - val_loss: 0.1983 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19834 to 0.19829, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1980 - acc: 0.9279 - val_loss: 0.1913 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19829 to 0.19128, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1956 - acc: 0.9313 - val_loss: 0.1877 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19128 to 0.18775, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1956 - acc: 0.9321 - val_loss: 0.1834 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18775 to 0.18339, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1858 - acc: 0.9372 - val_loss: 0.1803 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18339 to 0.18027, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1851 - acc: 0.9328 - val_loss: 0.1760 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18027 to 0.17604, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9333 - val_loss: 0.1725 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17604 to 0.17253, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1764 - acc: 0.9389 - val_loss: 0.1721 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17253 to 0.17207, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1861 - acc: 0.9323 - val_loss: 0.1675 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17207 to 0.16753, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1844 - acc: 0.9323 - val_loss: 0.1597 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16753 to 0.15970, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1775 - acc: 0.9372 - val_loss: 0.1560 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15970 to 0.15602, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1703 - acc: 0.9394 - val_loss: 0.1538 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15602 to 0.15380, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1694 - acc: 0.9399 - val_loss: 0.1526 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15380 to 0.15258, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1718 - acc: 0.9377 - val_loss: 0.1437 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15258 to 0.14369, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1559 - acc: 0.9440 - val_loss: 0.1448 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.14369\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1623 - acc: 0.9399 - val_loss: 0.1373 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14369 to 0.13727, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1655 - acc: 0.9401 - val_loss: 0.1427 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.13727\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1603 - acc: 0.9438 - val_loss: 0.1324 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13727 to 0.13235, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1521 - acc: 0.9447 - val_loss: 0.1287 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13235 to 0.12875, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1490 - acc: 0.9450 - val_loss: 0.1277 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12875 to 0.12775, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1460 - acc: 0.9486 - val_loss: 0.1231 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12775 to 0.12315, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1470 - acc: 0.9486 - val_loss: 0.1216 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12315 to 0.12159, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1373 - acc: 0.9547 - val_loss: 0.1220 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.12159\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1388 - acc: 0.9533 - val_loss: 0.1145 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12159 to 0.11447, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1380 - acc: 0.9503 - val_loss: 0.1120 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11447 to 0.11200, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1387 - acc: 0.9508 - val_loss: 0.1133 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.11200\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1326 - acc: 0.9554 - val_loss: 0.1072 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11200 to 0.10715, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1298 - acc: 0.9542 - val_loss: 0.1073 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10715\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1329 - acc: 0.9540 - val_loss: 0.1020 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10715 to 0.10205, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1326 - acc: 0.9496 - val_loss: 0.0990 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10205 to 0.09902, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9530 - val_loss: 0.0972 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09902 to 0.09723, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1229 - acc: 0.9596 - val_loss: 0.0952 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09723 to 0.09517, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1207 - acc: 0.9581 - val_loss: 0.0941 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09517 to 0.09406, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1301 - acc: 0.9540 - val_loss: 0.0921 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09406 to 0.09209, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1368 - acc: 0.9515 - val_loss: 0.0910 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09209 to 0.09097, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1210 - acc: 0.9586 - val_loss: 0.0918 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.09097\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9581 - val_loss: 0.0872 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.09097 to 0.08715, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1166 - acc: 0.9615 - val_loss: 0.0859 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08715 to 0.08591, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1112 - acc: 0.9635 - val_loss: 0.0849 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08591 to 0.08487, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1157 - acc: 0.9589 - val_loss: 0.0828 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08487 to 0.08284, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1102 - acc: 0.9606 - val_loss: 0.0798 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08284 to 0.07983, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1147 - acc: 0.9610 - val_loss: 0.0785 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07983 to 0.07847, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1078 - acc: 0.9632 - val_loss: 0.0772 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07847 to 0.07720, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1084 - acc: 0.9608 - val_loss: 0.0752 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07720 to 0.07516, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1024 - acc: 0.9642 - val_loss: 0.0738 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07516 to 0.07378, saving model to best.model\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1092 - acc: 0.9618 - val_loss: 0.0713 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07378 to 0.07132, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9623 - val_loss: 0.0703 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07132 to 0.07029, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1016 - acc: 0.9632 - val_loss: 0.0691 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07029 to 0.06911, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9659 - val_loss: 0.0688 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06911 to 0.06880, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9640 - val_loss: 0.0689 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06880\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0934 - acc: 0.9671 - val_loss: 0.0658 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06880 to 0.06581, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0946 - acc: 0.9691 - val_loss: 0.0637 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06581 to 0.06375, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9686 - val_loss: 0.0609 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06375 to 0.06090, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9669 - val_loss: 0.0603 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06090 to 0.06034, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0931 - acc: 0.9669 - val_loss: 0.0583 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06034 to 0.05827, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0860 - acc: 0.9666 - val_loss: 0.0593 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05827\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9674 - val_loss: 0.0560 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05827 to 0.05605, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9683 - val_loss: 0.0551 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05605 to 0.05513, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9679 - val_loss: 0.0526 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05513 to 0.05257, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9730 - val_loss: 0.0515 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05257 to 0.05148, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0926 - acc: 0.9705 - val_loss: 0.0501 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05148 to 0.05015, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0794 - acc: 0.9725 - val_loss: 0.0479 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05015 to 0.04791, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9686 - val_loss: 0.0464 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04791 to 0.04636, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9671 - val_loss: 0.0526 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04636\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9698 - val_loss: 0.0463 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04636 to 0.04630, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9688 - val_loss: 0.0426 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04630 to 0.04261, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0807 - acc: 0.9691 - val_loss: 0.0418 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04261 to 0.04183, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0767 - acc: 0.9720 - val_loss: 0.0406 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.04183 to 0.04065, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0788 - acc: 0.9710 - val_loss: 0.0399 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04065 to 0.03990, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0760 - acc: 0.9727 - val_loss: 0.0393 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03990 to 0.03928, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0789 - acc: 0.9742 - val_loss: 0.0397 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03928\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0707 - acc: 0.9749 - val_loss: 0.0382 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03928 to 0.03819, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9732 - val_loss: 0.0370 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03819 to 0.03697, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9722 - val_loss: 0.0329 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03697 to 0.03286, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0761 - acc: 0.9742 - val_loss: 0.0338 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03286\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0762 - acc: 0.9703 - val_loss: 0.0325 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03286 to 0.03252, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9735 - val_loss: 0.0307 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03252 to 0.03070, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9730 - val_loss: 0.0321 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03070\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9713 - val_loss: 0.0295 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.03070 to 0.02947, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9771 - val_loss: 0.0288 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02947 to 0.02884, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9757 - val_loss: 0.0269 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02884 to 0.02688, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9771 - val_loss: 0.0263 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02688 to 0.02633, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9752 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02633 to 0.02622, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9791 - val_loss: 0.0258 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02622 to 0.02580, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0642 - acc: 0.9771 - val_loss: 0.0259 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02580\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9786 - val_loss: 0.0243 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02580 to 0.02431, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9778 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02431 to 0.02387, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0799 - acc: 0.9701 - val_loss: 0.0295 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02387\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9754 - val_loss: 0.0230 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.02387 to 0.02300, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9783 - val_loss: 0.0221 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02300 to 0.02210, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0630 - acc: 0.9769 - val_loss: 0.0230 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02210\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9752 - val_loss: 0.0307 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02210\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9747 - val_loss: 0.0228 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02210\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9808 - val_loss: 0.0230 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02210\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9798 - val_loss: 0.0208 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02210 to 0.02077, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0575 - acc: 0.9800 - val_loss: 0.0210 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02077\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0573 - acc: 0.9795 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02077 to 0.01976, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0573 - acc: 0.9786 - val_loss: 0.0189 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01976 to 0.01885, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9822 - val_loss: 0.0188 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01885 to 0.01883, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9834 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01883 to 0.01854, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9798 - val_loss: 0.0170 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01854 to 0.01704, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9810 - val_loss: 0.0173 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01704\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9815 - val_loss: 0.0169 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01704 to 0.01687, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9786 - val_loss: 0.0162 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01687 to 0.01616, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9793 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01616\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9825 - val_loss: 0.0171 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01616\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0453 - acc: 0.9825 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01616 to 0.01603, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9815 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01603 to 0.01522, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9800 - val_loss: 0.0171 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01522\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9842 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01522\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9839 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01522 to 0.01346, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9849 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01346\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9822 - val_loss: 0.0129 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01346 to 0.01293, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9847 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.01293 to 0.01245, saving model to best.model\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9854 - val_loss: 0.0129 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01245\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9851 - val_loss: 0.0123 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.01245 to 0.01231, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0434 - acc: 0.9834 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01231 to 0.01144, saving model to best.model\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0495 - acc: 0.9805 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01144\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9854 - val_loss: 0.0155 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01144\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9837 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01144\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9837 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01144\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9851 - val_loss: 0.0107 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.01144 to 0.01075, saving model to best.model\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9851 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01075\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9859 - val_loss: 0.0100 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.01075 to 0.00996, saving model to best.model\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9842 - val_loss: 0.0100 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00996 to 0.00995, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0329 - acc: 0.9878 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00995\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9830 - val_loss: 0.0099 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00995 to 0.00994, saving model to best.model\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9820 - val_loss: 0.0104 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00994\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9842 - val_loss: 0.0110 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00994\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9844 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00994 to 0.00898, saving model to best.model\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9825 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00898\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0372 - acc: 0.9854 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00898 to 0.00892, saving model to best.model\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9861 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00892 to 0.00830, saving model to best.model\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9876 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00830\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9854 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00830 to 0.00829, saving model to best.model\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9876 - val_loss: 0.0086 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00829\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0361 - acc: 0.9873 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00829 to 0.00699, saving model to best.model\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0376 - acc: 0.9856 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00699\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9832 - val_loss: 0.0069 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00699 to 0.00690, saving model to best.model\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9873 - val_loss: 0.0067 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00690 to 0.00672, saving model to best.model\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9851 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00672\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9871 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00672\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9881 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00672\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9878 - val_loss: 0.0085 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00672\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0426 - acc: 0.9839 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00672\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 8s - loss: 0.8032 - acc: 0.5116 - val_loss: 0.6713 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67135, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7505 - acc: 0.5284 - val_loss: 0.6471 - val_acc: 0.7381\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67135 to 0.64712, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7026 - acc: 0.5659 - val_loss: 0.6050 - val_acc: 0.7342\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64712 to 0.60498, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6319 - acc: 0.6445 - val_loss: 0.5192 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60498 to 0.51918, saving model to best.model\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.5523 - acc: 0.7229 - val_loss: 0.4364 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51918 to 0.43641, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4868 - acc: 0.7806 - val_loss: 0.3800 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43641 to 0.38005, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4449 - acc: 0.8064 - val_loss: 0.3448 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38005 to 0.34478, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4069 - acc: 0.8269 - val_loss: 0.3263 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34478 to 0.32625, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3892 - acc: 0.8447 - val_loss: 0.3056 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32625 to 0.30559, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3787 - acc: 0.8434 - val_loss: 0.2925 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30559 to 0.29251, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3466 - acc: 0.8590 - val_loss: 0.2839 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29251 to 0.28386, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3451 - acc: 0.8607 - val_loss: 0.2749 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28386 to 0.27485, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3273 - acc: 0.8717 - val_loss: 0.2678 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27485 to 0.26779, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3256 - acc: 0.8724 - val_loss: 0.2620 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26779 to 0.26195, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3186 - acc: 0.8697 - val_loss: 0.2595 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26195 to 0.25948, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3041 - acc: 0.8790 - val_loss: 0.2546 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25948 to 0.25456, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2921 - acc: 0.8860 - val_loss: 0.2494 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25456 to 0.24940, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2925 - acc: 0.8924 - val_loss: 0.2461 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24940 to 0.24606, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2794 - acc: 0.8953 - val_loss: 0.2418 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24606 to 0.24178, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2766 - acc: 0.8926 - val_loss: 0.2399 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24178 to 0.23991, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2667 - acc: 0.9026 - val_loss: 0.2360 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23991 to 0.23599, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2711 - acc: 0.8990 - val_loss: 0.2323 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23599 to 0.23234, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2581 - acc: 0.9024 - val_loss: 0.2297 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23234 to 0.22974, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2557 - acc: 0.9036 - val_loss: 0.2277 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22974 to 0.22768, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2484 - acc: 0.9065 - val_loss: 0.2300 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.22768\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2535 - acc: 0.9063 - val_loss: 0.2223 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22768 to 0.22230, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2462 - acc: 0.9102 - val_loss: 0.2179 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.22230 to 0.21795, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2466 - acc: 0.9094 - val_loss: 0.2152 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21795 to 0.21521, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2392 - acc: 0.9143 - val_loss: 0.2158 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.21521\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2295 - acc: 0.9179 - val_loss: 0.2118 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21521 to 0.21180, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2337 - acc: 0.9145 - val_loss: 0.2121 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21180\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2270 - acc: 0.9160 - val_loss: 0.2058 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21180 to 0.20577, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2218 - acc: 0.9235 - val_loss: 0.2030 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20577 to 0.20296, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2208 - acc: 0.9192 - val_loss: 0.1993 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20296 to 0.19929, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2127 - acc: 0.9279 - val_loss: 0.1970 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19929 to 0.19701, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2100 - acc: 0.9296 - val_loss: 0.1959 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19701 to 0.19594, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9260 - val_loss: 0.1925 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19594 to 0.19246, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2068 - acc: 0.9226 - val_loss: 0.1876 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19246 to 0.18757, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9248 - val_loss: 0.1847 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18757 to 0.18467, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9267 - val_loss: 0.1818 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18467 to 0.18177, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2057 - acc: 0.9277 - val_loss: 0.1753 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18177 to 0.17526, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2015 - acc: 0.9294 - val_loss: 0.1731 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17526 to 0.17309, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1893 - acc: 0.9360 - val_loss: 0.1748 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17309\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2013 - acc: 0.9267 - val_loss: 0.1742 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17309\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1872 - acc: 0.9362 - val_loss: 0.1675 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17309 to 0.16748, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1835 - acc: 0.9345 - val_loss: 0.1619 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16748 to 0.16189, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1764 - acc: 0.9416 - val_loss: 0.1611 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16189 to 0.16113, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1833 - acc: 0.9367 - val_loss: 0.1545 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.16113 to 0.15452, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1801 - acc: 0.9360 - val_loss: 0.1510 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15452 to 0.15105, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1715 - acc: 0.9382 - val_loss: 0.1470 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15105 to 0.14704, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1618 - acc: 0.9403 - val_loss: 0.1435 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14704 to 0.14352, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1672 - acc: 0.9389 - val_loss: 0.1414 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14352 to 0.14136, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1546 - acc: 0.9462 - val_loss: 0.1372 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14136 to 0.13716, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1586 - acc: 0.9421 - val_loss: 0.1374 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.13716\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1597 - acc: 0.9455 - val_loss: 0.1316 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13716 to 0.13163, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1535 - acc: 0.9494 - val_loss: 0.1295 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13163 to 0.12953, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1539 - acc: 0.9489 - val_loss: 0.1273 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12953 to 0.12726, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1430 - acc: 0.9489 - val_loss: 0.1242 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12726 to 0.12421, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1444 - acc: 0.9503 - val_loss: 0.1220 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12421 to 0.12198, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1470 - acc: 0.9537 - val_loss: 0.1258 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.12198\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9486 - val_loss: 0.1186 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.12198 to 0.11856, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1468 - acc: 0.9472 - val_loss: 0.1169 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11856 to 0.11694, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1397 - acc: 0.9503 - val_loss: 0.1114 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11694 to 0.11139, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1292 - acc: 0.9542 - val_loss: 0.1093 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11139 to 0.10934, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1336 - acc: 0.9545 - val_loss: 0.1080 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10934 to 0.10801, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1217 - acc: 0.9574 - val_loss: 0.1094 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10801\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1283 - acc: 0.9542 - val_loss: 0.1043 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10801 to 0.10428, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1265 - acc: 0.9562 - val_loss: 0.1017 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10428 to 0.10169, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1204 - acc: 0.9603 - val_loss: 0.0978 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10169 to 0.09783, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1181 - acc: 0.9581 - val_loss: 0.0983 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.09783\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1216 - acc: 0.9562 - val_loss: 0.0972 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.09783 to 0.09719, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1253 - acc: 0.9569 - val_loss: 0.0939 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.09719 to 0.09393, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1191 - acc: 0.9569 - val_loss: 0.0909 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.09393 to 0.09095, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1157 - acc: 0.9596 - val_loss: 0.0896 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.09095 to 0.08956, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1128 - acc: 0.9652 - val_loss: 0.0893 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08956 to 0.08930, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1077 - acc: 0.9593 - val_loss: 0.0864 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08930 to 0.08639, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9620 - val_loss: 0.0852 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.08639 to 0.08517, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0989 - acc: 0.9647 - val_loss: 0.0828 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.08517 to 0.08280, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1068 - acc: 0.9635 - val_loss: 0.0809 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.08280 to 0.08093, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9637 - val_loss: 0.0768 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.08093 to 0.07679, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9662 - val_loss: 0.0767 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07679 to 0.07669, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0963 - acc: 0.9659 - val_loss: 0.0730 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07669 to 0.07304, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0962 - acc: 0.9688 - val_loss: 0.0724 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07304 to 0.07240, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9664 - val_loss: 0.0694 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.07240 to 0.06944, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0958 - acc: 0.9664 - val_loss: 0.0728 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06944\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9652 - val_loss: 0.0679 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06944 to 0.06787, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0871 - acc: 0.9662 - val_loss: 0.0644 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06787 to 0.06436, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9683 - val_loss: 0.0625 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06436 to 0.06252, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9698 - val_loss: 0.0654 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06252\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9715 - val_loss: 0.0593 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06252 to 0.05930, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9696 - val_loss: 0.0584 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05930 to 0.05836, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0835 - acc: 0.9698 - val_loss: 0.0566 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05836 to 0.05665, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9727 - val_loss: 0.0538 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05665 to 0.05379, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9703 - val_loss: 0.0501 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05379 to 0.05014, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9693 - val_loss: 0.0510 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05014\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9710 - val_loss: 0.0488 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05014 to 0.04878, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9725 - val_loss: 0.0486 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04878 to 0.04860, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9752 - val_loss: 0.0496 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04860\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9732 - val_loss: 0.0468 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04860 to 0.04684, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9739 - val_loss: 0.0459 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04684 to 0.04594, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0711 - acc: 0.9735 - val_loss: 0.0489 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04594\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9713 - val_loss: 0.0487 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04594\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9732 - val_loss: 0.0423 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.04594 to 0.04231, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9720 - val_loss: 0.0423 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04231 to 0.04226, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9752 - val_loss: 0.0403 - val_acc: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_loss improved from 0.04226 to 0.04035, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9766 - val_loss: 0.0437 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04035\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9757 - val_loss: 0.0426 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04035\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0691 - acc: 0.9727 - val_loss: 0.0387 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04035 to 0.03869, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9778 - val_loss: 0.0377 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03869 to 0.03765, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0664 - acc: 0.9764 - val_loss: 0.0363 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03765 to 0.03635, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9791 - val_loss: 0.0347 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03635 to 0.03474, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9764 - val_loss: 0.0328 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03474 to 0.03276, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9781 - val_loss: 0.0307 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03276 to 0.03068, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9774 - val_loss: 0.0330 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03068\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0544 - acc: 0.9776 - val_loss: 0.0291 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03068 to 0.02912, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0537 - acc: 0.9798 - val_loss: 0.0298 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02912\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0507 - acc: 0.9808 - val_loss: 0.0283 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02912 to 0.02829, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0550 - acc: 0.9805 - val_loss: 0.0268 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02829 to 0.02684, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9808 - val_loss: 0.0282 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02684\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9769 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02684 to 0.02646, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9803 - val_loss: 0.0277 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02646\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9813 - val_loss: 0.0250 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02646 to 0.02504, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0505 - acc: 0.9813 - val_loss: 0.0249 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.02504 to 0.02488, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9817 - val_loss: 0.0330 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02488\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9815 - val_loss: 0.0254 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02488\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9805 - val_loss: 0.0247 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02488 to 0.02475, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9832 - val_loss: 0.0269 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02475\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9817 - val_loss: 0.0215 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.02475 to 0.02150, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9778 - val_loss: 0.0339 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02150\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9788 - val_loss: 0.0227 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02150\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9795 - val_loss: 0.0253 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02150\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9834 - val_loss: 0.0251 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02150\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9825 - val_loss: 0.0227 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02150\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.8159 - acc: 0.5121 - val_loss: 0.6757 - val_acc: 0.5122\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67571, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7447 - acc: 0.5308 - val_loss: 0.6576 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67571 to 0.65764, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7137 - acc: 0.5515 - val_loss: 0.6096 - val_acc: 0.7838\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65764 to 0.60960, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6408 - acc: 0.6394 - val_loss: 0.5511 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60960 to 0.55112, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5674 - acc: 0.7085 - val_loss: 0.4784 - val_acc: 0.8053\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55112 to 0.47836, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5026 - acc: 0.7663 - val_loss: 0.4205 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47836 to 0.42052, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4523 - acc: 0.8033 - val_loss: 0.3822 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42052 to 0.38219, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4209 - acc: 0.8215 - val_loss: 0.3662 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38219 to 0.36624, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3898 - acc: 0.8493 - val_loss: 0.3550 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36624 to 0.35500, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3807 - acc: 0.8505 - val_loss: 0.3265 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35500 to 0.32646, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3619 - acc: 0.8622 - val_loss: 0.3202 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32646 to 0.32015, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3467 - acc: 0.8661 - val_loss: 0.3018 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.32015 to 0.30184, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3393 - acc: 0.8685 - val_loss: 0.2937 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.30184 to 0.29370, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3319 - acc: 0.8702 - val_loss: 0.2882 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.29370 to 0.28824, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3183 - acc: 0.8766 - val_loss: 0.2976 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28824\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3066 - acc: 0.8829 - val_loss: 0.2777 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.28824 to 0.27774, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2893 - acc: 0.8921 - val_loss: 0.2727 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.27774 to 0.27266, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2888 - acc: 0.8972 - val_loss: 0.2647 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27266 to 0.26472, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2846 - acc: 0.8948 - val_loss: 0.2713 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26472\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2749 - acc: 0.9031 - val_loss: 0.2528 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26472 to 0.25279, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2674 - acc: 0.9087 - val_loss: 0.2534 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25279\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2677 - acc: 0.9021 - val_loss: 0.2509 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25279 to 0.25090, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2588 - acc: 0.9092 - val_loss: 0.2431 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.25090 to 0.24308, saving model to best.model\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2529 - acc: 0.9072 - val_loss: 0.2449 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24308\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2564 - acc: 0.9094 - val_loss: 0.2352 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24308 to 0.23524, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2469 - acc: 0.9077 - val_loss: 0.2384 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.23524\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2482 - acc: 0.9123 - val_loss: 0.2282 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23524 to 0.22822, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2332 - acc: 0.9177 - val_loss: 0.2216 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22822 to 0.22158, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2382 - acc: 0.9116 - val_loss: 0.2276 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.22158\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2275 - acc: 0.9165 - val_loss: 0.2181 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22158 to 0.21813, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2237 - acc: 0.9184 - val_loss: 0.2184 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21813\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2207 - acc: 0.9189 - val_loss: 0.2094 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21813 to 0.20937, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2288 - acc: 0.9123 - val_loss: 0.2147 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20937\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2171 - acc: 0.9194 - val_loss: 0.2011 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20937 to 0.20111, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2103 - acc: 0.9238 - val_loss: 0.1989 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20111 to 0.19886, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2056 - acc: 0.9218 - val_loss: 0.1941 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19886 to 0.19412, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2013 - acc: 0.9228 - val_loss: 0.1927 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19412 to 0.19268, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1983 - acc: 0.9287 - val_loss: 0.1877 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19268 to 0.18771, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1995 - acc: 0.9245 - val_loss: 0.1866 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18771 to 0.18657, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1968 - acc: 0.9287 - val_loss: 0.1823 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18657 to 0.18225, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1893 - acc: 0.9272 - val_loss: 0.1833 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.18225\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1876 - acc: 0.9333 - val_loss: 0.1705 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18225 to 0.17045, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9277 - val_loss: 0.1768 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17045\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9326 - val_loss: 0.1785 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17045\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1836 - acc: 0.9328 - val_loss: 0.1587 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17045 to 0.15868, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9384 - val_loss: 0.1774 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.15868\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1896 - acc: 0.9323 - val_loss: 0.1522 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15868 to 0.15223, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1704 - acc: 0.9326 - val_loss: 0.1483 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15223 to 0.14829, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1579 - acc: 0.9403 - val_loss: 0.1473 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14829 to 0.14728, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1580 - acc: 0.9389 - val_loss: 0.1425 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14728 to 0.14253, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1565 - acc: 0.9372 - val_loss: 0.1385 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14253 to 0.13852, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1536 - acc: 0.9396 - val_loss: 0.1411 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.13852\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1500 - acc: 0.9416 - val_loss: 0.1289 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13852 to 0.12891, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1539 - acc: 0.9408 - val_loss: 0.1236 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12891 to 0.12358, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1459 - acc: 0.9462 - val_loss: 0.1289 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.12358\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1444 - acc: 0.9445 - val_loss: 0.1284 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.12358\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1507 - acc: 0.9406 - val_loss: 0.1156 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12358 to 0.11562, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1438 - acc: 0.9438 - val_loss: 0.1096 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11562 to 0.10955, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1324 - acc: 0.9472 - val_loss: 0.1101 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10955\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1224 - acc: 0.9518 - val_loss: 0.1041 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10955 to 0.10406, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1262 - acc: 0.9515 - val_loss: 0.0995 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10406 to 0.09954, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1275 - acc: 0.9515 - val_loss: 0.0964 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09954 to 0.09637, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9486 - val_loss: 0.0937 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09637 to 0.09368, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1202 - acc: 0.9523 - val_loss: 0.0910 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09368 to 0.09103, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1196 - acc: 0.9557 - val_loss: 0.0868 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09103 to 0.08681, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1151 - acc: 0.9550 - val_loss: 0.0872 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08681\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1092 - acc: 0.9579 - val_loss: 0.0837 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08681 to 0.08367, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1218 - acc: 0.9525 - val_loss: 0.0794 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08367 to 0.07938, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1157 - acc: 0.9554 - val_loss: 0.0811 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07938\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9552 - val_loss: 0.0764 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07938 to 0.07636, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1146 - acc: 0.9557 - val_loss: 0.0779 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07636\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1096 - acc: 0.9533 - val_loss: 0.0757 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07636 to 0.07574, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9552 - val_loss: 0.0795 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07574\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1082 - acc: 0.9603 - val_loss: 0.0716 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.07574 to 0.07159, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9584 - val_loss: 0.0732 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.07159\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1103 - acc: 0.9586 - val_loss: 0.0678 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07159 to 0.06777, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1011 - acc: 0.9586 - val_loss: 0.0655 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06777 to 0.06550, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0957 - acc: 0.9645 - val_loss: 0.0668 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06550\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0940 - acc: 0.9625 - val_loss: 0.0622 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06550 to 0.06225, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9652 - val_loss: 0.0629 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06225\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0895 - acc: 0.9654 - val_loss: 0.0616 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06225 to 0.06161, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9705 - val_loss: 0.0559 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06161 to 0.05593, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9659 - val_loss: 0.0546 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05593 to 0.05459, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0837 - acc: 0.9674 - val_loss: 0.0554 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05459\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9701 - val_loss: 0.0516 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05459 to 0.05160, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0859 - acc: 0.9691 - val_loss: 0.0510 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05160 to 0.05103, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0803 - acc: 0.9679 - val_loss: 0.0478 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05103 to 0.04782, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9664 - val_loss: 0.0464 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04782 to 0.04644, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9730 - val_loss: 0.0461 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04644 to 0.04610, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9720 - val_loss: 0.0442 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04610 to 0.04420, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9735 - val_loss: 0.0460 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04420\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0711 - acc: 0.9735 - val_loss: 0.0454 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04420\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0732 - acc: 0.9739 - val_loss: 0.0430 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04420 to 0.04296, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9732 - val_loss: 0.0407 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04296 to 0.04066, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9703 - val_loss: 0.0448 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04066\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9722 - val_loss: 0.0405 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04066 to 0.04049, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0703 - acc: 0.9735 - val_loss: 0.0392 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04049 to 0.03923, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9769 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03923 to 0.03874, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9761 - val_loss: 0.0361 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03874 to 0.03610, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9747 - val_loss: 0.0396 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03610\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9747 - val_loss: 0.0375 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03610\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0642 - acc: 0.9747 - val_loss: 0.0379 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03610\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9708 - val_loss: 0.0469 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03610\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9739 - val_loss: 0.0359 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03610 to 0.03589, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9752 - val_loss: 0.0345 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03589 to 0.03455, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9744 - val_loss: 0.0322 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03455 to 0.03216, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0700 - acc: 0.9739 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03216\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9715 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03216 to 0.03182, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9764 - val_loss: 0.0314 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03182 to 0.03141, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9803 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03141\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9810 - val_loss: 0.0280 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03141 to 0.02798, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9805 - val_loss: 0.0271 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02798 to 0.02712, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9774 - val_loss: 0.0269 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02712 to 0.02692, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9774 - val_loss: 0.0288 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02692\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9781 - val_loss: 0.0276 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02692\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9817 - val_loss: 0.0283 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02692\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9791 - val_loss: 0.0255 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02692 to 0.02548, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0547 - acc: 0.9798 - val_loss: 0.0297 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02548\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9817 - val_loss: 0.0261 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02548\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0526 - acc: 0.9803 - val_loss: 0.0287 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02548\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9774 - val_loss: 0.0263 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02548\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9778 - val_loss: 0.0261 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02548\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.7856 - acc: 0.5218 - val_loss: 0.6679 - val_acc: 0.7459\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66785, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7440 - acc: 0.5242 - val_loss: 0.6452 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66785 to 0.64525, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6882 - acc: 0.5839 - val_loss: 0.6115 - val_acc: 0.7059\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64525 to 0.61155, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6343 - acc: 0.6535 - val_loss: 0.5419 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61155 to 0.54189, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5724 - acc: 0.7132 - val_loss: 0.4827 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54189 to 0.48269, saving model to best.model\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.5029 - acc: 0.7628 - val_loss: 0.4558 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48269 to 0.45582, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4660 - acc: 0.7935 - val_loss: 0.4142 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45582 to 0.41415, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4310 - acc: 0.8198 - val_loss: 0.3903 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41415 to 0.39028, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4019 - acc: 0.8383 - val_loss: 0.3754 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39028 to 0.37540, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3869 - acc: 0.8410 - val_loss: 0.3571 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37540 to 0.35709, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3688 - acc: 0.8568 - val_loss: 0.3392 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.35709 to 0.33917, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3603 - acc: 0.8636 - val_loss: 0.3245 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33917 to 0.32448, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3342 - acc: 0.8714 - val_loss: 0.3124 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32448 to 0.31238, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3318 - acc: 0.8702 - val_loss: 0.3027 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.31238 to 0.30267, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3137 - acc: 0.8780 - val_loss: 0.2961 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.30267 to 0.29606, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3077 - acc: 0.8851 - val_loss: 0.2842 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.29606 to 0.28424, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3067 - acc: 0.8851 - val_loss: 0.2769 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.28424 to 0.27693, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2933 - acc: 0.8912 - val_loss: 0.2693 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27693 to 0.26932, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2793 - acc: 0.8955 - val_loss: 0.2648 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.26932 to 0.26480, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2820 - acc: 0.8955 - val_loss: 0.2589 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26480 to 0.25888, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2768 - acc: 0.8968 - val_loss: 0.2520 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25888 to 0.25197, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2689 - acc: 0.9038 - val_loss: 0.2468 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25197 to 0.24683, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2644 - acc: 0.9036 - val_loss: 0.2445 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24683 to 0.24445, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2604 - acc: 0.9053 - val_loss: 0.2414 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.24445 to 0.24138, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2570 - acc: 0.9102 - val_loss: 0.2352 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24138 to 0.23518, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2402 - acc: 0.9060 - val_loss: 0.2304 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23518 to 0.23043, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2365 - acc: 0.9172 - val_loss: 0.2264 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23043 to 0.22638, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2477 - acc: 0.9111 - val_loss: 0.2228 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22638 to 0.22278, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2391 - acc: 0.9138 - val_loss: 0.2210 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22278 to 0.22105, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2382 - acc: 0.9143 - val_loss: 0.2183 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22105 to 0.21829, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2284 - acc: 0.9179 - val_loss: 0.2172 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21829 to 0.21724, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2272 - acc: 0.9165 - val_loss: 0.2110 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21724 to 0.21098, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2222 - acc: 0.9167 - val_loss: 0.2077 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.21098 to 0.20771, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2149 - acc: 0.9255 - val_loss: 0.2052 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20771 to 0.20517, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2091 - acc: 0.9262 - val_loss: 0.2029 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20517 to 0.20287, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2119 - acc: 0.9270 - val_loss: 0.1997 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20287 to 0.19968, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2095 - acc: 0.9252 - val_loss: 0.1974 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19968 to 0.19743, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9284 - val_loss: 0.1925 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19743 to 0.19251, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9235 - val_loss: 0.1952 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.19251\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2088 - acc: 0.9209 - val_loss: 0.1879 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19251 to 0.18795, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2002 - acc: 0.9274 - val_loss: 0.1839 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18795 to 0.18385, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1958 - acc: 0.9311 - val_loss: 0.1817 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18385 to 0.18169, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1941 - acc: 0.9316 - val_loss: 0.1815 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.18169 to 0.18146, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1859 - acc: 0.9345 - val_loss: 0.1782 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.18146 to 0.17819, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1913 - acc: 0.9340 - val_loss: 0.1751 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17819 to 0.17512, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1880 - acc: 0.9352 - val_loss: 0.1720 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17512 to 0.17197, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1820 - acc: 0.9362 - val_loss: 0.1715 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17197 to 0.17155, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1822 - acc: 0.9367 - val_loss: 0.1667 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.17155 to 0.16668, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1720 - acc: 0.9369 - val_loss: 0.1664 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.16668 to 0.16635, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1701 - acc: 0.9399 - val_loss: 0.1606 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.16635 to 0.16062, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1739 - acc: 0.9386 - val_loss: 0.1595 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.16062 to 0.15949, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1672 - acc: 0.9421 - val_loss: 0.1552 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15949 to 0.15516, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1694 - acc: 0.9421 - val_loss: 0.1528 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.15516 to 0.15277, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9442 - val_loss: 0.1525 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.15277 to 0.15252, saving model to best.model\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1593 - acc: 0.9467 - val_loss: 0.1515 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.15252 to 0.15149, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1605 - acc: 0.9472 - val_loss: 0.1459 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.15149 to 0.14586, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1490 - acc: 0.9472 - val_loss: 0.1437 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.14586 to 0.14375, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1551 - acc: 0.9442 - val_loss: 0.1410 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.14375 to 0.14096, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1529 - acc: 0.9455 - val_loss: 0.1390 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.14096 to 0.13904, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1475 - acc: 0.9472 - val_loss: 0.1324 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.13904 to 0.13239, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1445 - acc: 0.9506 - val_loss: 0.1303 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13239 to 0.13028, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1500 - acc: 0.9462 - val_loss: 0.1316 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.13028\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1500 - acc: 0.9450 - val_loss: 0.1250 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.13028 to 0.12497, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1378 - acc: 0.9547 - val_loss: 0.1261 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.12497\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1320 - acc: 0.9503 - val_loss: 0.1159 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.12497 to 0.11586, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1346 - acc: 0.9489 - val_loss: 0.1143 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11586 to 0.11430, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1270 - acc: 0.9513 - val_loss: 0.1060 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.11430 to 0.10595, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1277 - acc: 0.9554 - val_loss: 0.1040 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10595 to 0.10403, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1326 - acc: 0.9515 - val_loss: 0.0968 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10403 to 0.09684, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1243 - acc: 0.9559 - val_loss: 0.0966 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09684 to 0.09664, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1156 - acc: 0.9601 - val_loss: 0.0910 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.09664 to 0.09102, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1289 - acc: 0.9530 - val_loss: 0.0879 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.09102 to 0.08792, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1158 - acc: 0.9557 - val_loss: 0.0840 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08792 to 0.08404, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1073 - acc: 0.9630 - val_loss: 0.0842 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08404\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1201 - acc: 0.9567 - val_loss: 0.0833 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08404 to 0.08330, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1145 - acc: 0.9576 - val_loss: 0.0799 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08330 to 0.07994, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1193 - acc: 0.9564 - val_loss: 0.0800 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07994\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1104 - acc: 0.9596 - val_loss: 0.0774 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07994 to 0.07737, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1095 - acc: 0.9569 - val_loss: 0.0727 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07737 to 0.07274, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9606 - val_loss: 0.0701 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07274 to 0.07006, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1064 - acc: 0.9581 - val_loss: 0.0736 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07006\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1025 - acc: 0.9608 - val_loss: 0.0659 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07006 to 0.06594, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1031 - acc: 0.9635 - val_loss: 0.0651 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06594 to 0.06513, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0950 - acc: 0.9640 - val_loss: 0.0669 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06513\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9623 - val_loss: 0.0622 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06513 to 0.06220, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0991 - acc: 0.9662 - val_loss: 0.0590 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06220 to 0.05896, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0935 - acc: 0.9637 - val_loss: 0.0589 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05896 to 0.05894, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0937 - acc: 0.9671 - val_loss: 0.0556 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05894 to 0.05559, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0934 - acc: 0.9657 - val_loss: 0.0560 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05559\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0912 - acc: 0.9654 - val_loss: 0.0545 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05559 to 0.05454, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0850 - acc: 0.9710 - val_loss: 0.0543 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05454 to 0.05431, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9686 - val_loss: 0.0538 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05431 to 0.05381, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0824 - acc: 0.9718 - val_loss: 0.0519 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05381 to 0.05193, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0856 - acc: 0.9642 - val_loss: 0.0488 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05193 to 0.04882, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0890 - acc: 0.9691 - val_loss: 0.0491 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04882\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9703 - val_loss: 0.0476 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04882 to 0.04765, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0797 - acc: 0.9696 - val_loss: 0.0463 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04765 to 0.04625, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9676 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04625 to 0.04507, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0729 - acc: 0.9730 - val_loss: 0.0424 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04507 to 0.04243, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0797 - acc: 0.9727 - val_loss: 0.0430 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04243\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0758 - acc: 0.9727 - val_loss: 0.0425 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04243\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9705 - val_loss: 0.0418 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04243 to 0.04177, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9727 - val_loss: 0.0411 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.04177 to 0.04112, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9725 - val_loss: 0.0388 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04112 to 0.03881, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9754 - val_loss: 0.0377 - val_acc: 0.9854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_loss improved from 0.03881 to 0.03767, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0697 - acc: 0.9713 - val_loss: 0.0374 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03767 to 0.03736, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9759 - val_loss: 0.0353 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03736 to 0.03528, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9764 - val_loss: 0.0432 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03528\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9735 - val_loss: 0.0349 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03528 to 0.03492, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9735 - val_loss: 0.0341 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03492 to 0.03407, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0714 - acc: 0.9739 - val_loss: 0.0437 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03407\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9769 - val_loss: 0.0325 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03407 to 0.03253, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9752 - val_loss: 0.0317 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03253 to 0.03175, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9757 - val_loss: 0.0320 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03175\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9766 - val_loss: 0.0296 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03175 to 0.02955, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0632 - acc: 0.9749 - val_loss: 0.0301 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02955\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9754 - val_loss: 0.0288 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02955 to 0.02879, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9776 - val_loss: 0.0309 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02879\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9813 - val_loss: 0.0276 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02879 to 0.02759, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9774 - val_loss: 0.0272 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02759 to 0.02715, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9766 - val_loss: 0.0276 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02715\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9739 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02715\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0571 - acc: 0.9761 - val_loss: 0.0288 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02715\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9749 - val_loss: 0.0275 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02715\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9788 - val_loss: 0.0258 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02715 to 0.02576, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0571 - acc: 0.9771 - val_loss: 0.0248 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02576 to 0.02483, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9810 - val_loss: 0.0271 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02483\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9754 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02483\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9788 - val_loss: 0.0257 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02483\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9795 - val_loss: 0.0302 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02483\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9815 - val_loss: 0.0229 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02483 to 0.02292, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9805 - val_loss: 0.0220 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02292 to 0.02195, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0474 - acc: 0.9805 - val_loss: 0.0257 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02195\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9788 - val_loss: 0.0204 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.02195 to 0.02039, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9854 - val_loss: 0.0240 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02039\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9808 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02039\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9813 - val_loss: 0.0203 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.02039 to 0.02026, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9817 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02026\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9827 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02026\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9832 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.02026 to 0.01885, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0397 - acc: 0.9851 - val_loss: 0.0266 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01885\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0499 - acc: 0.9800 - val_loss: 0.0181 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01885 to 0.01806, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9832 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01806\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0409 - acc: 0.9851 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.01806 to 0.01667, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9834 - val_loss: 0.0182 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01667\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9842 - val_loss: 0.0184 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01667\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9861 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01667\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0467 - acc: 0.9839 - val_loss: 0.0166 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01667 to 0.01663, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0466 - acc: 0.9817 - val_loss: 0.0210 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01663\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9844 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.01663 to 0.01537, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9834 - val_loss: 0.0184 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01537\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9864 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01537\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0365 - acc: 0.9869 - val_loss: 0.0142 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01537 to 0.01422, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9851 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01422\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9813 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01422\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9837 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01422\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9839 - val_loss: 0.0152 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01422\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9847 - val_loss: 0.0176 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01422\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.7972 - acc: 0.5189 - val_loss: 0.6705 - val_acc: 0.7215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67052, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7473 - acc: 0.5279 - val_loss: 0.6463 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67052 to 0.64629, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7034 - acc: 0.5722 - val_loss: 0.6051 - val_acc: 0.7371\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64629 to 0.60509, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6558 - acc: 0.6209 - val_loss: 0.5601 - val_acc: 0.7342\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60509 to 0.56012, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5974 - acc: 0.6815 - val_loss: 0.4790 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56012 to 0.47900, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5274 - acc: 0.7495 - val_loss: 0.4263 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47900 to 0.42630, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4727 - acc: 0.7896 - val_loss: 0.3972 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42630 to 0.39722, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4393 - acc: 0.8118 - val_loss: 0.3607 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39722 to 0.36073, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4170 - acc: 0.8315 - val_loss: 0.3412 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36073 to 0.34117, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3882 - acc: 0.8339 - val_loss: 0.3313 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34117 to 0.33129, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3749 - acc: 0.8478 - val_loss: 0.3222 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33129 to 0.32223, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3656 - acc: 0.8527 - val_loss: 0.3084 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.32223 to 0.30839, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3544 - acc: 0.8610 - val_loss: 0.3026 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.30839 to 0.30264, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3402 - acc: 0.8695 - val_loss: 0.2989 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.30264 to 0.29895, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3267 - acc: 0.8719 - val_loss: 0.2901 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.29895 to 0.29011, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3069 - acc: 0.8822 - val_loss: 0.2842 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.29011 to 0.28422, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3084 - acc: 0.8834 - val_loss: 0.2840 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.28422 to 0.28400, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2918 - acc: 0.8946 - val_loss: 0.2926 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.28400\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2991 - acc: 0.8892 - val_loss: 0.2746 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.28400 to 0.27461, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2962 - acc: 0.8909 - val_loss: 0.2697 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.27461 to 0.26974, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2912 - acc: 0.8965 - val_loss: 0.2655 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.26974 to 0.26550, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2749 - acc: 0.8985 - val_loss: 0.2746 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26550\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2778 - acc: 0.9024 - val_loss: 0.2623 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.26550 to 0.26226, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2737 - acc: 0.9021 - val_loss: 0.2587 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.26226 to 0.25865, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2670 - acc: 0.9004 - val_loss: 0.2631 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.25865\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2672 - acc: 0.9011 - val_loss: 0.2540 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.25865 to 0.25398, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2684 - acc: 0.9014 - val_loss: 0.2497 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.25398 to 0.24972, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2499 - acc: 0.9111 - val_loss: 0.2503 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.24972\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2617 - acc: 0.9058 - val_loss: 0.2512 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.24972\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2546 - acc: 0.9121 - val_loss: 0.2397 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.24972 to 0.23972, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2418 - acc: 0.9138 - val_loss: 0.2436 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.23972\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2428 - acc: 0.9131 - val_loss: 0.2326 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.23972 to 0.23260, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2393 - acc: 0.9109 - val_loss: 0.2323 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.23260 to 0.23230, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2355 - acc: 0.9131 - val_loss: 0.2275 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.23230 to 0.22745, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2332 - acc: 0.9133 - val_loss: 0.2192 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.22745 to 0.21924, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2412 - acc: 0.9097 - val_loss: 0.2277 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.21924\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2253 - acc: 0.9162 - val_loss: 0.2152 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.21924 to 0.21518, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2189 - acc: 0.9196 - val_loss: 0.2129 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.21518 to 0.21286, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2139 - acc: 0.9189 - val_loss: 0.2029 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.21286 to 0.20295, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2185 - acc: 0.9192 - val_loss: 0.2105 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20295\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2119 - acc: 0.9187 - val_loss: 0.1958 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.20295 to 0.19575, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2104 - acc: 0.9214 - val_loss: 0.1916 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.19575 to 0.19156, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2056 - acc: 0.9211 - val_loss: 0.1970 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.19156\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1970 - acc: 0.9262 - val_loss: 0.1826 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.19156 to 0.18265, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1900 - acc: 0.9250 - val_loss: 0.1830 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.18265\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1950 - acc: 0.9267 - val_loss: 0.1757 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.18265 to 0.17572, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1942 - acc: 0.9289 - val_loss: 0.1687 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17572 to 0.16866, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9265 - val_loss: 0.1632 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.16866 to 0.16318, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1829 - acc: 0.9301 - val_loss: 0.1587 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.16318 to 0.15875, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1853 - acc: 0.9296 - val_loss: 0.1538 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15875 to 0.15382, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1717 - acc: 0.9362 - val_loss: 0.1632 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.15382\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1751 - acc: 0.9328 - val_loss: 0.1412 - val_acc: 0.9464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_loss improved from 0.15382 to 0.14118, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1719 - acc: 0.9326 - val_loss: 0.1419 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.14118\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1780 - acc: 0.9311 - val_loss: 0.1506 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.14118\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1716 - acc: 0.9396 - val_loss: 0.1298 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14118 to 0.12978, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1598 - acc: 0.9430 - val_loss: 0.1318 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.12978\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1557 - acc: 0.9435 - val_loss: 0.1242 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12978 to 0.12424, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1613 - acc: 0.9396 - val_loss: 0.1192 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12424 to 0.11925, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1493 - acc: 0.9457 - val_loss: 0.1208 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.11925\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1498 - acc: 0.9447 - val_loss: 0.1233 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.11925\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1524 - acc: 0.9435 - val_loss: 0.1173 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11925 to 0.11728, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1467 - acc: 0.9477 - val_loss: 0.1116 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11728 to 0.11159, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1432 - acc: 0.9457 - val_loss: 0.1062 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11159 to 0.10615, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1338 - acc: 0.9525 - val_loss: 0.1029 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10615 to 0.10292, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1380 - acc: 0.9489 - val_loss: 0.1022 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10292 to 0.10217, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9559 - val_loss: 0.1019 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10217 to 0.10194, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9506 - val_loss: 0.1053 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10194\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1353 - acc: 0.9511 - val_loss: 0.0923 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10194 to 0.09235, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1321 - acc: 0.9547 - val_loss: 0.0961 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.09235\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9523 - val_loss: 0.0872 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09235 to 0.08716, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1301 - acc: 0.9523 - val_loss: 0.0974 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08716\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1221 - acc: 0.9574 - val_loss: 0.0874 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08716\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1215 - acc: 0.9545 - val_loss: 0.0842 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08716 to 0.08422, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1164 - acc: 0.9542 - val_loss: 0.0836 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08422 to 0.08359, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1179 - acc: 0.9542 - val_loss: 0.0755 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08359 to 0.07550, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1126 - acc: 0.9564 - val_loss: 0.0747 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07550 to 0.07475, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1129 - acc: 0.9579 - val_loss: 0.0737 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07475 to 0.07366, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9618 - val_loss: 0.0807 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07366\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1033 - acc: 0.9606 - val_loss: 0.0701 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07366 to 0.07006, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1078 - acc: 0.9615 - val_loss: 0.0724 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07006\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1062 - acc: 0.9627 - val_loss: 0.0694 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07006 to 0.06943, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1068 - acc: 0.9596 - val_loss: 0.0707 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.06943\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1058 - acc: 0.9601 - val_loss: 0.0656 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06943 to 0.06563, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9657 - val_loss: 0.0684 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06563\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0951 - acc: 0.9666 - val_loss: 0.0619 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06563 to 0.06191, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9613 - val_loss: 0.0640 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06191\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0854 - acc: 0.9705 - val_loss: 0.0636 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06191\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9679 - val_loss: 0.0606 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06191 to 0.06059, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0904 - acc: 0.9642 - val_loss: 0.0614 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06059\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0858 - acc: 0.9666 - val_loss: 0.0563 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06059 to 0.05628, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0827 - acc: 0.9683 - val_loss: 0.0647 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05628\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0910 - acc: 0.9669 - val_loss: 0.0552 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05628 to 0.05518, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0933 - acc: 0.9674 - val_loss: 0.0623 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05518\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0860 - acc: 0.9698 - val_loss: 0.0492 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05518 to 0.04925, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0852 - acc: 0.9686 - val_loss: 0.0567 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04925\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9701 - val_loss: 0.0514 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04925\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9727 - val_loss: 0.0483 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04925 to 0.04833, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9713 - val_loss: 0.0491 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04833\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0796 - acc: 0.9708 - val_loss: 0.0494 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04833\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0820 - acc: 0.9701 - val_loss: 0.0539 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04833\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9759 - val_loss: 0.0489 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04833\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0803 - acc: 0.9710 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04833 to 0.04463, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9713 - val_loss: 0.0512 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04463\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0777 - acc: 0.9713 - val_loss: 0.0426 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04463 to 0.04259, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9732 - val_loss: 0.0456 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04259\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0688 - acc: 0.9752 - val_loss: 0.0433 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04259\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9752 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04259 to 0.03750, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9722 - val_loss: 0.0497 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03750\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9722 - val_loss: 0.0360 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03750 to 0.03598, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9754 - val_loss: 0.0460 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03598\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9727 - val_loss: 0.0346 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03598 to 0.03462, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9764 - val_loss: 0.0461 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03462\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0642 - acc: 0.9771 - val_loss: 0.0437 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03462\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0701 - acc: 0.9742 - val_loss: 0.0409 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03462\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9747 - val_loss: 0.0481 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03462\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0663 - acc: 0.9778 - val_loss: 0.0402 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03462\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.7964 - acc: 0.5198 - val_loss: 0.6752 - val_acc: 0.4849\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67523, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7504 - acc: 0.5167 - val_loss: 0.6404 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67523 to 0.64035, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6816 - acc: 0.5844 - val_loss: 0.5920 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64035 to 0.59196, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6362 - acc: 0.6387 - val_loss: 0.5173 - val_acc: 0.8208\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59196 to 0.51735, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5461 - acc: 0.7385 - val_loss: 0.4434 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51735 to 0.44343, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4797 - acc: 0.7801 - val_loss: 0.3903 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44343 to 0.39032, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4452 - acc: 0.8152 - val_loss: 0.3619 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39032 to 0.36186, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3980 - acc: 0.8315 - val_loss: 0.3428 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36186 to 0.34282, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3858 - acc: 0.8415 - val_loss: 0.3253 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34282 to 0.32530, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3573 - acc: 0.8566 - val_loss: 0.3187 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32530 to 0.31872, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3410 - acc: 0.8675 - val_loss: 0.3066 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31872 to 0.30664, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3448 - acc: 0.8605 - val_loss: 0.3084 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.30664\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3301 - acc: 0.8731 - val_loss: 0.3137 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.30664\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3055 - acc: 0.8817 - val_loss: 0.2893 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.30664 to 0.28929, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3034 - acc: 0.8834 - val_loss: 0.2904 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28929\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2982 - acc: 0.8843 - val_loss: 0.2922 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.28929\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2862 - acc: 0.8936 - val_loss: 0.2788 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.28929 to 0.27884, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2800 - acc: 0.8897 - val_loss: 0.2740 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27884 to 0.27400, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2726 - acc: 0.8972 - val_loss: 0.2782 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.27400\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2772 - acc: 0.8948 - val_loss: 0.2719 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.27400 to 0.27189, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2704 - acc: 0.9036 - val_loss: 0.2716 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.27189 to 0.27164, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2723 - acc: 0.9026 - val_loss: 0.2644 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.27164 to 0.26440, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2598 - acc: 0.9007 - val_loss: 0.2603 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.26440 to 0.26033, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2557 - acc: 0.9053 - val_loss: 0.2526 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.26033 to 0.25263, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2469 - acc: 0.9106 - val_loss: 0.2484 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.25263 to 0.24836, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2459 - acc: 0.9121 - val_loss: 0.2472 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.24836 to 0.24716, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2374 - acc: 0.9136 - val_loss: 0.2473 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.24716\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2393 - acc: 0.9104 - val_loss: 0.2415 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.24716 to 0.24154, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2318 - acc: 0.9150 - val_loss: 0.2360 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.24154 to 0.23597, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2275 - acc: 0.9172 - val_loss: 0.2354 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.23597 to 0.23537, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2268 - acc: 0.9226 - val_loss: 0.2291 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.23537 to 0.22906, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9184 - val_loss: 0.2311 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.22906\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9187 - val_loss: 0.2262 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.22906 to 0.22616, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2146 - acc: 0.9221 - val_loss: 0.2261 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.22616 to 0.22610, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9267 - val_loss: 0.2149 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.22610 to 0.21492, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2034 - acc: 0.9265 - val_loss: 0.2109 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.21492 to 0.21091, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2034 - acc: 0.9294 - val_loss: 0.2079 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.21091 to 0.20792, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2017 - acc: 0.9313 - val_loss: 0.2045 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.20792 to 0.20450, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1955 - acc: 0.9277 - val_loss: 0.1992 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.20450 to 0.19924, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9301 - val_loss: 0.1989 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19924 to 0.19889, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1938 - acc: 0.9270 - val_loss: 0.1905 - val_acc: 0.9270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_loss improved from 0.19889 to 0.19051, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1971 - acc: 0.9289 - val_loss: 0.1890 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.19051 to 0.18895, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1854 - acc: 0.9326 - val_loss: 0.1838 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.18895 to 0.18381, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1794 - acc: 0.9345 - val_loss: 0.1848 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.18381\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1769 - acc: 0.9357 - val_loss: 0.1834 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.18381 to 0.18341, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1760 - acc: 0.9347 - val_loss: 0.1721 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.18341 to 0.17209, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1722 - acc: 0.9364 - val_loss: 0.1747 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.17209\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1782 - acc: 0.9347 - val_loss: 0.1638 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.17209 to 0.16380, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1716 - acc: 0.9372 - val_loss: 0.1580 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.16380 to 0.15795, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1653 - acc: 0.9384 - val_loss: 0.1532 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15795 to 0.15318, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9386 - val_loss: 0.1619 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.15318\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1588 - acc: 0.9411 - val_loss: 0.1467 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15318 to 0.14672, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1490 - acc: 0.9459 - val_loss: 0.1410 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14672 to 0.14102, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1562 - acc: 0.9416 - val_loss: 0.1480 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.14102\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1489 - acc: 0.9450 - val_loss: 0.1350 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14102 to 0.13499, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1547 - acc: 0.9457 - val_loss: 0.1422 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.13499\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9469 - val_loss: 0.1273 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.13499 to 0.12728, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1399 - acc: 0.9457 - val_loss: 0.1220 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12728 to 0.12201, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1369 - acc: 0.9486 - val_loss: 0.1219 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12201 to 0.12190, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1371 - acc: 0.9467 - val_loss: 0.1155 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12190 to 0.11550, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1373 - acc: 0.9506 - val_loss: 0.1104 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11550 to 0.11038, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1258 - acc: 0.9523 - val_loss: 0.1079 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11038 to 0.10785, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1328 - acc: 0.9511 - val_loss: 0.1187 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10785\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9562 - val_loss: 0.1084 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10785\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1261 - acc: 0.9545 - val_loss: 0.1083 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10785\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1212 - acc: 0.9574 - val_loss: 0.0974 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10785 to 0.09744, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1184 - acc: 0.9591 - val_loss: 0.0936 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09744 to 0.09360, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1186 - acc: 0.9576 - val_loss: 0.0953 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09360\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1071 - acc: 0.9606 - val_loss: 0.0895 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09360 to 0.08948, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1145 - acc: 0.9569 - val_loss: 0.0881 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08948 to 0.08807, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1129 - acc: 0.9545 - val_loss: 0.0843 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08807 to 0.08434, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1008 - acc: 0.9618 - val_loss: 0.0809 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08434 to 0.08090, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1184 - acc: 0.9576 - val_loss: 0.0862 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08090\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1065 - acc: 0.9598 - val_loss: 0.0777 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08090 to 0.07773, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1092 - acc: 0.9613 - val_loss: 0.0756 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07773 to 0.07561, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1038 - acc: 0.9608 - val_loss: 0.0733 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07561 to 0.07326, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0943 - acc: 0.9674 - val_loss: 0.0764 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07326\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1001 - acc: 0.9615 - val_loss: 0.0691 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07326 to 0.06909, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1007 - acc: 0.9637 - val_loss: 0.0680 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06909 to 0.06804, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0932 - acc: 0.9649 - val_loss: 0.0658 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.06804 to 0.06584, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0897 - acc: 0.9649 - val_loss: 0.0648 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06584 to 0.06477, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0935 - acc: 0.9640 - val_loss: 0.0627 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06477 to 0.06275, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1008 - acc: 0.9625 - val_loss: 0.0602 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06275 to 0.06023, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9681 - val_loss: 0.0580 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06023 to 0.05796, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9713 - val_loss: 0.0541 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05796 to 0.05410, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0884 - acc: 0.9674 - val_loss: 0.0649 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05410\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9613 - val_loss: 0.0512 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05410 to 0.05123, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0854 - acc: 0.9701 - val_loss: 0.0504 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05123 to 0.05043, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0729 - acc: 0.9735 - val_loss: 0.0592 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05043\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9676 - val_loss: 0.0511 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05043\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9713 - val_loss: 0.0468 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05043 to 0.04682, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9718 - val_loss: 0.0476 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04682\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0748 - acc: 0.9725 - val_loss: 0.0475 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04682\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9693 - val_loss: 0.0465 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04682 to 0.04651, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9722 - val_loss: 0.0503 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04651\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9708 - val_loss: 0.0456 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04651 to 0.04558, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0700 - acc: 0.9732 - val_loss: 0.0434 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04558 to 0.04338, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9742 - val_loss: 0.0437 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04338\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9747 - val_loss: 0.0409 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04338 to 0.04089, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9744 - val_loss: 0.0390 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04089 to 0.03903, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9754 - val_loss: 0.0503 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03903\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9739 - val_loss: 0.0394 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03903\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9766 - val_loss: 0.0433 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03903\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9757 - val_loss: 0.0363 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03903 to 0.03629, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9754 - val_loss: 0.0463 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03629\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0675 - acc: 0.9749 - val_loss: 0.0391 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03629\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9781 - val_loss: 0.0403 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03629\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9791 - val_loss: 0.0378 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03629\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0575 - acc: 0.9783 - val_loss: 0.0393 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03629\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 9s - loss: 0.7955 - acc: 0.5191 - val_loss: 0.6637 - val_acc: 0.5375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66368, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7560 - acc: 0.5271 - val_loss: 0.6295 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66368 to 0.62945, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6824 - acc: 0.5968 - val_loss: 0.5672 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62945 to 0.56718, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6136 - acc: 0.6633 - val_loss: 0.4841 - val_acc: 0.8238\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56718 to 0.48407, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5575 - acc: 0.7271 - val_loss: 0.4202 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48407 to 0.42025, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5006 - acc: 0.7750 - val_loss: 0.3809 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42025 to 0.38088, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4480 - acc: 0.8091 - val_loss: 0.3527 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38088 to 0.35266, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4351 - acc: 0.8167 - val_loss: 0.3316 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35266 to 0.33164, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4094 - acc: 0.8332 - val_loss: 0.3270 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33164 to 0.32703, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3945 - acc: 0.8371 - val_loss: 0.3007 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32703 to 0.30067, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3691 - acc: 0.8554 - val_loss: 0.2908 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30067 to 0.29081, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3478 - acc: 0.8619 - val_loss: 0.2803 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29081 to 0.28031, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3367 - acc: 0.8763 - val_loss: 0.2703 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28031 to 0.27030, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3355 - acc: 0.8700 - val_loss: 0.2640 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27030 to 0.26396, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3186 - acc: 0.8717 - val_loss: 0.2572 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26396 to 0.25716, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3087 - acc: 0.8804 - val_loss: 0.2498 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25716 to 0.24978, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3039 - acc: 0.8890 - val_loss: 0.2454 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24978 to 0.24540, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2955 - acc: 0.8897 - val_loss: 0.2408 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24540 to 0.24083, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2993 - acc: 0.8865 - val_loss: 0.2367 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24083 to 0.23674, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2859 - acc: 0.8919 - val_loss: 0.2304 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23674 to 0.23041, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2767 - acc: 0.8963 - val_loss: 0.2269 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23041 to 0.22688, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2753 - acc: 0.8965 - val_loss: 0.2285 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.22688\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2648 - acc: 0.9009 - val_loss: 0.2191 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22688 to 0.21911, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2632 - acc: 0.9014 - val_loss: 0.2139 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21911 to 0.21391, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2550 - acc: 0.9080 - val_loss: 0.2111 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21391 to 0.21110, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2551 - acc: 0.9075 - val_loss: 0.2073 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21110 to 0.20725, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2437 - acc: 0.9092 - val_loss: 0.2029 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20725 to 0.20292, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9089 - val_loss: 0.2017 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20292 to 0.20165, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2457 - acc: 0.9092 - val_loss: 0.1987 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20165 to 0.19873, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2418 - acc: 0.9116 - val_loss: 0.1930 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19873 to 0.19302, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2243 - acc: 0.9209 - val_loss: 0.1894 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19302 to 0.18939, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2343 - acc: 0.9087 - val_loss: 0.1839 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.18939 to 0.18386, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2295 - acc: 0.9121 - val_loss: 0.1820 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18386 to 0.18203, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2216 - acc: 0.9194 - val_loss: 0.1770 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18203 to 0.17703, saving model to best.model\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2152 - acc: 0.9218 - val_loss: 0.1769 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17703 to 0.17692, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2168 - acc: 0.9238 - val_loss: 0.1746 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17692 to 0.17464, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2092 - acc: 0.9240 - val_loss: 0.1668 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17464 to 0.16677, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2075 - acc: 0.9267 - val_loss: 0.1652 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16677 to 0.16523, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2011 - acc: 0.9226 - val_loss: 0.1593 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16523 to 0.15934, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2003 - acc: 0.9252 - val_loss: 0.1541 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15934 to 0.15408, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1972 - acc: 0.9289 - val_loss: 0.1509 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15408 to 0.15088, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1824 - acc: 0.9291 - val_loss: 0.1468 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15088 to 0.14684, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1941 - acc: 0.9289 - val_loss: 0.1498 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.14684\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1906 - acc: 0.9226 - val_loss: 0.1389 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14684 to 0.13890, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1785 - acc: 0.9321 - val_loss: 0.1362 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13890 to 0.13625, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1828 - acc: 0.9355 - val_loss: 0.1330 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13625 to 0.13302, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1689 - acc: 0.9313 - val_loss: 0.1275 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13302 to 0.12755, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1690 - acc: 0.9377 - val_loss: 0.1240 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12755 to 0.12400, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1721 - acc: 0.9355 - val_loss: 0.1207 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12400 to 0.12074, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1594 - acc: 0.9423 - val_loss: 0.1170 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12074 to 0.11700, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1576 - acc: 0.9399 - val_loss: 0.1147 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11700 to 0.11474, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1533 - acc: 0.9406 - val_loss: 0.1125 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11474 to 0.11247, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1583 - acc: 0.9399 - val_loss: 0.1083 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11247 to 0.10829, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1609 - acc: 0.9389 - val_loss: 0.1054 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10829 to 0.10536, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1445 - acc: 0.9462 - val_loss: 0.1026 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10536 to 0.10261, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1428 - acc: 0.9462 - val_loss: 0.1005 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10261 to 0.10051, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1527 - acc: 0.9408 - val_loss: 0.1012 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10051\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1449 - acc: 0.9459 - val_loss: 0.0977 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10051 to 0.09767, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1364 - acc: 0.9477 - val_loss: 0.0939 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09767 to 0.09386, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1299 - acc: 0.9503 - val_loss: 0.0920 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09386 to 0.09196, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1318 - acc: 0.9472 - val_loss: 0.0896 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09196 to 0.08956, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1254 - acc: 0.9533 - val_loss: 0.0870 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08956 to 0.08696, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9423 - val_loss: 0.0852 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08696 to 0.08516, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1315 - acc: 0.9503 - val_loss: 0.0821 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08516 to 0.08206, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1247 - acc: 0.9501 - val_loss: 0.0830 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08206\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1301 - acc: 0.9523 - val_loss: 0.0820 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08206 to 0.08201, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1235 - acc: 0.9481 - val_loss: 0.0794 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08201 to 0.07937, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1208 - acc: 0.9506 - val_loss: 0.0781 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07937 to 0.07813, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9520 - val_loss: 0.0752 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07813 to 0.07524, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1154 - acc: 0.9511 - val_loss: 0.0736 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07524 to 0.07361, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1100 - acc: 0.9581 - val_loss: 0.0712 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07361 to 0.07118, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1086 - acc: 0.9576 - val_loss: 0.0682 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07118 to 0.06824, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9593 - val_loss: 0.0667 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06824 to 0.06675, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9589 - val_loss: 0.0647 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06675 to 0.06468, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1024 - acc: 0.9589 - val_loss: 0.0675 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06468\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9593 - val_loss: 0.0643 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06468 to 0.06429, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9627 - val_loss: 0.0638 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06429 to 0.06376, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1065 - acc: 0.9576 - val_loss: 0.0608 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06376 to 0.06084, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9581 - val_loss: 0.0634 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06084\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9523 - val_loss: 0.0611 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06084\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0968 - acc: 0.9654 - val_loss: 0.0581 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06084 to 0.05807, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1010 - acc: 0.9635 - val_loss: 0.0583 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05807\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0962 - acc: 0.9632 - val_loss: 0.0571 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05807 to 0.05708, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0911 - acc: 0.9618 - val_loss: 0.0549 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05708 to 0.05489, saving model to best.model\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0972 - acc: 0.9627 - val_loss: 0.0561 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05489\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0999 - acc: 0.9637 - val_loss: 0.0526 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05489 to 0.05264, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0884 - acc: 0.9679 - val_loss: 0.0514 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05264 to 0.05140, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0912 - acc: 0.9657 - val_loss: 0.0489 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05140 to 0.04891, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0875 - acc: 0.9688 - val_loss: 0.0493 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04891\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9645 - val_loss: 0.0473 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04891 to 0.04727, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0850 - acc: 0.9647 - val_loss: 0.0499 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04727\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9727 - val_loss: 0.0447 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04727 to 0.04465, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9683 - val_loss: 0.0442 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04465 to 0.04420, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9698 - val_loss: 0.0430 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04420 to 0.04300, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0828 - acc: 0.9701 - val_loss: 0.0422 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04300 to 0.04219, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9701 - val_loss: 0.0416 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04219 to 0.04157, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0866 - acc: 0.9669 - val_loss: 0.0387 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04157 to 0.03872, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9701 - val_loss: 0.0390 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03872\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9686 - val_loss: 0.0387 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03872 to 0.03869, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0807 - acc: 0.9679 - val_loss: 0.0373 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03869 to 0.03725, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9701 - val_loss: 0.0360 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03725 to 0.03604, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0723 - acc: 0.9730 - val_loss: 0.0409 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03604\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9705 - val_loss: 0.0358 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03604 to 0.03579, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9739 - val_loss: 0.0385 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03579\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0688 - acc: 0.9739 - val_loss: 0.0344 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03579 to 0.03439, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9739 - val_loss: 0.0354 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03439\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9727 - val_loss: 0.0321 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03439 to 0.03212, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9749 - val_loss: 0.0339 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03212\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9761 - val_loss: 0.0342 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03212\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9713 - val_loss: 0.0342 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03212\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9732 - val_loss: 0.0365 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03212\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9776 - val_loss: 0.0328 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03212\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 10s - loss: 0.7937 - acc: 0.4953 - val_loss: 0.6709 - val_acc: 0.6787\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67093, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7247 - acc: 0.5401 - val_loss: 0.6391 - val_acc: 0.7546\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67093 to 0.63908, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6823 - acc: 0.5878 - val_loss: 0.5767 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63908 to 0.57673, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6088 - acc: 0.6669 - val_loss: 0.4950 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57673 to 0.49502, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5233 - acc: 0.7594 - val_loss: 0.4258 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49502 to 0.42585, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4638 - acc: 0.7962 - val_loss: 0.3850 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42585 to 0.38497, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4333 - acc: 0.8206 - val_loss: 0.3550 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38497 to 0.35501, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4009 - acc: 0.8408 - val_loss: 0.3317 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35501 to 0.33167, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3823 - acc: 0.8427 - val_loss: 0.3174 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33167 to 0.31737, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3670 - acc: 0.8585 - val_loss: 0.3084 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31737 to 0.30838, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3453 - acc: 0.8661 - val_loss: 0.2882 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30838 to 0.28818, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3260 - acc: 0.8717 - val_loss: 0.2796 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28818 to 0.27964, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3301 - acc: 0.8722 - val_loss: 0.2725 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27964 to 0.27253, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3088 - acc: 0.8809 - val_loss: 0.2626 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27253 to 0.26260, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3021 - acc: 0.8909 - val_loss: 0.2632 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26260\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2877 - acc: 0.8921 - val_loss: 0.2470 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26260 to 0.24701, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2860 - acc: 0.8953 - val_loss: 0.2444 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24701 to 0.24438, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2702 - acc: 0.9007 - val_loss: 0.2332 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24438 to 0.23323, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2740 - acc: 0.9019 - val_loss: 0.2299 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23323 to 0.22993, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2664 - acc: 0.9055 - val_loss: 0.2272 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22993 to 0.22718, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2562 - acc: 0.9041 - val_loss: 0.2205 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22718 to 0.22048, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2475 - acc: 0.9140 - val_loss: 0.2164 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22048 to 0.21640, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9140 - val_loss: 0.2096 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21640 to 0.20958, saving model to best.model\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2400 - acc: 0.9136 - val_loss: 0.2124 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20958\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2390 - acc: 0.9196 - val_loss: 0.2044 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20958 to 0.20441, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2377 - acc: 0.9162 - val_loss: 0.1981 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20441 to 0.19815, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2290 - acc: 0.9184 - val_loss: 0.1918 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19815 to 0.19182, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2196 - acc: 0.9235 - val_loss: 0.1905 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19182 to 0.19054, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2218 - acc: 0.9211 - val_loss: 0.1835 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19054 to 0.18346, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2192 - acc: 0.9216 - val_loss: 0.1784 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18346 to 0.17840, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2202 - acc: 0.9209 - val_loss: 0.1785 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.17840\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2128 - acc: 0.9240 - val_loss: 0.1717 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17840 to 0.17167, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9279 - val_loss: 0.1769 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.17167\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2005 - acc: 0.9277 - val_loss: 0.1618 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17167 to 0.16182, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1923 - acc: 0.9304 - val_loss: 0.1575 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16182 to 0.15752, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2005 - acc: 0.9289 - val_loss: 0.1542 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15752 to 0.15419, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1907 - acc: 0.9330 - val_loss: 0.1549 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15419\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1987 - acc: 0.9299 - val_loss: 0.1565 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15419\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1854 - acc: 0.9289 - val_loss: 0.1478 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15419 to 0.14778, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1867 - acc: 0.9316 - val_loss: 0.1509 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14778\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1798 - acc: 0.9374 - val_loss: 0.1435 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14778 to 0.14350, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1778 - acc: 0.9335 - val_loss: 0.1382 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14350 to 0.13821, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1748 - acc: 0.9367 - val_loss: 0.1366 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13821 to 0.13658, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1681 - acc: 0.9372 - val_loss: 0.1344 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13658 to 0.13445, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1683 - acc: 0.9369 - val_loss: 0.1254 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13445 to 0.12542, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1618 - acc: 0.9423 - val_loss: 0.1284 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.12542\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1619 - acc: 0.9416 - val_loss: 0.1261 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.12542\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1650 - acc: 0.9416 - val_loss: 0.1181 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12542 to 0.11806, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1642 - acc: 0.9435 - val_loss: 0.1242 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11806\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1542 - acc: 0.9455 - val_loss: 0.1199 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11806\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1605 - acc: 0.9411 - val_loss: 0.1118 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11806 to 0.11179, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1540 - acc: 0.9467 - val_loss: 0.1151 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.11179\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1477 - acc: 0.9481 - val_loss: 0.1071 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11179 to 0.10707, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9472 - val_loss: 0.1084 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10707\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1496 - acc: 0.9489 - val_loss: 0.1097 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10707\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9496 - val_loss: 0.1003 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10707 to 0.10029, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9515 - val_loss: 0.1024 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10029\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1445 - acc: 0.9479 - val_loss: 0.0971 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10029 to 0.09708, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1411 - acc: 0.9503 - val_loss: 0.0948 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09708 to 0.09481, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1364 - acc: 0.9513 - val_loss: 0.0906 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09481 to 0.09057, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1271 - acc: 0.9550 - val_loss: 0.0918 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.09057\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1332 - acc: 0.9501 - val_loss: 0.0909 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.09057\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1215 - acc: 0.9584 - val_loss: 0.0852 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09057 to 0.08517, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1242 - acc: 0.9574 - val_loss: 0.0812 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08517 to 0.08116, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1244 - acc: 0.9564 - val_loss: 0.0827 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08116\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9606 - val_loss: 0.0847 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08116\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1255 - acc: 0.9540 - val_loss: 0.0760 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08116 to 0.07598, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9535 - val_loss: 0.0744 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07598 to 0.07441, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9593 - val_loss: 0.0755 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07441\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1167 - acc: 0.9591 - val_loss: 0.0698 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07441 to 0.06976, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1171 - acc: 0.9564 - val_loss: 0.0691 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06976 to 0.06908, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1109 - acc: 0.9620 - val_loss: 0.0767 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06908\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1098 - acc: 0.9613 - val_loss: 0.0620 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06908 to 0.06205, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1037 - acc: 0.9608 - val_loss: 0.0622 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06205\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0997 - acc: 0.9618 - val_loss: 0.0578 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06205 to 0.05778, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0988 - acc: 0.9625 - val_loss: 0.0602 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05778\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1027 - acc: 0.9623 - val_loss: 0.0536 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05778 to 0.05356, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9652 - val_loss: 0.0466 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05356 to 0.04655, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0953 - acc: 0.9625 - val_loss: 0.0430 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04655 to 0.04295, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0950 - acc: 0.9649 - val_loss: 0.0493 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04295\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0971 - acc: 0.9625 - val_loss: 0.0427 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04295 to 0.04266, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0976 - acc: 0.9659 - val_loss: 0.0475 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04266\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9615 - val_loss: 0.0445 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04266\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9647 - val_loss: 0.0388 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04266 to 0.03877, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0903 - acc: 0.9657 - val_loss: 0.0396 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03877\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0935 - acc: 0.9645 - val_loss: 0.0396 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03877\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0959 - acc: 0.9632 - val_loss: 0.0357 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.03877 to 0.03567, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0857 - acc: 0.9654 - val_loss: 0.0335 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03567 to 0.03346, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0862 - acc: 0.9679 - val_loss: 0.0327 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03346 to 0.03271, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9683 - val_loss: 0.0365 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03271\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9640 - val_loss: 0.0311 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03271 to 0.03112, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0744 - acc: 0.9749 - val_loss: 0.0332 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03112\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9732 - val_loss: 0.0307 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03112 to 0.03072, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0775 - acc: 0.9701 - val_loss: 0.0279 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03072 to 0.02793, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9720 - val_loss: 0.0279 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02793\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9722 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02793\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0729 - acc: 0.9715 - val_loss: 0.0265 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02793 to 0.02651, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0740 - acc: 0.9739 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02651 to 0.02545, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0759 - acc: 0.9742 - val_loss: 0.0261 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02545\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0789 - acc: 0.9696 - val_loss: 0.0266 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02545\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9774 - val_loss: 0.0228 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.02545 to 0.02281, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9742 - val_loss: 0.0266 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02281\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0660 - acc: 0.9786 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02281\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9759 - val_loss: 0.0223 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02281 to 0.02230, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9718 - val_loss: 0.0212 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02230 to 0.02118, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0688 - acc: 0.9742 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02118 to 0.02094, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9752 - val_loss: 0.0202 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02094 to 0.02021, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0741 - acc: 0.9735 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02021\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9761 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02021\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0557 - acc: 0.9798 - val_loss: 0.0198 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02021 to 0.01979, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9771 - val_loss: 0.0188 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.01979 to 0.01880, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9739 - val_loss: 0.0214 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01880\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9810 - val_loss: 0.0183 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.01880 to 0.01826, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9761 - val_loss: 0.0175 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01826 to 0.01752, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0615 - acc: 0.9754 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.01752 to 0.01730, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9778 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01730 to 0.01665, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9764 - val_loss: 0.0171 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01665\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9771 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.01665 to 0.01641, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9764 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01641\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9781 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01641\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9795 - val_loss: 0.0151 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01641 to 0.01514, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9815 - val_loss: 0.0162 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01514\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0550 - acc: 0.9788 - val_loss: 0.0162 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01514\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9803 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01514 to 0.01474, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9815 - val_loss: 0.0149 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01474\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9817 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01474 to 0.01393, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9803 - val_loss: 0.0149 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01393\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9795 - val_loss: 0.0134 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01393 to 0.01341, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9837 - val_loss: 0.0145 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01341\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0532 - acc: 0.9810 - val_loss: 0.0142 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01341\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9808 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01341 to 0.01258, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9815 - val_loss: 0.0152 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01258\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9813 - val_loss: 0.0134 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01258\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9803 - val_loss: 0.0131 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01258\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9830 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01258\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9871 - val_loss: 0.0114 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01258 to 0.01137, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9837 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01137\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9827 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01137 to 0.01073, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9820 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01073\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9815 - val_loss: 0.0133 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01073\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9842 - val_loss: 0.0124 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01073\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9837 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01073 to 0.01004, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9881 - val_loss: 0.0105 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01004\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0437 - acc: 0.9800 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01004\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9820 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.01004 to 0.00876, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9837 - val_loss: 0.0144 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00876\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9822 - val_loss: 0.0085 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00876 to 0.00847, saving model to best.model\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9844 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00847\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0409 - acc: 0.9844 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00847\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0414 - acc: 0.9837 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00847\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0410 - acc: 0.9830 - val_loss: 0.0087 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00847\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9810 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00847\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 10s - loss: 0.8099 - acc: 0.5023 - val_loss: 0.6777 - val_acc: 0.4917\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67769, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7492 - acc: 0.5252 - val_loss: 0.6510 - val_acc: 0.7235\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67769 to 0.65096, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7082 - acc: 0.5547 - val_loss: 0.6029 - val_acc: 0.8014\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65096 to 0.60294, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6493 - acc: 0.6133 - val_loss: 0.5351 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60294 to 0.53507, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5828 - acc: 0.7042 - val_loss: 0.4631 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53507 to 0.46313, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5161 - acc: 0.7607 - val_loss: 0.4014 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46313 to 0.40139, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4614 - acc: 0.7972 - val_loss: 0.3624 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40139 to 0.36238, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4324 - acc: 0.8201 - val_loss: 0.3393 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36238 to 0.33926, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4044 - acc: 0.8359 - val_loss: 0.3166 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33926 to 0.31659, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3743 - acc: 0.8493 - val_loss: 0.3023 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31659 to 0.30228, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3642 - acc: 0.8593 - val_loss: 0.2843 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30228 to 0.28426, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3467 - acc: 0.8629 - val_loss: 0.2738 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28426 to 0.27379, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3431 - acc: 0.8651 - val_loss: 0.2801 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27379\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3281 - acc: 0.8712 - val_loss: 0.2599 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27379 to 0.25992, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3147 - acc: 0.8800 - val_loss: 0.2489 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25992 to 0.24893, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3053 - acc: 0.8858 - val_loss: 0.2468 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24893 to 0.24683, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2959 - acc: 0.8873 - val_loss: 0.2401 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24683 to 0.24005, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2855 - acc: 0.8875 - val_loss: 0.2385 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24005 to 0.23854, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2805 - acc: 0.8936 - val_loss: 0.2305 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23854 to 0.23046, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2760 - acc: 0.8972 - val_loss: 0.2354 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.23046\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2689 - acc: 0.9021 - val_loss: 0.2223 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23046 to 0.22231, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2627 - acc: 0.9004 - val_loss: 0.2270 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.22231\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2579 - acc: 0.9065 - val_loss: 0.2153 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22231 to 0.21528, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2528 - acc: 0.9067 - val_loss: 0.2121 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21528 to 0.21213, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2465 - acc: 0.9116 - val_loss: 0.2086 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21213 to 0.20861, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2517 - acc: 0.9070 - val_loss: 0.2056 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20861 to 0.20562, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2389 - acc: 0.9109 - val_loss: 0.2003 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20562 to 0.20032, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2294 - acc: 0.9189 - val_loss: 0.1980 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20032 to 0.19800, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2297 - acc: 0.9148 - val_loss: 0.1972 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19800 to 0.19725, saving model to best.model\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2366 - acc: 0.9126 - val_loss: 0.1932 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19725 to 0.19321, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2269 - acc: 0.9179 - val_loss: 0.1893 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19321 to 0.18934, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2222 - acc: 0.9182 - val_loss: 0.1951 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.18934\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2233 - acc: 0.9175 - val_loss: 0.1840 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18934 to 0.18403, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2127 - acc: 0.9192 - val_loss: 0.1796 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18403 to 0.17964, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2099 - acc: 0.9206 - val_loss: 0.1749 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17964 to 0.17493, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2060 - acc: 0.9221 - val_loss: 0.1720 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17493 to 0.17195, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2126 - acc: 0.9204 - val_loss: 0.1780 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.17195\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1982 - acc: 0.9240 - val_loss: 0.1669 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17195 to 0.16688, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1993 - acc: 0.9233 - val_loss: 0.1628 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16688 to 0.16283, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1942 - acc: 0.9306 - val_loss: 0.1637 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16283\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1850 - acc: 0.9311 - val_loss: 0.1577 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16283 to 0.15765, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1912 - acc: 0.9277 - val_loss: 0.1569 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15765 to 0.15689, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1881 - acc: 0.9321 - val_loss: 0.1500 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15689 to 0.14999, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1853 - acc: 0.9301 - val_loss: 0.1524 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.14999\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1798 - acc: 0.9318 - val_loss: 0.1447 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14999 to 0.14474, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1835 - acc: 0.9311 - val_loss: 0.1409 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14474 to 0.14087, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1770 - acc: 0.9321 - val_loss: 0.1443 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.14087\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1769 - acc: 0.9364 - val_loss: 0.1371 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14087 to 0.13714, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1690 - acc: 0.9355 - val_loss: 0.1322 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13714 to 0.13219, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1696 - acc: 0.9377 - val_loss: 0.1290 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.13219 to 0.12904, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1597 - acc: 0.9401 - val_loss: 0.1291 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.12904\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1563 - acc: 0.9374 - val_loss: 0.1251 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12904 to 0.12511, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1604 - acc: 0.9399 - val_loss: 0.1229 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12511 to 0.12291, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1604 - acc: 0.9355 - val_loss: 0.1205 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12291 to 0.12046, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1499 - acc: 0.9425 - val_loss: 0.1168 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12046 to 0.11684, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1525 - acc: 0.9440 - val_loss: 0.1183 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11684\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1441 - acc: 0.9477 - val_loss: 0.1135 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11684 to 0.11350, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1436 - acc: 0.9462 - val_loss: 0.1104 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11350 to 0.11036, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1455 - acc: 0.9464 - val_loss: 0.1094 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11036 to 0.10941, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1431 - acc: 0.9479 - val_loss: 0.1069 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10941 to 0.10689, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1341 - acc: 0.9501 - val_loss: 0.1048 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10689 to 0.10479, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1309 - acc: 0.9535 - val_loss: 0.1007 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10479 to 0.10066, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1292 - acc: 0.9523 - val_loss: 0.0987 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10066 to 0.09873, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1296 - acc: 0.9525 - val_loss: 0.0966 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09873 to 0.09658, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9533 - val_loss: 0.0936 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09658 to 0.09363, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1228 - acc: 0.9506 - val_loss: 0.0926 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09363 to 0.09262, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1226 - acc: 0.9554 - val_loss: 0.0991 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.09262\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1269 - acc: 0.9530 - val_loss: 0.0866 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09262 to 0.08660, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1195 - acc: 0.9581 - val_loss: 0.0834 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08660 to 0.08342, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1275 - acc: 0.9518 - val_loss: 0.0960 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08342\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1177 - acc: 0.9545 - val_loss: 0.0815 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08342 to 0.08151, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1179 - acc: 0.9542 - val_loss: 0.0842 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08151\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1158 - acc: 0.9593 - val_loss: 0.0828 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08151\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1188 - acc: 0.9571 - val_loss: 0.0764 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08151 to 0.07644, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1143 - acc: 0.9535 - val_loss: 0.0727 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07644 to 0.07274, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1144 - acc: 0.9576 - val_loss: 0.0728 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07274\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1043 - acc: 0.9618 - val_loss: 0.0680 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07274 to 0.06803, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9589 - val_loss: 0.0682 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06803\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9625 - val_loss: 0.0649 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06803 to 0.06489, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1012 - acc: 0.9649 - val_loss: 0.0658 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06489\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9657 - val_loss: 0.0613 - val_acc: 0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_loss improved from 0.06489 to 0.06126, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0946 - acc: 0.9642 - val_loss: 0.0617 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.06126\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0985 - acc: 0.9606 - val_loss: 0.0571 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06126 to 0.05707, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0952 - acc: 0.9625 - val_loss: 0.0574 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05707\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9635 - val_loss: 0.0554 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05707 to 0.05543, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9635 - val_loss: 0.0556 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05543\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9630 - val_loss: 0.0531 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05543 to 0.05305, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9652 - val_loss: 0.0527 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05305 to 0.05267, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0923 - acc: 0.9640 - val_loss: 0.0490 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05267 to 0.04903, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0960 - acc: 0.9632 - val_loss: 0.0518 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04903\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0868 - acc: 0.9666 - val_loss: 0.0492 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04903\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0829 - acc: 0.9669 - val_loss: 0.0467 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04903 to 0.04668, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0810 - acc: 0.9705 - val_loss: 0.0487 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04668\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9681 - val_loss: 0.0420 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04668 to 0.04205, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0873 - acc: 0.9671 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04205\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9722 - val_loss: 0.0430 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04205\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9696 - val_loss: 0.0398 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04205 to 0.03977, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9749 - val_loss: 0.0402 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03977\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9686 - val_loss: 0.0393 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03977 to 0.03932, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0888 - acc: 0.9681 - val_loss: 0.0385 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03932 to 0.03847, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0810 - acc: 0.9683 - val_loss: 0.0415 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03847\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9725 - val_loss: 0.0358 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03847 to 0.03576, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9725 - val_loss: 0.0391 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03576\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0744 - acc: 0.9730 - val_loss: 0.0346 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03576 to 0.03464, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0603 - acc: 0.9771 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03464 to 0.03183, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9725 - val_loss: 0.0324 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03183\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9752 - val_loss: 0.0304 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03183 to 0.03040, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0695 - acc: 0.9725 - val_loss: 0.0309 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03040\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9730 - val_loss: 0.0272 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03040 to 0.02724, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9720 - val_loss: 0.0370 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02724\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9749 - val_loss: 0.0294 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02724\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9749 - val_loss: 0.0288 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02724\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9730 - val_loss: 0.0279 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02724\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9757 - val_loss: 0.0288 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02724\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 10s - loss: 0.8009 - acc: 0.4974 - val_loss: 0.6686 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66863, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7393 - acc: 0.5237 - val_loss: 0.6361 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66863 to 0.63606, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6787 - acc: 0.5895 - val_loss: 0.5793 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63606 to 0.57934, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6117 - acc: 0.6715 - val_loss: 0.5022 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57934 to 0.50218, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5343 - acc: 0.7404 - val_loss: 0.4279 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50218 to 0.42790, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4685 - acc: 0.7991 - val_loss: 0.3828 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42790 to 0.38279, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4261 - acc: 0.8242 - val_loss: 0.3544 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38279 to 0.35439, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3880 - acc: 0.8449 - val_loss: 0.3304 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35439 to 0.33042, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3748 - acc: 0.8556 - val_loss: 0.3130 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33042 to 0.31302, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3467 - acc: 0.8615 - val_loss: 0.3036 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31302 to 0.30355, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3331 - acc: 0.8727 - val_loss: 0.2878 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30355 to 0.28784, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3296 - acc: 0.8758 - val_loss: 0.2722 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28784 to 0.27225, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3157 - acc: 0.8839 - val_loss: 0.2749 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27225\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.2987 - acc: 0.8897 - val_loss: 0.2559 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27225 to 0.25589, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.2922 - acc: 0.8929 - val_loss: 0.2491 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25589 to 0.24911, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2929 - acc: 0.8909 - val_loss: 0.2430 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24911 to 0.24300, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2715 - acc: 0.9021 - val_loss: 0.2383 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24300 to 0.23828, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2654 - acc: 0.9070 - val_loss: 0.2318 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23828 to 0.23183, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2573 - acc: 0.9031 - val_loss: 0.2456 - val_acc: 0.9124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23183\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2536 - acc: 0.9148 - val_loss: 0.2228 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23183 to 0.22283, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2527 - acc: 0.9106 - val_loss: 0.2218 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22283 to 0.22178, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2505 - acc: 0.9165 - val_loss: 0.2191 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22178 to 0.21915, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2410 - acc: 0.9165 - val_loss: 0.2144 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21915 to 0.21436, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2361 - acc: 0.9167 - val_loss: 0.2162 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.21436\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2331 - acc: 0.9201 - val_loss: 0.2163 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.21436\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2348 - acc: 0.9177 - val_loss: 0.2086 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21436 to 0.20861, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2279 - acc: 0.9233 - val_loss: 0.2031 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20861 to 0.20310, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2250 - acc: 0.9228 - val_loss: 0.2016 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20310 to 0.20156, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2252 - acc: 0.9233 - val_loss: 0.2004 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20156 to 0.20038, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2169 - acc: 0.9243 - val_loss: 0.2001 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20038 to 0.20008, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2111 - acc: 0.9262 - val_loss: 0.1968 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20008 to 0.19677, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2103 - acc: 0.9270 - val_loss: 0.1902 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19677 to 0.19020, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2133 - acc: 0.9291 - val_loss: 0.1888 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19020 to 0.18883, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2088 - acc: 0.9277 - val_loss: 0.1892 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.18883\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2030 - acc: 0.9294 - val_loss: 0.1809 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18883 to 0.18090, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1936 - acc: 0.9343 - val_loss: 0.1834 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.18090\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9313 - val_loss: 0.1804 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18090 to 0.18044, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1927 - acc: 0.9338 - val_loss: 0.1736 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18044 to 0.17364, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1927 - acc: 0.9340 - val_loss: 0.1692 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17364 to 0.16924, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1894 - acc: 0.9357 - val_loss: 0.1742 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16924\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1838 - acc: 0.9386 - val_loss: 0.1639 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16924 to 0.16388, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9330 - val_loss: 0.1694 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16388\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1817 - acc: 0.9384 - val_loss: 0.1602 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16388 to 0.16021, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1709 - acc: 0.9447 - val_loss: 0.1584 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16021 to 0.15841, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9418 - val_loss: 0.1520 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15841 to 0.15196, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9379 - val_loss: 0.1531 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.15196\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1708 - acc: 0.9438 - val_loss: 0.1472 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15196 to 0.14723, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1653 - acc: 0.9457 - val_loss: 0.1465 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14723 to 0.14648, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1621 - acc: 0.9425 - val_loss: 0.1467 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.14648\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1652 - acc: 0.9442 - val_loss: 0.1391 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14648 to 0.13914, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1597 - acc: 0.9455 - val_loss: 0.1403 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.13914\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1621 - acc: 0.9452 - val_loss: 0.1336 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13914 to 0.13364, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1623 - acc: 0.9440 - val_loss: 0.1398 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.13364\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1491 - acc: 0.9528 - val_loss: 0.1307 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13364 to 0.13065, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1410 - acc: 0.9530 - val_loss: 0.1295 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13065 to 0.12951, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1576 - acc: 0.9469 - val_loss: 0.1252 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12951 to 0.12519, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1484 - acc: 0.9533 - val_loss: 0.1262 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12519\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1504 - acc: 0.9511 - val_loss: 0.1195 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12519 to 0.11951, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9540 - val_loss: 0.1180 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11951 to 0.11797, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1436 - acc: 0.9520 - val_loss: 0.1119 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11797 to 0.11194, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1457 - acc: 0.9515 - val_loss: 0.1156 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.11194\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1368 - acc: 0.9535 - val_loss: 0.1063 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11194 to 0.10634, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1307 - acc: 0.9552 - val_loss: 0.1118 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10634\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1349 - acc: 0.9525 - val_loss: 0.1010 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10634 to 0.10101, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1355 - acc: 0.9554 - val_loss: 0.1020 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10101\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1320 - acc: 0.9557 - val_loss: 0.0979 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10101 to 0.09794, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1240 - acc: 0.9608 - val_loss: 0.0932 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09794 to 0.09320, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1258 - acc: 0.9613 - val_loss: 0.0961 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09320\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1221 - acc: 0.9591 - val_loss: 0.0910 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09320 to 0.09097, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9571 - val_loss: 0.0938 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.09097\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1303 - acc: 0.9547 - val_loss: 0.0849 - val_acc: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: val_loss improved from 0.09097 to 0.08494, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1202 - acc: 0.9603 - val_loss: 0.0836 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08494 to 0.08364, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1213 - acc: 0.9581 - val_loss: 0.0820 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08364 to 0.08203, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1175 - acc: 0.9608 - val_loss: 0.0800 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08203 to 0.07995, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1161 - acc: 0.9618 - val_loss: 0.0772 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07995 to 0.07723, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9647 - val_loss: 0.0787 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07723\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1061 - acc: 0.9674 - val_loss: 0.0747 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07723 to 0.07469, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9598 - val_loss: 0.0747 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07469 to 0.07468, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1145 - acc: 0.9625 - val_loss: 0.0722 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07468 to 0.07223, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1070 - acc: 0.9649 - val_loss: 0.0721 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07223 to 0.07206, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9649 - val_loss: 0.0699 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07206 to 0.06995, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1000 - acc: 0.9681 - val_loss: 0.0692 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06995 to 0.06919, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9620 - val_loss: 0.0673 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06919 to 0.06728, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0984 - acc: 0.9696 - val_loss: 0.0687 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06728\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1007 - acc: 0.9642 - val_loss: 0.0664 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06728 to 0.06643, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1014 - acc: 0.9664 - val_loss: 0.0675 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06643\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0978 - acc: 0.9679 - val_loss: 0.0643 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06643 to 0.06434, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9679 - val_loss: 0.0656 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06434\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9683 - val_loss: 0.0618 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06434 to 0.06184, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0947 - acc: 0.9696 - val_loss: 0.0618 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06184 to 0.06181, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0952 - acc: 0.9713 - val_loss: 0.0602 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.06181 to 0.06017, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0854 - acc: 0.9703 - val_loss: 0.0613 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06017\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9674 - val_loss: 0.0576 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.06017 to 0.05760, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0873 - acc: 0.9735 - val_loss: 0.0572 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05760 to 0.05717, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9688 - val_loss: 0.0568 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05717 to 0.05678, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0882 - acc: 0.9708 - val_loss: 0.0549 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05678 to 0.05486, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0853 - acc: 0.9701 - val_loss: 0.0539 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05486 to 0.05395, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0825 - acc: 0.9742 - val_loss: 0.0584 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05395\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0927 - acc: 0.9676 - val_loss: 0.0522 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05395 to 0.05225, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0803 - acc: 0.9715 - val_loss: 0.0501 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05225 to 0.05011, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0827 - acc: 0.9737 - val_loss: 0.0500 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05011 to 0.04996, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9749 - val_loss: 0.0497 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04996 to 0.04965, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0805 - acc: 0.9730 - val_loss: 0.0489 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.04965 to 0.04888, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9757 - val_loss: 0.0475 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04888 to 0.04754, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0762 - acc: 0.9742 - val_loss: 0.0475 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.04754 to 0.04750, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9718 - val_loss: 0.0473 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04750 to 0.04728, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0746 - acc: 0.9754 - val_loss: 0.0455 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04728 to 0.04547, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9722 - val_loss: 0.0450 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04547 to 0.04504, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0728 - acc: 0.9732 - val_loss: 0.0463 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04504\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9742 - val_loss: 0.0437 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.04504 to 0.04365, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9742 - val_loss: 0.0416 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.04365 to 0.04161, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0674 - acc: 0.9769 - val_loss: 0.0422 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04161\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9781 - val_loss: 0.0412 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.04161 to 0.04123, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9764 - val_loss: 0.0403 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04123 to 0.04034, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9764 - val_loss: 0.0388 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.04034 to 0.03879, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9749 - val_loss: 0.0387 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.03879 to 0.03866, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9730 - val_loss: 0.0413 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03866\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9781 - val_loss: 0.0374 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.03866 to 0.03739, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0655 - acc: 0.9757 - val_loss: 0.0365 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.03739 to 0.03648, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9771 - val_loss: 0.0360 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.03648 to 0.03604, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9788 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.03604 to 0.03595, saving model to best.model\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0652 - acc: 0.9752 - val_loss: 0.0343 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.03595 to 0.03426, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9757 - val_loss: 0.0348 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03426\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9778 - val_loss: 0.0340 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.03426 to 0.03397, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9820 - val_loss: 0.0335 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.03397 to 0.03347, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0657 - acc: 0.9759 - val_loss: 0.0341 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03347\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9774 - val_loss: 0.0332 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.03347 to 0.03322, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9798 - val_loss: 0.0339 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03322\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9808 - val_loss: 0.0316 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.03322 to 0.03159, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9803 - val_loss: 0.0312 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.03159 to 0.03116, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9771 - val_loss: 0.0320 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03116\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9776 - val_loss: 0.0297 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.03116 to 0.02970, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0581 - acc: 0.9793 - val_loss: 0.0289 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.02970 to 0.02889, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9810 - val_loss: 0.0297 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02889\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9810 - val_loss: 0.0276 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.02889 to 0.02755, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9803 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.02755 to 0.02715, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9849 - val_loss: 0.0265 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.02715 to 0.02647, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9837 - val_loss: 0.0266 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02647\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9788 - val_loss: 0.0253 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.02647 to 0.02526, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9822 - val_loss: 0.0252 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.02526 to 0.02521, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9834 - val_loss: 0.0276 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02521\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9798 - val_loss: 0.0259 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02521\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9854 - val_loss: 0.0260 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02521\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9825 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02521\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9830 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.02521 to 0.02416, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9815 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02416\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9832 - val_loss: 0.0228 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.02416 to 0.02278, saving model to best.model\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9822 - val_loss: 0.0224 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.02278 to 0.02242, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9832 - val_loss: 0.0221 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.02242 to 0.02212, saving model to best.model\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9844 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.02212 to 0.02124, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9842 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.02124 to 0.02111, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9820 - val_loss: 0.0215 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02111\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9832 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.02111 to 0.02079, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9820 - val_loss: 0.0230 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02079\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9859 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.02079 to 0.02062, saving model to best.model\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0458 - acc: 0.9842 - val_loss: 0.0213 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02062\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9817 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02062\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9844 - val_loss: 0.0216 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02062\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9822 - val_loss: 0.0205 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.02062 to 0.02052, saving model to best.model\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9876 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.02052 to 0.02045, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0189 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.02045 to 0.01894, saving model to best.model\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0415 - acc: 0.9856 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.01894 to 0.01825, saving model to best.model\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0392 - acc: 0.9861 - val_loss: 0.0191 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01825\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0364 - acc: 0.9866 - val_loss: 0.0177 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.01825 to 0.01774, saving model to best.model\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0438 - acc: 0.9847 - val_loss: 0.0178 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01774\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9847 - val_loss: 0.0174 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.01774 to 0.01744, saving model to best.model\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9859 - val_loss: 0.0187 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01744\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.01744 to 0.01742, saving model to best.model\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9834 - val_loss: 0.0181 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.01742\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9851 - val_loss: 0.0170 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.01742 to 0.01699, saving model to best.model\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9859 - val_loss: 0.0179 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01699\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0163 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.01699 to 0.01627, saving model to best.model\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0395 - acc: 0.9847 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01627\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9832 - val_loss: 0.0160 - val_acc: 0.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00174: val_loss improved from 0.01627 to 0.01595, saving model to best.model\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0397 - acc: 0.9847 - val_loss: 0.0164 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.01595\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9876 - val_loss: 0.0161 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.01595\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9854 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.01595\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9883 - val_loss: 0.0149 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.01595 to 0.01490, saving model to best.model\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0323 - acc: 0.9890 - val_loss: 0.0155 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.01490\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9881 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.01490\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9851 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.01490 to 0.01419, saving model to best.model\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9834 - val_loss: 0.0133 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.01419 to 0.01326, saving model to best.model\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0361 - acc: 0.9856 - val_loss: 0.0137 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.01326\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9869 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.01326\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0306 - acc: 0.9900 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.01326\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9886 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.01326\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9888 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.01326 to 0.01273, saving model to best.model\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9869 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.01273 to 0.01265, saving model to best.model\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9866 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01265\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0320 - acc: 0.9893 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01265\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0302 - acc: 0.9876 - val_loss: 0.0124 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.01265 to 0.01238, saving model to best.model\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9900 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.01238 to 0.01199, saving model to best.model\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9886 - val_loss: 0.0118 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.01199 to 0.01183, saving model to best.model\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0331 - acc: 0.9878 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01183\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0364 - acc: 0.9883 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01183\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0384 - acc: 0.9856 - val_loss: 0.0117 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.01183 to 0.01165, saving model to best.model\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0346 - acc: 0.9869 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.01165 to 0.01115, saving model to best.model\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0299 - acc: 0.9888 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.01115 to 0.01109, saving model to best.model\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9920 - val_loss: 0.0107 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.01109 to 0.01065, saving model to best.model\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0301 - acc: 0.9888 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01065\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 11s - loss: 0.8012 - acc: 0.4950 - val_loss: 0.6773 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67732, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7530 - acc: 0.5142 - val_loss: 0.6531 - val_acc: 0.7176\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67732 to 0.65306, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6987 - acc: 0.5668 - val_loss: 0.6158 - val_acc: 0.7254\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65306 to 0.61576, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6374 - acc: 0.6394 - val_loss: 0.5509 - val_acc: 0.7877\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61576 to 0.55094, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5840 - acc: 0.6944 - val_loss: 0.4814 - val_acc: 0.8053\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55094 to 0.48139, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5185 - acc: 0.7538 - val_loss: 0.4297 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48139 to 0.42971, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4719 - acc: 0.7869 - val_loss: 0.3986 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42971 to 0.39865, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4370 - acc: 0.8145 - val_loss: 0.3689 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39865 to 0.36888, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4090 - acc: 0.8332 - val_loss: 0.3398 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36888 to 0.33976, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3883 - acc: 0.8408 - val_loss: 0.3222 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33976 to 0.32221, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3736 - acc: 0.8468 - val_loss: 0.3057 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32221 to 0.30569, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3513 - acc: 0.8544 - val_loss: 0.3056 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30569 to 0.30565, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3378 - acc: 0.8651 - val_loss: 0.2824 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.30565 to 0.28244, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3299 - acc: 0.8800 - val_loss: 0.2655 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28244 to 0.26554, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3151 - acc: 0.8809 - val_loss: 0.2633 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26554 to 0.26334, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3089 - acc: 0.8785 - val_loss: 0.2565 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26334 to 0.25648, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2965 - acc: 0.8926 - val_loss: 0.2484 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25648 to 0.24838, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2877 - acc: 0.8931 - val_loss: 0.2447 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24838 to 0.24466, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2807 - acc: 0.8965 - val_loss: 0.2355 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24466 to 0.23548, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2759 - acc: 0.9004 - val_loss: 0.2317 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23548 to 0.23173, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2684 - acc: 0.9036 - val_loss: 0.2309 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23173 to 0.23090, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2663 - acc: 0.9067 - val_loss: 0.2237 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23090 to 0.22374, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2571 - acc: 0.9082 - val_loss: 0.2218 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22374 to 0.22179, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2497 - acc: 0.9094 - val_loss: 0.2186 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22179 to 0.21862, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2535 - acc: 0.9116 - val_loss: 0.2156 - val_acc: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_loss improved from 0.21862 to 0.21560, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2469 - acc: 0.9143 - val_loss: 0.2124 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21560 to 0.21243, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2401 - acc: 0.9153 - val_loss: 0.2104 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21243 to 0.21038, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2405 - acc: 0.9158 - val_loss: 0.2085 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21038 to 0.20854, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9170 - val_loss: 0.2065 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20854 to 0.20647, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2337 - acc: 0.9150 - val_loss: 0.2053 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20647 to 0.20530, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2305 - acc: 0.9226 - val_loss: 0.1974 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20530 to 0.19736, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2253 - acc: 0.9209 - val_loss: 0.1953 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19736 to 0.19534, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2247 - acc: 0.9209 - val_loss: 0.1946 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19534 to 0.19463, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2152 - acc: 0.9231 - val_loss: 0.1904 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19463 to 0.19037, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2124 - acc: 0.9243 - val_loss: 0.1863 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19037 to 0.18635, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2129 - acc: 0.9257 - val_loss: 0.1827 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18635 to 0.18271, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2035 - acc: 0.9282 - val_loss: 0.1800 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18271 to 0.18004, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2028 - acc: 0.9294 - val_loss: 0.1764 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18004 to 0.17640, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2085 - acc: 0.9284 - val_loss: 0.1801 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.17640\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9301 - val_loss: 0.1696 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17640 to 0.16963, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1958 - acc: 0.9333 - val_loss: 0.1657 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16963 to 0.16565, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1905 - acc: 0.9330 - val_loss: 0.1638 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.16565 to 0.16379, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1914 - acc: 0.9299 - val_loss: 0.1617 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16379 to 0.16168, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1831 - acc: 0.9352 - val_loss: 0.1672 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16168\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9313 - val_loss: 0.1529 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16168 to 0.15291, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1767 - acc: 0.9377 - val_loss: 0.1515 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15291 to 0.15147, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9355 - val_loss: 0.1529 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.15147\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1735 - acc: 0.9421 - val_loss: 0.1429 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15147 to 0.14287, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1700 - acc: 0.9394 - val_loss: 0.1390 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14287 to 0.13896, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1635 - acc: 0.9418 - val_loss: 0.1463 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.13896\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1668 - acc: 0.9433 - val_loss: 0.1330 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13896 to 0.13300, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1627 - acc: 0.9440 - val_loss: 0.1322 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13300 to 0.13224, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9430 - val_loss: 0.1262 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13224 to 0.12618, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1535 - acc: 0.9447 - val_loss: 0.1226 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12618 to 0.12255, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1492 - acc: 0.9455 - val_loss: 0.1265 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.12255\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1477 - acc: 0.9494 - val_loss: 0.1182 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12255 to 0.11822, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1424 - acc: 0.9469 - val_loss: 0.1259 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11822\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1378 - acc: 0.9491 - val_loss: 0.1137 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11822 to 0.11366, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1521 - acc: 0.9464 - val_loss: 0.1094 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11366 to 0.10938, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1430 - acc: 0.9486 - val_loss: 0.1073 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10938 to 0.10728, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1421 - acc: 0.9489 - val_loss: 0.1052 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10728 to 0.10521, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1367 - acc: 0.9530 - val_loss: 0.1067 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10521\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1389 - acc: 0.9523 - val_loss: 0.1065 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10521\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1280 - acc: 0.9552 - val_loss: 0.1042 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10521 to 0.10418, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1247 - acc: 0.9557 - val_loss: 0.1048 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10418\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1243 - acc: 0.9576 - val_loss: 0.0974 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10418 to 0.09744, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1255 - acc: 0.9554 - val_loss: 0.0949 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09744 to 0.09489, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1204 - acc: 0.9537 - val_loss: 0.1010 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09489\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1168 - acc: 0.9559 - val_loss: 0.0901 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09489 to 0.09010, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1192 - acc: 0.9569 - val_loss: 0.0890 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09010 to 0.08898, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9589 - val_loss: 0.0904 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08898\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1194 - acc: 0.9581 - val_loss: 0.0898 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08898\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9569 - val_loss: 0.0837 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08898 to 0.08372, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9596 - val_loss: 0.0802 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08372 to 0.08020, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1036 - acc: 0.9618 - val_loss: 0.0793 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08020 to 0.07930, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1025 - acc: 0.9625 - val_loss: 0.0757 - val_acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00076: val_loss improved from 0.07930 to 0.07574, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9606 - val_loss: 0.0773 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07574\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1003 - acc: 0.9640 - val_loss: 0.0714 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07574 to 0.07142, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0948 - acc: 0.9649 - val_loss: 0.0708 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07142 to 0.07080, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9645 - val_loss: 0.0675 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07080 to 0.06751, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9666 - val_loss: 0.0653 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06751 to 0.06532, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9722 - val_loss: 0.0628 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06532 to 0.06282, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9676 - val_loss: 0.0631 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06282\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9666 - val_loss: 0.0589 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06282 to 0.05887, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0935 - acc: 0.9649 - val_loss: 0.0679 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05887\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9674 - val_loss: 0.0607 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05887\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9703 - val_loss: 0.0577 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05887 to 0.05768, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9730 - val_loss: 0.0556 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05768 to 0.05565, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0815 - acc: 0.9701 - val_loss: 0.0539 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05565 to 0.05390, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0788 - acc: 0.9693 - val_loss: 0.0541 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05390\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9710 - val_loss: 0.0479 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05390 to 0.04788, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9730 - val_loss: 0.0496 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04788\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0474 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04788 to 0.04735, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0761 - acc: 0.9710 - val_loss: 0.0507 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04735\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0775 - acc: 0.9727 - val_loss: 0.0558 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04735\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0723 - acc: 0.9713 - val_loss: 0.0448 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04735 to 0.04476, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9718 - val_loss: 0.0439 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04476 to 0.04394, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9727 - val_loss: 0.0485 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04394\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0683 - acc: 0.9735 - val_loss: 0.0419 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04394 to 0.04190, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9747 - val_loss: 0.0418 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04190 to 0.04179, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9769 - val_loss: 0.0464 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04179\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9781 - val_loss: 0.0399 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04179 to 0.03990, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9752 - val_loss: 0.0400 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03990\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0649 - acc: 0.9764 - val_loss: 0.0427 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03990\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9764 - val_loss: 0.0358 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03990 to 0.03582, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9747 - val_loss: 0.0392 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03582\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9771 - val_loss: 0.0322 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03582 to 0.03221, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9759 - val_loss: 0.0371 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03221\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9786 - val_loss: 0.0358 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03221\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0603 - acc: 0.9766 - val_loss: 0.0400 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03221\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9798 - val_loss: 0.0315 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03221 to 0.03148, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9776 - val_loss: 0.0387 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03148\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9820 - val_loss: 0.0296 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03148 to 0.02957, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9776 - val_loss: 0.0276 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02957 to 0.02762, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0632 - acc: 0.9776 - val_loss: 0.0375 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02762\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9783 - val_loss: 0.0292 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02762\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9803 - val_loss: 0.0339 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02762\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9800 - val_loss: 0.0294 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02762\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9825 - val_loss: 0.0373 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02762\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 10s - loss: 0.7946 - acc: 0.4970 - val_loss: 0.6901 - val_acc: 0.4547\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69008, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7428 - acc: 0.5191 - val_loss: 0.6608 - val_acc: 0.6105\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69008 to 0.66075, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7078 - acc: 0.5381 - val_loss: 0.6423 - val_acc: 0.7517\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66075 to 0.64234, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6619 - acc: 0.6024 - val_loss: 0.5912 - val_acc: 0.7838\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64234 to 0.59119, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5971 - acc: 0.6798 - val_loss: 0.5060 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59119 to 0.50595, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5401 - acc: 0.7356 - val_loss: 0.4392 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50595 to 0.43924, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4729 - acc: 0.7906 - val_loss: 0.3908 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43924 to 0.39082, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4342 - acc: 0.8145 - val_loss: 0.3590 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39082 to 0.35904, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4121 - acc: 0.8300 - val_loss: 0.3378 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35904 to 0.33776, saving model to best.model\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3844 - acc: 0.8451 - val_loss: 0.3187 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33776 to 0.31875, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3716 - acc: 0.8539 - val_loss: 0.3034 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31875 to 0.30339, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3483 - acc: 0.8602 - val_loss: 0.2925 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30339 to 0.29248, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3421 - acc: 0.8724 - val_loss: 0.2793 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29248 to 0.27934, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3216 - acc: 0.8797 - val_loss: 0.2723 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27934 to 0.27226, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3176 - acc: 0.8797 - val_loss: 0.2701 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27226 to 0.27014, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3172 - acc: 0.8800 - val_loss: 0.2630 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27014 to 0.26299, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2971 - acc: 0.8926 - val_loss: 0.2570 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26299 to 0.25704, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2932 - acc: 0.8897 - val_loss: 0.2540 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25704 to 0.25400, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2830 - acc: 0.8968 - val_loss: 0.2502 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.25400 to 0.25022, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2825 - acc: 0.8902 - val_loss: 0.2512 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25022\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2798 - acc: 0.8987 - val_loss: 0.2418 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25022 to 0.24183, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2699 - acc: 0.9019 - val_loss: 0.2380 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24183 to 0.23803, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2666 - acc: 0.9033 - val_loss: 0.2369 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23803 to 0.23694, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2639 - acc: 0.9033 - val_loss: 0.2320 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23694 to 0.23200, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2535 - acc: 0.9109 - val_loss: 0.2296 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23200 to 0.22960, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2594 - acc: 0.9063 - val_loss: 0.2278 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22960 to 0.22782, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2495 - acc: 0.9116 - val_loss: 0.2243 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.22782 to 0.22432, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2478 - acc: 0.9136 - val_loss: 0.2224 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22432 to 0.22244, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2451 - acc: 0.9126 - val_loss: 0.2232 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.22244\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2420 - acc: 0.9162 - val_loss: 0.2191 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22244 to 0.21909, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2428 - acc: 0.9167 - val_loss: 0.2162 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21909 to 0.21623, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2395 - acc: 0.9136 - val_loss: 0.2115 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21623 to 0.21146, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2330 - acc: 0.9206 - val_loss: 0.2086 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.21146 to 0.20863, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2255 - acc: 0.9248 - val_loss: 0.2050 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20863 to 0.20503, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2218 - acc: 0.9223 - val_loss: 0.2005 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20503 to 0.20051, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2251 - acc: 0.9235 - val_loss: 0.1984 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20051 to 0.19845, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2192 - acc: 0.9260 - val_loss: 0.1949 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19845 to 0.19488, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2209 - acc: 0.9214 - val_loss: 0.1960 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.19488\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2172 - acc: 0.9235 - val_loss: 0.1892 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19488 to 0.18921, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2080 - acc: 0.9270 - val_loss: 0.1868 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18921 to 0.18678, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2076 - acc: 0.9267 - val_loss: 0.1871 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.18678\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2083 - acc: 0.9274 - val_loss: 0.1814 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18678 to 0.18138, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2031 - acc: 0.9296 - val_loss: 0.1765 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.18138 to 0.17653, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9299 - val_loss: 0.1760 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17653 to 0.17597, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1955 - acc: 0.9301 - val_loss: 0.1698 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17597 to 0.16985, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1917 - acc: 0.9330 - val_loss: 0.1648 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16985 to 0.16480, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1834 - acc: 0.9323 - val_loss: 0.1615 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16480 to 0.16145, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1860 - acc: 0.9311 - val_loss: 0.1577 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.16145 to 0.15768, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1792 - acc: 0.9352 - val_loss: 0.1580 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.15768\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1795 - acc: 0.9321 - val_loss: 0.1519 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15768 to 0.15192, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1730 - acc: 0.9347 - val_loss: 0.1516 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.15192 to 0.15161, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1665 - acc: 0.9396 - val_loss: 0.1453 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15161 to 0.14528, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1605 - acc: 0.9445 - val_loss: 0.1411 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14528 to 0.14114, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9403 - val_loss: 0.1371 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14114 to 0.13713, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1603 - acc: 0.9406 - val_loss: 0.1327 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13713 to 0.13273, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1495 - acc: 0.9459 - val_loss: 0.1300 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13273 to 0.12996, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1512 - acc: 0.9423 - val_loss: 0.1278 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12996 to 0.12778, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1511 - acc: 0.9481 - val_loss: 0.1258 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12778 to 0.12585, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1374 - acc: 0.9494 - val_loss: 0.1234 - val_acc: 0.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_loss improved from 0.12585 to 0.12338, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1409 - acc: 0.9491 - val_loss: 0.1206 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12338 to 0.12063, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9481 - val_loss: 0.1183 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.12063 to 0.11833, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1462 - acc: 0.9469 - val_loss: 0.1187 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.11833\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1331 - acc: 0.9494 - val_loss: 0.1148 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11833 to 0.11478, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1419 - acc: 0.9494 - val_loss: 0.1118 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11478 to 0.11181, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1343 - acc: 0.9506 - val_loss: 0.1081 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.11181 to 0.10813, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1309 - acc: 0.9540 - val_loss: 0.1059 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10813 to 0.10593, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1333 - acc: 0.9515 - val_loss: 0.1044 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10593 to 0.10437, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1150 - acc: 0.9584 - val_loss: 0.1019 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10437 to 0.10187, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1279 - acc: 0.9533 - val_loss: 0.0993 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10187 to 0.09935, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1292 - acc: 0.9540 - val_loss: 0.0983 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09935 to 0.09826, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1245 - acc: 0.9530 - val_loss: 0.0964 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.09826 to 0.09644, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1120 - acc: 0.9642 - val_loss: 0.0973 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.09644\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1107 - acc: 0.9623 - val_loss: 0.0924 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.09644 to 0.09243, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1176 - acc: 0.9598 - val_loss: 0.0884 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.09243 to 0.08840, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1139 - acc: 0.9603 - val_loss: 0.0862 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08840 to 0.08616, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9567 - val_loss: 0.0825 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08616 to 0.08252, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1109 - acc: 0.9584 - val_loss: 0.0817 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.08252 to 0.08171, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1081 - acc: 0.9550 - val_loss: 0.0778 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.08171 to 0.07782, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1038 - acc: 0.9603 - val_loss: 0.0796 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07782\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9674 - val_loss: 0.0769 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07782 to 0.07689, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9688 - val_loss: 0.0739 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07689 to 0.07389, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9681 - val_loss: 0.0732 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07389 to 0.07315, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9647 - val_loss: 0.0725 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07315 to 0.07250, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9637 - val_loss: 0.0728 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.07250\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0935 - acc: 0.9647 - val_loss: 0.0687 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.07250 to 0.06865, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9705 - val_loss: 0.0680 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06865 to 0.06795, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0912 - acc: 0.9671 - val_loss: 0.0655 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06795 to 0.06547, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0890 - acc: 0.9666 - val_loss: 0.0606 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06547 to 0.06060, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9683 - val_loss: 0.0599 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06060 to 0.05989, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0833 - acc: 0.9696 - val_loss: 0.0589 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05989 to 0.05885, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0889 - acc: 0.9652 - val_loss: 0.0597 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05885\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0844 - acc: 0.9691 - val_loss: 0.0599 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05885\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9686 - val_loss: 0.0523 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05885 to 0.05231, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0808 - acc: 0.9718 - val_loss: 0.0518 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05231 to 0.05184, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0747 - acc: 0.9732 - val_loss: 0.0492 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05184 to 0.04923, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9727 - val_loss: 0.0491 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04923 to 0.04914, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9766 - val_loss: 0.0474 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04914 to 0.04737, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0722 - acc: 0.9744 - val_loss: 0.0456 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04737 to 0.04557, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0680 - acc: 0.9727 - val_loss: 0.0457 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04557\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9747 - val_loss: 0.0473 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04557\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9754 - val_loss: 0.0435 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04557 to 0.04352, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0712 - acc: 0.9725 - val_loss: 0.0417 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04352 to 0.04167, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9737 - val_loss: 0.0430 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04167\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9725 - val_loss: 0.0428 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04167\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9735 - val_loss: 0.0420 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04167\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9757 - val_loss: 0.0401 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04167 to 0.04005, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9778 - val_loss: 0.0369 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04005 to 0.03690, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9761 - val_loss: 0.0357 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03690 to 0.03574, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9783 - val_loss: 0.0357 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03574 to 0.03572, saving model to best.model\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0664 - acc: 0.9759 - val_loss: 0.0366 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03572\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9759 - val_loss: 0.0340 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03572 to 0.03403, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9771 - val_loss: 0.0334 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03403 to 0.03336, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9808 - val_loss: 0.0340 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03336\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0618 - acc: 0.9752 - val_loss: 0.0297 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.03336 to 0.02970, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0583 - acc: 0.9781 - val_loss: 0.0303 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02970\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9793 - val_loss: 0.0290 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02970 to 0.02896, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9815 - val_loss: 0.0300 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02896\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9771 - val_loss: 0.0293 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02896\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9776 - val_loss: 0.0344 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02896\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9803 - val_loss: 0.0263 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02896 to 0.02633, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0565 - acc: 0.9793 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02633 to 0.02491, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9769 - val_loss: 0.0248 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02491 to 0.02478, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9764 - val_loss: 0.0259 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02478\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0489 - acc: 0.9813 - val_loss: 0.0249 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02478\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9827 - val_loss: 0.0240 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02478 to 0.02397, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9803 - val_loss: 0.0241 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02397\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0490 - acc: 0.9834 - val_loss: 0.0233 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02397 to 0.02335, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0435 - acc: 0.9842 - val_loss: 0.0243 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02335\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9791 - val_loss: 0.0233 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02335\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9781 - val_loss: 0.0256 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02335\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9800 - val_loss: 0.0192 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02335 to 0.01915, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9781 - val_loss: 0.0206 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01915\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9847 - val_loss: 0.0202 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01915\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9803 - val_loss: 0.0205 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01915\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9795 - val_loss: 0.0200 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01915\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9788 - val_loss: 0.0270 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01915\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 11s - loss: 0.8068 - acc: 0.5082 - val_loss: 0.6746 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67455, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7499 - acc: 0.5198 - val_loss: 0.6503 - val_acc: 0.7877\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67455 to 0.65029, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7107 - acc: 0.5466 - val_loss: 0.6156 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65029 to 0.61561, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6628 - acc: 0.6056 - val_loss: 0.5536 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61561 to 0.55364, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5857 - acc: 0.6942 - val_loss: 0.4713 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55364 to 0.47135, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5164 - acc: 0.7589 - val_loss: 0.4110 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47135 to 0.41097, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4466 - acc: 0.8062 - val_loss: 0.3720 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41097 to 0.37196, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4221 - acc: 0.8247 - val_loss: 0.3544 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37196 to 0.35437, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3980 - acc: 0.8444 - val_loss: 0.3296 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35437 to 0.32963, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3796 - acc: 0.8495 - val_loss: 0.3171 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32963 to 0.31708, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3585 - acc: 0.8559 - val_loss: 0.3090 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31708 to 0.30899, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3296 - acc: 0.8766 - val_loss: 0.2970 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30899 to 0.29700, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3290 - acc: 0.8751 - val_loss: 0.2923 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29700 to 0.29227, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3138 - acc: 0.8826 - val_loss: 0.2811 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.29227 to 0.28112, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.2964 - acc: 0.8863 - val_loss: 0.2819 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28112\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2915 - acc: 0.8936 - val_loss: 0.2717 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.28112 to 0.27168, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2901 - acc: 0.8980 - val_loss: 0.2757 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.27168\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2851 - acc: 0.9002 - val_loss: 0.2635 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27168 to 0.26352, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2675 - acc: 0.9070 - val_loss: 0.2624 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.26352 to 0.26242, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2675 - acc: 0.9055 - val_loss: 0.2656 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26242\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2598 - acc: 0.9119 - val_loss: 0.2610 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.26242 to 0.26096, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2587 - acc: 0.9099 - val_loss: 0.2528 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.26096 to 0.25275, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2608 - acc: 0.9148 - val_loss: 0.2477 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.25275 to 0.24774, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2513 - acc: 0.9155 - val_loss: 0.2465 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.24774 to 0.24647, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2497 - acc: 0.9138 - val_loss: 0.2460 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24647 to 0.24600, saving model to best.model\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2465 - acc: 0.9145 - val_loss: 0.2449 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.24600 to 0.24495, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2359 - acc: 0.9192 - val_loss: 0.2374 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.24495 to 0.23740, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2386 - acc: 0.9170 - val_loss: 0.2350 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.23740 to 0.23501, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2334 - acc: 0.9209 - val_loss: 0.2333 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23501 to 0.23331, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2340 - acc: 0.9187 - val_loss: 0.2386 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.23331\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2249 - acc: 0.9223 - val_loss: 0.2221 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.23331 to 0.22212, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2321 - acc: 0.9238 - val_loss: 0.2326 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.22212\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2204 - acc: 0.9245 - val_loss: 0.2182 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.22212 to 0.21820, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2132 - acc: 0.9260 - val_loss: 0.2169 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.21820 to 0.21691, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2143 - acc: 0.9235 - val_loss: 0.2103 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.21691 to 0.21030, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2017 - acc: 0.9304 - val_loss: 0.2104 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.21030\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2084 - acc: 0.9306 - val_loss: 0.2035 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.21030 to 0.20354, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2025 - acc: 0.9304 - val_loss: 0.2039 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20354\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1988 - acc: 0.9301 - val_loss: 0.1993 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.20354 to 0.19931, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1969 - acc: 0.9304 - val_loss: 0.1944 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19931 to 0.19440, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1858 - acc: 0.9369 - val_loss: 0.1862 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.19440 to 0.18621, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1884 - acc: 0.9357 - val_loss: 0.1876 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.18621\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1921 - acc: 0.9333 - val_loss: 0.1894 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.18621\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1885 - acc: 0.9330 - val_loss: 0.1757 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.18621 to 0.17573, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1735 - acc: 0.9369 - val_loss: 0.1750 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17573 to 0.17502, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1836 - acc: 0.9291 - val_loss: 0.1712 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17502 to 0.17118, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1724 - acc: 0.9391 - val_loss: 0.1797 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.17118\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1657 - acc: 0.9428 - val_loss: 0.1595 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.17118 to 0.15951, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1606 - acc: 0.9413 - val_loss: 0.1585 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15951 to 0.15848, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1530 - acc: 0.9440 - val_loss: 0.1537 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15848 to 0.15370, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1530 - acc: 0.9496 - val_loss: 0.1584 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.15370\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1560 - acc: 0.9457 - val_loss: 0.1447 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15370 to 0.14465, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9472 - val_loss: 0.1398 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14465 to 0.13982, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1510 - acc: 0.9457 - val_loss: 0.1466 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.13982\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1468 - acc: 0.9491 - val_loss: 0.1436 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.13982\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1452 - acc: 0.9474 - val_loss: 0.1334 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13982 to 0.13345, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1485 - acc: 0.9472 - val_loss: 0.1319 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.13345 to 0.13187, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9511 - val_loss: 0.1319 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.13187\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1349 - acc: 0.9528 - val_loss: 0.1276 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.13187 to 0.12755, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1312 - acc: 0.9508 - val_loss: 0.1210 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12755 to 0.12099, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1318 - acc: 0.9574 - val_loss: 0.1282 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.12099\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1289 - acc: 0.9559 - val_loss: 0.1216 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.12099\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1262 - acc: 0.9576 - val_loss: 0.1179 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12099 to 0.11793, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9586 - val_loss: 0.1146 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11793 to 0.11458, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1219 - acc: 0.9576 - val_loss: 0.1127 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.11458 to 0.11267, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1196 - acc: 0.9576 - val_loss: 0.1123 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11267 to 0.11226, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1218 - acc: 0.9537 - val_loss: 0.1137 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.11226\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1191 - acc: 0.9581 - val_loss: 0.1061 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.11226 to 0.10607, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1106 - acc: 0.9608 - val_loss: 0.0991 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10607 to 0.09909, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1157 - acc: 0.9581 - val_loss: 0.1046 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.09909\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1146 - acc: 0.9574 - val_loss: 0.1034 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.09909\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1118 - acc: 0.9601 - val_loss: 0.0987 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.09909 to 0.09870, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0985 - acc: 0.9642 - val_loss: 0.0901 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.09870 to 0.09014, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1037 - acc: 0.9645 - val_loss: 0.0906 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.09014\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9591 - val_loss: 0.0889 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.09014 to 0.08889, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9610 - val_loss: 0.0913 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08889\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9662 - val_loss: 0.0893 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08889\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0971 - acc: 0.9632 - val_loss: 0.0824 - val_acc: 0.9679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00078: val_loss improved from 0.08889 to 0.08238, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1033 - acc: 0.9630 - val_loss: 0.0892 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08238\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0918 - acc: 0.9637 - val_loss: 0.0807 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.08238 to 0.08069, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9654 - val_loss: 0.0812 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08069\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1020 - acc: 0.9635 - val_loss: 0.0884 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.08069\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0944 - acc: 0.9664 - val_loss: 0.0770 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.08069 to 0.07701, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0857 - acc: 0.9696 - val_loss: 0.0767 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.07701 to 0.07669, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0943 - acc: 0.9613 - val_loss: 0.0734 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.07669 to 0.07336, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0852 - acc: 0.9718 - val_loss: 0.0737 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.07336\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0833 - acc: 0.9696 - val_loss: 0.0724 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.07336 to 0.07237, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9703 - val_loss: 0.0667 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.07237 to 0.06667, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0833 - acc: 0.9686 - val_loss: 0.0734 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06667\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0822 - acc: 0.9676 - val_loss: 0.0628 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06667 to 0.06282, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9688 - val_loss: 0.0798 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06282\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0846 - acc: 0.9676 - val_loss: 0.0637 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06282\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0858 - acc: 0.9688 - val_loss: 0.0822 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.06282\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0607 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.06282 to 0.06073, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9727 - val_loss: 0.0592 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06073 to 0.05919, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0748 - acc: 0.9739 - val_loss: 0.0659 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05919\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0760 - acc: 0.9722 - val_loss: 0.0562 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05919 to 0.05616, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9688 - val_loss: 0.0660 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05616\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9730 - val_loss: 0.0548 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05616 to 0.05479, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9766 - val_loss: 0.0592 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05479\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9752 - val_loss: 0.0604 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05479\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0747 - acc: 0.9720 - val_loss: 0.0585 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05479\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0672 - acc: 0.9766 - val_loss: 0.0569 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05479\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9764 - val_loss: 0.0536 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05479 to 0.05362, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0627 - acc: 0.9764 - val_loss: 0.0515 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05362 to 0.05151, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9769 - val_loss: 0.0472 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.05151 to 0.04721, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0663 - acc: 0.9710 - val_loss: 0.0635 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04721\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9771 - val_loss: 0.0508 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04721\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9730 - val_loss: 0.0583 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04721\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9761 - val_loss: 0.0430 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.04721 to 0.04300, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9766 - val_loss: 0.0520 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04300\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9778 - val_loss: 0.0481 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04300\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9783 - val_loss: 0.0444 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04300\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9766 - val_loss: 0.0451 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04300\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0565 - acc: 0.9778 - val_loss: 0.0435 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04300\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 11s - loss: 0.8239 - acc: 0.5089 - val_loss: 0.6861 - val_acc: 0.5170\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68614, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7545 - acc: 0.5301 - val_loss: 0.6588 - val_acc: 0.7059\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68614 to 0.65884, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.7296 - acc: 0.5457 - val_loss: 0.6298 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65884 to 0.62980, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6707 - acc: 0.5939 - val_loss: 0.5769 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62980 to 0.57687, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6068 - acc: 0.6762 - val_loss: 0.5025 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57687 to 0.50249, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5369 - acc: 0.7429 - val_loss: 0.4432 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50249 to 0.44323, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4691 - acc: 0.7930 - val_loss: 0.4035 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44323 to 0.40351, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4322 - acc: 0.8154 - val_loss: 0.3807 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40351 to 0.38072, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.4094 - acc: 0.8300 - val_loss: 0.3524 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38072 to 0.35239, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3876 - acc: 0.8415 - val_loss: 0.3330 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35239 to 0.33304, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3717 - acc: 0.8532 - val_loss: 0.3139 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33304 to 0.31392, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3494 - acc: 0.8654 - val_loss: 0.2994 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31392 to 0.29942, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3410 - acc: 0.8729 - val_loss: 0.2860 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29942 to 0.28596, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3188 - acc: 0.8809 - val_loss: 0.2740 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28596 to 0.27405, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3099 - acc: 0.8809 - val_loss: 0.2648 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27405 to 0.26475, saving model to best.model\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3023 - acc: 0.8899 - val_loss: 0.2553 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26475 to 0.25526, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.2930 - acc: 0.8895 - val_loss: 0.2482 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25526 to 0.24824, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.2949 - acc: 0.8880 - val_loss: 0.2429 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24824 to 0.24295, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2861 - acc: 0.8929 - val_loss: 0.2468 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24295\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.2861 - acc: 0.8963 - val_loss: 0.2348 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24295 to 0.23476, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2726 - acc: 0.9016 - val_loss: 0.2278 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23476 to 0.22778, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2705 - acc: 0.9028 - val_loss: 0.2250 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22778 to 0.22505, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2612 - acc: 0.9092 - val_loss: 0.2233 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22505 to 0.22333, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2570 - acc: 0.9099 - val_loss: 0.2149 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22333 to 0.21490, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2566 - acc: 0.9058 - val_loss: 0.2204 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.21490\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2541 - acc: 0.9063 - val_loss: 0.2125 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21490 to 0.21246, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.2508 - acc: 0.9111 - val_loss: 0.2032 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21246 to 0.20320, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2491 - acc: 0.9070 - val_loss: 0.2003 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20320 to 0.20032, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2415 - acc: 0.9133 - val_loss: 0.2064 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20032\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.2457 - acc: 0.9136 - val_loss: 0.1983 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20032 to 0.19827, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2328 - acc: 0.9194 - val_loss: 0.1922 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19827 to 0.19222, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2348 - acc: 0.9187 - val_loss: 0.1978 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.19222\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.2278 - acc: 0.9214 - val_loss: 0.1898 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19222 to 0.18980, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2299 - acc: 0.9165 - val_loss: 0.1886 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18980 to 0.18863, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2219 - acc: 0.9199 - val_loss: 0.1809 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18863 to 0.18093, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2127 - acc: 0.9196 - val_loss: 0.1759 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18093 to 0.17592, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2109 - acc: 0.9267 - val_loss: 0.1799 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.17592\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2162 - acc: 0.9257 - val_loss: 0.1711 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17592 to 0.17107, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2045 - acc: 0.9257 - val_loss: 0.1665 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17107 to 0.16648, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2026 - acc: 0.9252 - val_loss: 0.1683 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16648\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2026 - acc: 0.9255 - val_loss: 0.1590 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16648 to 0.15899, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2013 - acc: 0.9279 - val_loss: 0.1574 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15899 to 0.15744, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.1942 - acc: 0.9306 - val_loss: 0.1566 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15744 to 0.15663, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1889 - acc: 0.9321 - val_loss: 0.1495 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15663 to 0.14945, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1942 - acc: 0.9326 - val_loss: 0.1553 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.14945\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1836 - acc: 0.9343 - val_loss: 0.1402 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14945 to 0.14024, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1886 - acc: 0.9333 - val_loss: 0.1437 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.14024\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1850 - acc: 0.9279 - val_loss: 0.1354 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14024 to 0.13541, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1718 - acc: 0.9364 - val_loss: 0.1384 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.13541\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1782 - acc: 0.9311 - val_loss: 0.1265 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.13541 to 0.12653, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1697 - acc: 0.9357 - val_loss: 0.1201 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12653 to 0.12013, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1669 - acc: 0.9374 - val_loss: 0.1181 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12013 to 0.11812, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1556 - acc: 0.9399 - val_loss: 0.1186 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.11812\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9416 - val_loss: 0.1102 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11812 to 0.11019, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1563 - acc: 0.9403 - val_loss: 0.1040 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11019 to 0.10403, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9413 - val_loss: 0.1007 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10403 to 0.10074, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1533 - acc: 0.9425 - val_loss: 0.1057 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10074\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1434 - acc: 0.9452 - val_loss: 0.0931 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10074 to 0.09312, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1489 - acc: 0.9442 - val_loss: 0.1031 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.09312\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1411 - acc: 0.9472 - val_loss: 0.0877 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09312 to 0.08774, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1359 - acc: 0.9501 - val_loss: 0.0887 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.08774\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1280 - acc: 0.9518 - val_loss: 0.0848 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08774 to 0.08477, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1319 - acc: 0.9518 - val_loss: 0.0795 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08477 to 0.07947, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.1302 - acc: 0.9525 - val_loss: 0.0743 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07947 to 0.07427, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1184 - acc: 0.9530 - val_loss: 0.0718 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07427 to 0.07183, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1186 - acc: 0.9535 - val_loss: 0.0712 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07183 to 0.07124, saving model to best.model\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1185 - acc: 0.9547 - val_loss: 0.0664 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07124 to 0.06645, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1228 - acc: 0.9574 - val_loss: 0.0725 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06645\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1099 - acc: 0.9608 - val_loss: 0.0655 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06645 to 0.06551, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1158 - acc: 0.9535 - val_loss: 0.0634 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06551 to 0.06341, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1092 - acc: 0.9586 - val_loss: 0.0620 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06341 to 0.06195, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1121 - acc: 0.9586 - val_loss: 0.0597 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06195 to 0.05972, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1022 - acc: 0.9593 - val_loss: 0.0557 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05972 to 0.05572, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1022 - acc: 0.9603 - val_loss: 0.0536 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05572 to 0.05360, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0996 - acc: 0.9635 - val_loss: 0.0564 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05360\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.1023 - acc: 0.9632 - val_loss: 0.0503 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05360 to 0.05027, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9647 - val_loss: 0.0480 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05027 to 0.04798, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9623 - val_loss: 0.0507 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04798\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1043 - acc: 0.9615 - val_loss: 0.0498 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04798\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0971 - acc: 0.9625 - val_loss: 0.0462 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04798 to 0.04619, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9652 - val_loss: 0.0481 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04619\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0860 - acc: 0.9683 - val_loss: 0.0422 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04619 to 0.04216, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9659 - val_loss: 0.0450 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04216\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0927 - acc: 0.9657 - val_loss: 0.0438 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04216\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0903 - acc: 0.9666 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04216 to 0.03979, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0872 - acc: 0.9649 - val_loss: 0.0388 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03979 to 0.03879, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9718 - val_loss: 0.0375 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.03879 to 0.03748, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9708 - val_loss: 0.0366 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03748 to 0.03656, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0796 - acc: 0.9696 - val_loss: 0.0350 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03656 to 0.03495, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0793 - acc: 0.9679 - val_loss: 0.0346 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03495 to 0.03465, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9715 - val_loss: 0.0368 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03465\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9696 - val_loss: 0.0330 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03465 to 0.03296, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9696 - val_loss: 0.0330 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03296\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9654 - val_loss: 0.0325 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03296 to 0.03254, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0744 - acc: 0.9735 - val_loss: 0.0322 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03254 to 0.03222, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9703 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03222 to 0.03074, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9725 - val_loss: 0.0310 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03074\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9708 - val_loss: 0.0296 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03074 to 0.02960, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0713 - acc: 0.9722 - val_loss: 0.0269 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.02960 to 0.02689, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9739 - val_loss: 0.0253 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02689 to 0.02528, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0665 - acc: 0.9730 - val_loss: 0.0259 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02528\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9749 - val_loss: 0.0283 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02528\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0681 - acc: 0.9730 - val_loss: 0.0251 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02528 to 0.02512, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9742 - val_loss: 0.0257 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02512\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0740 - acc: 0.9708 - val_loss: 0.0264 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02512\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9778 - val_loss: 0.0266 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02512\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0684 - acc: 0.9725 - val_loss: 0.0248 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02512 to 0.02476, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9788 - val_loss: 0.0248 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02476\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9759 - val_loss: 0.0218 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02476 to 0.02177, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9778 - val_loss: 0.0218 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02177\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0688 - acc: 0.9725 - val_loss: 0.0301 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02177\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9791 - val_loss: 0.0236 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02177\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9788 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02177 to 0.02116, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9791 - val_loss: 0.0232 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02116\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9764 - val_loss: 0.0233 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02116\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9774 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02116\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9791 - val_loss: 0.0187 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02116 to 0.01872, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9778 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01872\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9793 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01872\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0643 - acc: 0.9764 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.01872 to 0.01802, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0585 - acc: 0.9786 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01802\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0557 - acc: 0.9791 - val_loss: 0.0224 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01802\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0547 - acc: 0.9781 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01802 to 0.01717, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9820 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01717 to 0.01652, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9810 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01652\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9800 - val_loss: 0.0164 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01652 to 0.01639, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9803 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01639\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9834 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01639 to 0.01530, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9822 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01530 to 0.01496, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0467 - acc: 0.9822 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01496\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9810 - val_loss: 0.0161 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01496\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0411 - acc: 0.9837 - val_loss: 0.0151 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01496\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9827 - val_loss: 0.0157 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01496\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9825 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01496 to 0.01452, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0415 - acc: 0.9830 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01452 to 0.01435, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9822 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01435\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9832 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01435\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9839 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01435\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0459 - acc: 0.9839 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01435 to 0.01310, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9849 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.01310 to 0.01307, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0416 - acc: 0.9837 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01307\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0530 - acc: 0.9827 - val_loss: 0.0119 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01307 to 0.01188, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9844 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01188\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9842 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01188\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0443 - acc: 0.9820 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01188\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9822 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01188 to 0.01098, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9825 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01098\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9851 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01098 to 0.01098, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0378 - acc: 0.9861 - val_loss: 0.0112 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01098\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9839 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.01098 to 0.01071, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01071\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9854 - val_loss: 0.0123 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01071\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0381 - acc: 0.9866 - val_loss: 0.0100 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01071 to 0.01001, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9830 - val_loss: 0.0142 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01001\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9832 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01001\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0394 - acc: 0.9869 - val_loss: 0.0101 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01001\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9849 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01001\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9839 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.01001 to 0.00943, saving model to best.model\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00943\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0376 - acc: 0.9847 - val_loss: 0.0103 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00943\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0376 - acc: 0.9844 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00943 to 0.00913, saving model to best.model\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9856 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00913\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9842 - val_loss: 0.0090 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00913 to 0.00902, saving model to best.model\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0397 - acc: 0.9847 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00902\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0372 - acc: 0.9883 - val_loss: 0.0103 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00902\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0314 - acc: 0.9881 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00902\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0356 - acc: 0.9871 - val_loss: 0.0093 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00902\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0359 - acc: 0.9866 - val_loss: 0.0100 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00902\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 0.7938 - acc: 0.5133 - val_loss: 0.6685 - val_acc: 0.6699\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66847, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7353 - acc: 0.5376 - val_loss: 0.6420 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66847 to 0.64200, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6868 - acc: 0.5883 - val_loss: 0.5884 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64200 to 0.58844, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6214 - acc: 0.6620 - val_loss: 0.5094 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58844 to 0.50935, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.5498 - acc: 0.7295 - val_loss: 0.4240 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50935 to 0.42396, saving model to best.model\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4850 - acc: 0.7862 - val_loss: 0.3749 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42396 to 0.37488, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.4331 - acc: 0.8167 - val_loss: 0.3359 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37488 to 0.33587, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4134 - acc: 0.8310 - val_loss: 0.3132 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33587 to 0.31325, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3833 - acc: 0.8529 - val_loss: 0.2925 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31325 to 0.29246, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3705 - acc: 0.8598 - val_loss: 0.2764 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.29246 to 0.27637, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3513 - acc: 0.8656 - val_loss: 0.2691 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27637 to 0.26913, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3330 - acc: 0.8729 - val_loss: 0.2557 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26913 to 0.25569, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3260 - acc: 0.8756 - val_loss: 0.2438 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25569 to 0.24383, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3195 - acc: 0.8802 - val_loss: 0.2411 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24383 to 0.24113, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3075 - acc: 0.8873 - val_loss: 0.2303 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24113 to 0.23026, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3096 - acc: 0.8863 - val_loss: 0.2226 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.23026 to 0.22264, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2955 - acc: 0.8941 - val_loss: 0.2185 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22264 to 0.21852, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2827 - acc: 0.8990 - val_loss: 0.2102 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.21852 to 0.21015, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2848 - acc: 0.8990 - val_loss: 0.2166 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.21015\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2840 - acc: 0.9004 - val_loss: 0.2085 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21015 to 0.20846, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2774 - acc: 0.8992 - val_loss: 0.2028 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.20846 to 0.20276, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2609 - acc: 0.9089 - val_loss: 0.2009 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.20276 to 0.20092, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2567 - acc: 0.9143 - val_loss: 0.1919 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20092 to 0.19191, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2474 - acc: 0.9106 - val_loss: 0.1896 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19191 to 0.18958, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2483 - acc: 0.9131 - val_loss: 0.1859 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18958 to 0.18591, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2503 - acc: 0.9109 - val_loss: 0.1839 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.18591 to 0.18392, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2453 - acc: 0.9155 - val_loss: 0.1807 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.18392 to 0.18068, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2435 - acc: 0.9160 - val_loss: 0.1787 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18068 to 0.17866, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9097 - val_loss: 0.1762 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17866 to 0.17616, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9153 - val_loss: 0.1725 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.17616 to 0.17253, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2308 - acc: 0.9145 - val_loss: 0.1702 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17253 to 0.17018, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2245 - acc: 0.9211 - val_loss: 0.1673 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17018 to 0.16732, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2240 - acc: 0.9187 - val_loss: 0.1652 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16732 to 0.16517, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2200 - acc: 0.9175 - val_loss: 0.1632 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16517 to 0.16319, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2225 - acc: 0.9138 - val_loss: 0.1605 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16319 to 0.16046, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2113 - acc: 0.9223 - val_loss: 0.1553 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16046 to 0.15528, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9262 - val_loss: 0.1539 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15528 to 0.15395, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2025 - acc: 0.9228 - val_loss: 0.1486 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15395 to 0.14863, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2060 - acc: 0.9228 - val_loss: 0.1454 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14863 to 0.14538, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2015 - acc: 0.9223 - val_loss: 0.1413 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14538 to 0.14128, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1913 - acc: 0.9235 - val_loss: 0.1380 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14128 to 0.13800, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1896 - acc: 0.9250 - val_loss: 0.1340 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.13800 to 0.13403, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9296 - val_loss: 0.1298 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13403 to 0.12981, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1807 - acc: 0.9279 - val_loss: 0.1272 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.12981 to 0.12721, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1804 - acc: 0.9282 - val_loss: 0.1222 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12721 to 0.12222, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1802 - acc: 0.9291 - val_loss: 0.1222 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12222 to 0.12217, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1791 - acc: 0.9272 - val_loss: 0.1173 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12217 to 0.11727, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1683 - acc: 0.9328 - val_loss: 0.1135 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11727 to 0.11351, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.1701 - acc: 0.9301 - val_loss: 0.1083 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11351 to 0.10826, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1601 - acc: 0.9345 - val_loss: 0.1067 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10826 to 0.10667, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1606 - acc: 0.9343 - val_loss: 0.1000 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.10667 to 0.10001, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1531 - acc: 0.9396 - val_loss: 0.0973 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10001 to 0.09729, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1542 - acc: 0.9364 - val_loss: 0.0940 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.09729 to 0.09401, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1461 - acc: 0.9418 - val_loss: 0.0922 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.09401 to 0.09221, saving model to best.model\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1450 - acc: 0.9406 - val_loss: 0.0888 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.09221 to 0.08883, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1478 - acc: 0.9382 - val_loss: 0.0844 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08883 to 0.08442, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9421 - val_loss: 0.0835 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08442 to 0.08353, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1377 - acc: 0.9445 - val_loss: 0.0775 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08353 to 0.07746, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1320 - acc: 0.9467 - val_loss: 0.0740 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.07746 to 0.07399, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1340 - acc: 0.9498 - val_loss: 0.0719 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07399 to 0.07191, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1319 - acc: 0.9442 - val_loss: 0.0702 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.07191 to 0.07023, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1194 - acc: 0.9528 - val_loss: 0.0666 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.07023 to 0.06656, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1211 - acc: 0.9513 - val_loss: 0.0672 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06656\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1174 - acc: 0.9533 - val_loss: 0.0591 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.06656 to 0.05912, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1159 - acc: 0.9550 - val_loss: 0.0547 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.05912 to 0.05475, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1204 - acc: 0.9562 - val_loss: 0.0555 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.05475\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1188 - acc: 0.9511 - val_loss: 0.0555 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05475\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1110 - acc: 0.9569 - val_loss: 0.0528 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05475 to 0.05278, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1131 - acc: 0.9554 - val_loss: 0.0573 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05278\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1168 - acc: 0.9537 - val_loss: 0.0490 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.05278 to 0.04895, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1044 - acc: 0.9596 - val_loss: 0.0484 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.04895 to 0.04844, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1105 - acc: 0.9559 - val_loss: 0.0461 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.04844 to 0.04608, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1006 - acc: 0.9584 - val_loss: 0.0444 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.04608 to 0.04436, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1030 - acc: 0.9603 - val_loss: 0.0431 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.04436 to 0.04315, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1039 - acc: 0.9610 - val_loss: 0.0413 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.04315 to 0.04133, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0888 - acc: 0.9681 - val_loss: 0.0397 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.04133 to 0.03972, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9654 - val_loss: 0.0375 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.03972 to 0.03748, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9618 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.03748 to 0.03604, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0927 - acc: 0.9649 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.03604 to 0.03466, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9664 - val_loss: 0.0339 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.03466 to 0.03395, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0891 - acc: 0.9659 - val_loss: 0.0346 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03395\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0936 - acc: 0.9640 - val_loss: 0.0326 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.03395 to 0.03262, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9676 - val_loss: 0.0322 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03262 to 0.03220, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9691 - val_loss: 0.0331 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03220\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0808 - acc: 0.9669 - val_loss: 0.0294 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.03220 to 0.02938, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0748 - acc: 0.9701 - val_loss: 0.0270 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.02938 to 0.02705, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9713 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02705\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9681 - val_loss: 0.0267 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.02705 to 0.02671, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0760 - acc: 0.9698 - val_loss: 0.0256 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.02671 to 0.02559, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0783 - acc: 0.9679 - val_loss: 0.0246 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.02559 to 0.02463, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9718 - val_loss: 0.0253 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02463\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9757 - val_loss: 0.0233 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.02463 to 0.02332, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0762 - acc: 0.9722 - val_loss: 0.0235 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02332\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0751 - acc: 0.9730 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.02332 to 0.02311, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0774 - acc: 0.9703 - val_loss: 0.0229 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.02311 to 0.02287, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0673 - acc: 0.9732 - val_loss: 0.0220 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.02287 to 0.02201, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9703 - val_loss: 0.0223 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02201\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9778 - val_loss: 0.0195 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02201 to 0.01946, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9730 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01946\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0700 - acc: 0.9722 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01946\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0825 - acc: 0.9681 - val_loss: 0.0216 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01946\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9722 - val_loss: 0.0217 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.01946\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9739 - val_loss: 0.0205 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01946\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 11s - loss: 0.7880 - acc: 0.5289 - val_loss: 0.6683 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66832, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7466 - acc: 0.5391 - val_loss: 0.6382 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66832 to 0.63820, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6885 - acc: 0.5780 - val_loss: 0.5834 - val_acc: 0.8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 0.63820 to 0.58343, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6207 - acc: 0.6594 - val_loss: 0.5096 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58343 to 0.50960, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5557 - acc: 0.7297 - val_loss: 0.4425 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50960 to 0.44245, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4874 - acc: 0.7784 - val_loss: 0.4057 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44245 to 0.40573, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4549 - acc: 0.8040 - val_loss: 0.3806 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40573 to 0.38062, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4183 - acc: 0.8259 - val_loss: 0.3578 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38062 to 0.35776, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3919 - acc: 0.8434 - val_loss: 0.3397 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35776 to 0.33971, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3984 - acc: 0.8454 - val_loss: 0.3239 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33971 to 0.32394, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3657 - acc: 0.8600 - val_loss: 0.3259 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32394\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3522 - acc: 0.8627 - val_loss: 0.2978 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.32394 to 0.29780, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3303 - acc: 0.8690 - val_loss: 0.2852 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29780 to 0.28518, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3316 - acc: 0.8707 - val_loss: 0.2722 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28518 to 0.27224, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3185 - acc: 0.8773 - val_loss: 0.2643 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27224 to 0.26432, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3056 - acc: 0.8841 - val_loss: 0.2550 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26432 to 0.25502, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2952 - acc: 0.8897 - val_loss: 0.2480 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25502 to 0.24804, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2873 - acc: 0.8904 - val_loss: 0.2430 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24804 to 0.24297, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2851 - acc: 0.8941 - val_loss: 0.2381 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24297 to 0.23810, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2734 - acc: 0.8955 - val_loss: 0.2330 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23810 to 0.23299, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2755 - acc: 0.8958 - val_loss: 0.2280 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23299 to 0.22801, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2656 - acc: 0.9024 - val_loss: 0.2230 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22801 to 0.22296, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2591 - acc: 0.9075 - val_loss: 0.2207 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22296 to 0.22074, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2579 - acc: 0.9075 - val_loss: 0.2139 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22074 to 0.21395, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2515 - acc: 0.9087 - val_loss: 0.2103 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21395 to 0.21027, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2432 - acc: 0.9070 - val_loss: 0.2084 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21027 to 0.20842, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2392 - acc: 0.9138 - val_loss: 0.2036 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20842 to 0.20356, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2288 - acc: 0.9136 - val_loss: 0.2006 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20356 to 0.20057, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2367 - acc: 0.9121 - val_loss: 0.1956 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20057 to 0.19563, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2232 - acc: 0.9201 - val_loss: 0.1930 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19563 to 0.19296, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2280 - acc: 0.9187 - val_loss: 0.1919 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19296 to 0.19189, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2152 - acc: 0.9184 - val_loss: 0.1869 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19189 to 0.18688, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2192 - acc: 0.9223 - val_loss: 0.1823 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18688 to 0.18231, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2166 - acc: 0.9206 - val_loss: 0.1790 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18231 to 0.17904, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2115 - acc: 0.9248 - val_loss: 0.1752 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17904 to 0.17520, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2098 - acc: 0.9250 - val_loss: 0.1706 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17520 to 0.17063, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2128 - acc: 0.9218 - val_loss: 0.1666 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17063 to 0.16665, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1981 - acc: 0.9265 - val_loss: 0.1645 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16665 to 0.16446, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1938 - acc: 0.9296 - val_loss: 0.1666 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16446\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1967 - acc: 0.9243 - val_loss: 0.1570 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16446 to 0.15702, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1852 - acc: 0.9279 - val_loss: 0.1538 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15702 to 0.15378, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1854 - acc: 0.9347 - val_loss: 0.1520 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15378 to 0.15195, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1758 - acc: 0.9357 - val_loss: 0.1474 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15195 to 0.14743, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1736 - acc: 0.9374 - val_loss: 0.1450 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14743 to 0.14504, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1738 - acc: 0.9364 - val_loss: 0.1401 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14504 to 0.14006, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1721 - acc: 0.9377 - val_loss: 0.1401 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.14006\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1672 - acc: 0.9382 - val_loss: 0.1341 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14006 to 0.13411, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1614 - acc: 0.9423 - val_loss: 0.1343 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.13411\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1660 - acc: 0.9472 - val_loss: 0.1309 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13411 to 0.13091, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1524 - acc: 0.9423 - val_loss: 0.1292 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.13091 to 0.12923, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1589 - acc: 0.9423 - val_loss: 0.1252 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12923 to 0.12520, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1531 - acc: 0.9469 - val_loss: 0.1224 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12520 to 0.12235, saving model to best.model\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1529 - acc: 0.9481 - val_loss: 0.1204 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12235 to 0.12038, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1525 - acc: 0.9459 - val_loss: 0.1185 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12038 to 0.11852, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9486 - val_loss: 0.1162 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11852 to 0.11618, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9477 - val_loss: 0.1134 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.11618 to 0.11337, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1412 - acc: 0.9508 - val_loss: 0.1107 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11337 to 0.11070, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1390 - acc: 0.9503 - val_loss: 0.1085 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11070 to 0.10852, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1300 - acc: 0.9533 - val_loss: 0.1086 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10852\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1363 - acc: 0.9472 - val_loss: 0.1056 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10852 to 0.10558, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1333 - acc: 0.9576 - val_loss: 0.1024 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10558 to 0.10244, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1320 - acc: 0.9537 - val_loss: 0.1010 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10244 to 0.10101, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9559 - val_loss: 0.0998 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10101 to 0.09976, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1216 - acc: 0.9562 - val_loss: 0.1006 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.09976\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9608 - val_loss: 0.0948 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09976 to 0.09475, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1151 - acc: 0.9581 - val_loss: 0.0933 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09475 to 0.09329, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1149 - acc: 0.9615 - val_loss: 0.0929 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09329 to 0.09290, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1193 - acc: 0.9608 - val_loss: 0.0893 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09290 to 0.08933, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1191 - acc: 0.9564 - val_loss: 0.0868 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08933 to 0.08685, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1110 - acc: 0.9603 - val_loss: 0.0865 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08685 to 0.08646, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1148 - acc: 0.9579 - val_loss: 0.0849 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08646 to 0.08492, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1054 - acc: 0.9608 - val_loss: 0.0825 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08492 to 0.08252, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1029 - acc: 0.9623 - val_loss: 0.0827 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08252\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1070 - acc: 0.9615 - val_loss: 0.0795 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08252 to 0.07953, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1007 - acc: 0.9664 - val_loss: 0.0780 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07953 to 0.07799, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9632 - val_loss: 0.0753 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07799 to 0.07530, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1010 - acc: 0.9632 - val_loss: 0.0762 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07530\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1035 - acc: 0.9623 - val_loss: 0.0723 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07530 to 0.07231, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1005 - acc: 0.9659 - val_loss: 0.0757 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07231\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0984 - acc: 0.9625 - val_loss: 0.0739 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07231\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1006 - acc: 0.9610 - val_loss: 0.0746 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07231\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0980 - acc: 0.9659 - val_loss: 0.0688 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07231 to 0.06883, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0869 - acc: 0.9686 - val_loss: 0.0673 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06883 to 0.06727, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0912 - acc: 0.9683 - val_loss: 0.0673 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06727\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0853 - acc: 0.9708 - val_loss: 0.0629 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06727 to 0.06287, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9664 - val_loss: 0.0630 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06287\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9664 - val_loss: 0.0632 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06287\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9679 - val_loss: 0.0628 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06287 to 0.06279, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9620 - val_loss: 0.0582 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06279 to 0.05822, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0746 - acc: 0.9737 - val_loss: 0.0590 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05822\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9703 - val_loss: 0.0572 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05822 to 0.05718, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0829 - acc: 0.9703 - val_loss: 0.0557 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05718 to 0.05573, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9742 - val_loss: 0.0578 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05573\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0799 - acc: 0.9713 - val_loss: 0.0539 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05573 to 0.05394, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9747 - val_loss: 0.0545 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05394\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0890 - acc: 0.9662 - val_loss: 0.0539 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05394\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0788 - acc: 0.9720 - val_loss: 0.0551 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05394\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0781 - acc: 0.9718 - val_loss: 0.0512 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.05394 to 0.05116, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9764 - val_loss: 0.0489 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05116 to 0.04886, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9759 - val_loss: 0.0534 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04886\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9713 - val_loss: 0.0484 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04886 to 0.04835, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9730 - val_loss: 0.0461 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04835 to 0.04613, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9737 - val_loss: 0.0521 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04613\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9766 - val_loss: 0.0485 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04613\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0683 - acc: 0.9747 - val_loss: 0.0457 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.04613 to 0.04571, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9747 - val_loss: 0.0420 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04571 to 0.04201, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9732 - val_loss: 0.0427 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04201\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9774 - val_loss: 0.0437 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04201\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9742 - val_loss: 0.0401 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.04201 to 0.04007, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9710 - val_loss: 0.0384 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.04007 to 0.03838, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0632 - acc: 0.9776 - val_loss: 0.0406 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03838\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9742 - val_loss: 0.0402 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03838\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9778 - val_loss: 0.0441 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03838\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9791 - val_loss: 0.0409 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03838\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9774 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03838\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 11s - loss: 0.7944 - acc: 0.5121 - val_loss: 0.6706 - val_acc: 0.5161\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67064, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7286 - acc: 0.5418 - val_loss: 0.6348 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67064 to 0.63475, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6882 - acc: 0.5737 - val_loss: 0.5971 - val_acc: 0.7459\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63475 to 0.59708, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6209 - acc: 0.6635 - val_loss: 0.5106 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59708 to 0.51063, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5380 - acc: 0.7443 - val_loss: 0.4293 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51063 to 0.42933, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4800 - acc: 0.7887 - val_loss: 0.3782 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42933 to 0.37816, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4423 - acc: 0.8152 - val_loss: 0.3492 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37816 to 0.34917, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3948 - acc: 0.8374 - val_loss: 0.3247 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34917 to 0.32466, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3854 - acc: 0.8542 - val_loss: 0.3065 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32466 to 0.30648, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3561 - acc: 0.8668 - val_loss: 0.2939 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30648 to 0.29392, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3434 - acc: 0.8671 - val_loss: 0.2832 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29392 to 0.28324, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3322 - acc: 0.8766 - val_loss: 0.2731 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28324 to 0.27307, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3185 - acc: 0.8783 - val_loss: 0.2637 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27307 to 0.26371, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3096 - acc: 0.8865 - val_loss: 0.2575 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26371 to 0.25754, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.2995 - acc: 0.8936 - val_loss: 0.2540 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25754 to 0.25396, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2827 - acc: 0.8985 - val_loss: 0.2442 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25396 to 0.24420, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2868 - acc: 0.8958 - val_loss: 0.2403 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24420 to 0.24027, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2817 - acc: 0.9011 - val_loss: 0.2348 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24027 to 0.23484, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2753 - acc: 0.9016 - val_loss: 0.2351 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23484\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2754 - acc: 0.9019 - val_loss: 0.2284 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23484 to 0.22845, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2605 - acc: 0.9038 - val_loss: 0.2266 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22845 to 0.22661, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2564 - acc: 0.9080 - val_loss: 0.2249 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22661 to 0.22485, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2626 - acc: 0.9060 - val_loss: 0.2232 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22485 to 0.22323, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2442 - acc: 0.9155 - val_loss: 0.2171 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22323 to 0.21706, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2470 - acc: 0.9167 - val_loss: 0.2129 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21706 to 0.21291, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2476 - acc: 0.9143 - val_loss: 0.2099 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21291 to 0.20988, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2327 - acc: 0.9184 - val_loss: 0.2065 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20988 to 0.20654, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2454 - acc: 0.9131 - val_loss: 0.2046 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20654 to 0.20465, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2316 - acc: 0.9204 - val_loss: 0.2047 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20465\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2219 - acc: 0.9238 - val_loss: 0.2033 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20465 to 0.20332, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2299 - acc: 0.9221 - val_loss: 0.2001 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20332 to 0.20010, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9209 - val_loss: 0.1964 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20010 to 0.19642, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2190 - acc: 0.9282 - val_loss: 0.1940 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19642 to 0.19395, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2195 - acc: 0.9226 - val_loss: 0.1924 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19395 to 0.19237, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2136 - acc: 0.9238 - val_loss: 0.1913 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19237 to 0.19129, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2126 - acc: 0.9277 - val_loss: 0.1870 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19129 to 0.18695, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2114 - acc: 0.9235 - val_loss: 0.1829 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18695 to 0.18293, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9257 - val_loss: 0.1802 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18293 to 0.18019, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2045 - acc: 0.9308 - val_loss: 0.1821 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.18019\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2050 - acc: 0.9284 - val_loss: 0.1781 - val_acc: 0.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_loss improved from 0.18019 to 0.17806, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2032 - acc: 0.9282 - val_loss: 0.1745 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17806 to 0.17448, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2017 - acc: 0.9262 - val_loss: 0.1703 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17448 to 0.17029, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1912 - acc: 0.9330 - val_loss: 0.1691 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17029 to 0.16913, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1918 - acc: 0.9304 - val_loss: 0.1646 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16913 to 0.16461, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1876 - acc: 0.9340 - val_loss: 0.1639 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16461 to 0.16392, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1921 - acc: 0.9343 - val_loss: 0.1616 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16392 to 0.16161, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1853 - acc: 0.9379 - val_loss: 0.1599 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16161 to 0.15993, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1894 - acc: 0.9277 - val_loss: 0.1576 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15993 to 0.15755, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1792 - acc: 0.9355 - val_loss: 0.1539 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15755 to 0.15386, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1877 - acc: 0.9311 - val_loss: 0.1504 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15386 to 0.15043, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1731 - acc: 0.9369 - val_loss: 0.1473 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.15043 to 0.14733, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1691 - acc: 0.9391 - val_loss: 0.1467 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14733 to 0.14667, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1777 - acc: 0.9330 - val_loss: 0.1434 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14667 to 0.14344, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1706 - acc: 0.9357 - val_loss: 0.1420 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14344 to 0.14198, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1641 - acc: 0.9411 - val_loss: 0.1380 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14198 to 0.13795, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1587 - acc: 0.9403 - val_loss: 0.1327 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13795 to 0.13271, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1626 - acc: 0.9399 - val_loss: 0.1308 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.13271 to 0.13082, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1579 - acc: 0.9428 - val_loss: 0.1268 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.13082 to 0.12681, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1530 - acc: 0.9418 - val_loss: 0.1284 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.12681\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9445 - val_loss: 0.1248 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12681 to 0.12478, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1545 - acc: 0.9408 - val_loss: 0.1196 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.12478 to 0.11962, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9411 - val_loss: 0.1162 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11962 to 0.11619, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1384 - acc: 0.9457 - val_loss: 0.1112 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11619 to 0.11118, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9457 - val_loss: 0.1093 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11118 to 0.10926, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1408 - acc: 0.9467 - val_loss: 0.1054 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10926 to 0.10538, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1339 - acc: 0.9506 - val_loss: 0.1020 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10538 to 0.10199, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1391 - acc: 0.9481 - val_loss: 0.0984 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10199 to 0.09841, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1324 - acc: 0.9511 - val_loss: 0.0947 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09841 to 0.09469, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1292 - acc: 0.9513 - val_loss: 0.0922 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09469 to 0.09224, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1226 - acc: 0.9542 - val_loss: 0.0905 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09224 to 0.09052, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1254 - acc: 0.9491 - val_loss: 0.0860 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.09052 to 0.08597, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1280 - acc: 0.9479 - val_loss: 0.0877 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08597\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1230 - acc: 0.9535 - val_loss: 0.0901 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08597\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1235 - acc: 0.9523 - val_loss: 0.0827 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08597 to 0.08270, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1211 - acc: 0.9523 - val_loss: 0.0817 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08270 to 0.08166, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1089 - acc: 0.9559 - val_loss: 0.0778 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08166 to 0.07780, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1173 - acc: 0.9562 - val_loss: 0.0776 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07780 to 0.07761, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1027 - acc: 0.9627 - val_loss: 0.0755 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07761 to 0.07546, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1200 - acc: 0.9581 - val_loss: 0.0773 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07546\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1085 - acc: 0.9596 - val_loss: 0.0719 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07546 to 0.07195, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1102 - acc: 0.9562 - val_loss: 0.0678 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07195 to 0.06782, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1054 - acc: 0.9593 - val_loss: 0.0671 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06782 to 0.06706, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9586 - val_loss: 0.0653 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06706 to 0.06528, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1048 - acc: 0.9591 - val_loss: 0.0640 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06528 to 0.06398, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0991 - acc: 0.9606 - val_loss: 0.0633 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06398 to 0.06332, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9654 - val_loss: 0.0600 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06332 to 0.05999, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9681 - val_loss: 0.0591 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05999 to 0.05911, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0931 - acc: 0.9662 - val_loss: 0.0549 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05911 to 0.05486, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1012 - acc: 0.9627 - val_loss: 0.0593 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05486\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0913 - acc: 0.9645 - val_loss: 0.0567 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05486\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0879 - acc: 0.9686 - val_loss: 0.0553 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05486\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0890 - acc: 0.9664 - val_loss: 0.0534 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05486 to 0.05341, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9649 - val_loss: 0.0513 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05341 to 0.05127, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9635 - val_loss: 0.0522 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05127\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9683 - val_loss: 0.0492 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05127 to 0.04916, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0884 - acc: 0.9652 - val_loss: 0.0489 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04916 to 0.04886, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0871 - acc: 0.9698 - val_loss: 0.0458 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04886 to 0.04577, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9669 - val_loss: 0.0462 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04577\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9701 - val_loss: 0.0448 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04577 to 0.04478, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9718 - val_loss: 0.0475 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04478\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9657 - val_loss: 0.0428 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04478 to 0.04276, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9676 - val_loss: 0.0449 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04276\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9720 - val_loss: 0.0408 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.04276 to 0.04075, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9725 - val_loss: 0.0417 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04075\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9727 - val_loss: 0.0387 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.04075 to 0.03871, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9735 - val_loss: 0.0403 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03871\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0769 - acc: 0.9713 - val_loss: 0.0367 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03871 to 0.03673, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0761 - acc: 0.9732 - val_loss: 0.0380 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03673\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9737 - val_loss: 0.0394 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03673\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9749 - val_loss: 0.0358 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03673 to 0.03582, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9727 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03582\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9708 - val_loss: 0.0351 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03582 to 0.03510, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9735 - val_loss: 0.0336 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03510 to 0.03364, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9757 - val_loss: 0.0332 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.03364 to 0.03321, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9771 - val_loss: 0.0321 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03321 to 0.03213, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9718 - val_loss: 0.0363 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03213\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9752 - val_loss: 0.0332 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03213\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9778 - val_loss: 0.0339 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03213\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9771 - val_loss: 0.0301 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.03213 to 0.03006, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9766 - val_loss: 0.0312 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03006\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9747 - val_loss: 0.0289 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.03006 to 0.02885, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0691 - acc: 0.9754 - val_loss: 0.0409 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02885\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9757 - val_loss: 0.0300 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02885\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9776 - val_loss: 0.0297 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02885\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9764 - val_loss: 0.0277 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02885 to 0.02765, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0675 - acc: 0.9737 - val_loss: 0.0277 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02765\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9781 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02765 to 0.02703, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9752 - val_loss: 0.0308 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02703\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0620 - acc: 0.9752 - val_loss: 0.0282 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02703\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9761 - val_loss: 0.0268 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02703 to 0.02679, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9761 - val_loss: 0.0260 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02679 to 0.02602, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9769 - val_loss: 0.0308 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02602\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9752 - val_loss: 0.0287 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02602\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9778 - val_loss: 0.0266 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02602\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0530 - acc: 0.9805 - val_loss: 0.0298 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02602\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0550 - acc: 0.9788 - val_loss: 0.0237 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.02602 to 0.02368, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9795 - val_loss: 0.0253 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02368\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9808 - val_loss: 0.0236 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.02368 to 0.02365, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9776 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02365\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0530 - acc: 0.9803 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.02365 to 0.02249, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0505 - acc: 0.9805 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02249\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9810 - val_loss: 0.0222 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.02249 to 0.02225, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9805 - val_loss: 0.0214 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.02225 to 0.02140, saving model to best.model\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0512 - acc: 0.9805 - val_loss: 0.0235 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02140\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9788 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02140\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9793 - val_loss: 0.0241 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02140\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9795 - val_loss: 0.0247 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02140\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9803 - val_loss: 0.0211 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.02140 to 0.02107, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9791 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02107\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0453 - acc: 0.9825 - val_loss: 0.0208 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.02107 to 0.02080, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9822 - val_loss: 0.0201 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.02080 to 0.02013, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0496 - acc: 0.9820 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02013\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9817 - val_loss: 0.0195 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.02013 to 0.01949, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9808 - val_loss: 0.0198 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01949\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0490 - acc: 0.9827 - val_loss: 0.0205 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01949\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9832 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.01949 to 0.01911, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9832 - val_loss: 0.0183 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.01911 to 0.01827, saving model to best.model\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9813 - val_loss: 0.0229 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01827\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9808 - val_loss: 0.0189 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01827\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9808 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01827\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9847 - val_loss: 0.0215 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01827\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9847 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01827\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 12s - loss: 0.7961 - acc: 0.5225 - val_loss: 0.6703 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67029, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7441 - acc: 0.5383 - val_loss: 0.6477 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67029 to 0.64771, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6969 - acc: 0.5778 - val_loss: 0.6035 - val_acc: 0.7507\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64771 to 0.60354, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6380 - acc: 0.6370 - val_loss: 0.5332 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60354 to 0.53321, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5749 - acc: 0.7025 - val_loss: 0.4621 - val_acc: 0.8238\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53321 to 0.46208, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5307 - acc: 0.7502 - val_loss: 0.4130 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46208 to 0.41297, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4650 - acc: 0.7986 - val_loss: 0.3759 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41297 to 0.37587, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4384 - acc: 0.8050 - val_loss: 0.3523 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37587 to 0.35230, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4062 - acc: 0.8330 - val_loss: 0.3313 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35230 to 0.33130, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3981 - acc: 0.8376 - val_loss: 0.3104 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33130 to 0.31040, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3676 - acc: 0.8561 - val_loss: 0.2970 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31040 to 0.29701, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3613 - acc: 0.8556 - val_loss: 0.2852 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29701 to 0.28521, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3513 - acc: 0.8580 - val_loss: 0.2785 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28521 to 0.27846, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3416 - acc: 0.8673 - val_loss: 0.2710 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27846 to 0.27101, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3249 - acc: 0.8729 - val_loss: 0.2604 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27101 to 0.26037, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3118 - acc: 0.8761 - val_loss: 0.2545 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26037 to 0.25448, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3151 - acc: 0.8812 - val_loss: 0.2492 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25448 to 0.24918, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3104 - acc: 0.8804 - val_loss: 0.2454 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24918 to 0.24544, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3013 - acc: 0.8839 - val_loss: 0.2455 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24544\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3007 - acc: 0.8899 - val_loss: 0.2372 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24544 to 0.23719, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2849 - acc: 0.8970 - val_loss: 0.2325 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23719 to 0.23250, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2841 - acc: 0.8970 - val_loss: 0.2282 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23250 to 0.22821, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2757 - acc: 0.8955 - val_loss: 0.2243 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22821 to 0.22431, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2725 - acc: 0.9024 - val_loss: 0.2202 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22431 to 0.22016, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2709 - acc: 0.9031 - val_loss: 0.2196 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22016 to 0.21965, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2637 - acc: 0.9036 - val_loss: 0.2169 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21965 to 0.21690, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2633 - acc: 0.9058 - val_loss: 0.2135 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21690 to 0.21351, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2529 - acc: 0.9089 - val_loss: 0.2105 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21351 to 0.21046, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2460 - acc: 0.9111 - val_loss: 0.2105 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.21046\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2465 - acc: 0.9114 - val_loss: 0.2065 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21046 to 0.20653, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2491 - acc: 0.9099 - val_loss: 0.2025 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20653 to 0.20248, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2457 - acc: 0.9119 - val_loss: 0.2011 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20248 to 0.20107, saving model to best.model\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2416 - acc: 0.9150 - val_loss: 0.1994 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20107 to 0.19939, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2340 - acc: 0.9170 - val_loss: 0.1969 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19939 to 0.19689, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2378 - acc: 0.9170 - val_loss: 0.1938 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19689 to 0.19384, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2294 - acc: 0.9155 - val_loss: 0.1897 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19384 to 0.18974, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2216 - acc: 0.9218 - val_loss: 0.1910 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.18974\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2197 - acc: 0.9196 - val_loss: 0.1854 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18974 to 0.18541, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2183 - acc: 0.9218 - val_loss: 0.1846 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18541 to 0.18463, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2178 - acc: 0.9199 - val_loss: 0.1800 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18463 to 0.17996, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2170 - acc: 0.9194 - val_loss: 0.1765 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17996 to 0.17645, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2096 - acc: 0.9267 - val_loss: 0.1738 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17645 to 0.17376, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2126 - acc: 0.9250 - val_loss: 0.1718 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17376 to 0.17178, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1998 - acc: 0.9306 - val_loss: 0.1692 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17178 to 0.16919, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2037 - acc: 0.9243 - val_loss: 0.1678 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16919 to 0.16777, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1966 - acc: 0.9270 - val_loss: 0.1659 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16777 to 0.16594, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1925 - acc: 0.9299 - val_loss: 0.1623 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16594 to 0.16230, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9304 - val_loss: 0.1588 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.16230 to 0.15884, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1917 - acc: 0.9306 - val_loss: 0.1573 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15884 to 0.15734, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1893 - acc: 0.9311 - val_loss: 0.1551 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15734 to 0.15505, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1854 - acc: 0.9350 - val_loss: 0.1537 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.15505 to 0.15372, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9326 - val_loss: 0.1518 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15372 to 0.15181, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1777 - acc: 0.9384 - val_loss: 0.1481 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.15181 to 0.14810, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1810 - acc: 0.9338 - val_loss: 0.1480 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14810 to 0.14799, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1773 - acc: 0.9364 - val_loss: 0.1450 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14799 to 0.14500, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9379 - val_loss: 0.1409 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.14500 to 0.14088, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1635 - acc: 0.9423 - val_loss: 0.1381 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.14088 to 0.13806, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1699 - acc: 0.9333 - val_loss: 0.1341 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.13806 to 0.13407, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1724 - acc: 0.9428 - val_loss: 0.1326 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.13407 to 0.13260, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1590 - acc: 0.9408 - val_loss: 0.1319 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.13260 to 0.13193, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1584 - acc: 0.9430 - val_loss: 0.1219 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13193 to 0.12188, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1556 - acc: 0.9433 - val_loss: 0.1158 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.12188 to 0.11575, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1555 - acc: 0.9435 - val_loss: 0.1118 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11575 to 0.11181, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1531 - acc: 0.9425 - val_loss: 0.1091 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11181 to 0.10911, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9474 - val_loss: 0.1077 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10911 to 0.10768, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1470 - acc: 0.9442 - val_loss: 0.1025 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10768 to 0.10251, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1441 - acc: 0.9469 - val_loss: 0.0993 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10251 to 0.09928, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1426 - acc: 0.9508 - val_loss: 0.1041 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09928\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1362 - acc: 0.9547 - val_loss: 0.0929 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09928 to 0.09290, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1300 - acc: 0.9498 - val_loss: 0.0914 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09290 to 0.09145, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1347 - acc: 0.9513 - val_loss: 0.0914 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.09145 to 0.09138, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1181 - acc: 0.9542 - val_loss: 0.0847 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.09138 to 0.08471, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1291 - acc: 0.9520 - val_loss: 0.0806 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08471 to 0.08064, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1191 - acc: 0.9601 - val_loss: 0.0783 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08064 to 0.07826, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1178 - acc: 0.9552 - val_loss: 0.0769 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07826 to 0.07694, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1139 - acc: 0.9535 - val_loss: 0.0774 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07694\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9579 - val_loss: 0.0734 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07694 to 0.07343, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1110 - acc: 0.9589 - val_loss: 0.0703 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07343 to 0.07030, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9630 - val_loss: 0.0681 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07030 to 0.06805, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1124 - acc: 0.9593 - val_loss: 0.0722 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06805\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1071 - acc: 0.9576 - val_loss: 0.0679 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06805 to 0.06794, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1070 - acc: 0.9601 - val_loss: 0.0675 - val_acc: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00082: val_loss improved from 0.06794 to 0.06755, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1082 - acc: 0.9579 - val_loss: 0.0645 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06755 to 0.06454, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9610 - val_loss: 0.0601 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06454 to 0.06012, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1001 - acc: 0.9649 - val_loss: 0.0602 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06012\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9620 - val_loss: 0.0567 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06012 to 0.05667, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9705 - val_loss: 0.0555 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05667 to 0.05546, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0968 - acc: 0.9618 - val_loss: 0.0535 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05546 to 0.05349, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0941 - acc: 0.9664 - val_loss: 0.0517 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05349 to 0.05171, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0931 - acc: 0.9637 - val_loss: 0.0530 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05171\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0975 - acc: 0.9593 - val_loss: 0.0505 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05171 to 0.05047, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0881 - acc: 0.9696 - val_loss: 0.0506 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05047\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0809 - acc: 0.9688 - val_loss: 0.0487 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05047 to 0.04871, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0934 - acc: 0.9669 - val_loss: 0.0465 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04871 to 0.04654, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9686 - val_loss: 0.0444 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04654 to 0.04439, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9659 - val_loss: 0.0473 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04439\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0769 - acc: 0.9713 - val_loss: 0.0421 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04439 to 0.04210, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0787 - acc: 0.9725 - val_loss: 0.0411 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04210 to 0.04105, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9691 - val_loss: 0.0431 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04105\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0405 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04105 to 0.04051, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0718 - acc: 0.9715 - val_loss: 0.0413 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04051\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9698 - val_loss: 0.0368 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04051 to 0.03677, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9727 - val_loss: 0.0354 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03677 to 0.03539, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9742 - val_loss: 0.0359 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03539\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9715 - val_loss: 0.0479 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03539\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0779 - acc: 0.9701 - val_loss: 0.0361 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03539\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0722 - acc: 0.9757 - val_loss: 0.0375 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03539\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9744 - val_loss: 0.0359 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03539\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 12s - loss: 0.7793 - acc: 0.5159 - val_loss: 0.6573 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65726, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7129 - acc: 0.5493 - val_loss: 0.6143 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65726 to 0.61428, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6457 - acc: 0.6253 - val_loss: 0.5450 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61428 to 0.54503, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.5836 - acc: 0.6978 - val_loss: 0.4582 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54503 to 0.45818, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5064 - acc: 0.7716 - val_loss: 0.3899 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.45818 to 0.38991, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4621 - acc: 0.7979 - val_loss: 0.3682 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38991 to 0.36823, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4224 - acc: 0.8237 - val_loss: 0.3229 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36823 to 0.32291, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3941 - acc: 0.8378 - val_loss: 0.3008 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32291 to 0.30080, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3707 - acc: 0.8522 - val_loss: 0.2851 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30080 to 0.28513, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3542 - acc: 0.8578 - val_loss: 0.2681 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.28513 to 0.26808, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3331 - acc: 0.8700 - val_loss: 0.2590 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.26808 to 0.25897, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3251 - acc: 0.8768 - val_loss: 0.2448 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.25897 to 0.24480, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3097 - acc: 0.8800 - val_loss: 0.2396 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.24480 to 0.23961, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3098 - acc: 0.8865 - val_loss: 0.2299 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.23961 to 0.22994, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3094 - acc: 0.8804 - val_loss: 0.2305 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.22994\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2835 - acc: 0.8990 - val_loss: 0.2203 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22994 to 0.22028, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2743 - acc: 0.8963 - val_loss: 0.2157 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22028 to 0.21566, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2729 - acc: 0.8980 - val_loss: 0.2121 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.21566 to 0.21209, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2717 - acc: 0.8990 - val_loss: 0.2042 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.21209 to 0.20422, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2599 - acc: 0.9070 - val_loss: 0.2012 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20422 to 0.20118, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2595 - acc: 0.9041 - val_loss: 0.2027 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20118\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2553 - acc: 0.9104 - val_loss: 0.1978 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.20118 to 0.19777, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2481 - acc: 0.9082 - val_loss: 0.1905 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.19777 to 0.19046, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2450 - acc: 0.9126 - val_loss: 0.1893 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19046 to 0.18933, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2357 - acc: 0.9177 - val_loss: 0.1870 - val_acc: 0.9318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_loss improved from 0.18933 to 0.18701, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2413 - acc: 0.9131 - val_loss: 0.1839 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.18701 to 0.18389, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2377 - acc: 0.9160 - val_loss: 0.1804 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.18389 to 0.18045, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2267 - acc: 0.9170 - val_loss: 0.1842 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.18045\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2234 - acc: 0.9216 - val_loss: 0.1742 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.18045 to 0.17416, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2210 - acc: 0.9194 - val_loss: 0.1724 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.17416 to 0.17236, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2184 - acc: 0.9184 - val_loss: 0.1690 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17236 to 0.16900, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2125 - acc: 0.9196 - val_loss: 0.1663 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16900 to 0.16631, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2194 - acc: 0.9192 - val_loss: 0.1656 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16631 to 0.16560, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2076 - acc: 0.9252 - val_loss: 0.1616 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16560 to 0.16163, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2060 - acc: 0.9240 - val_loss: 0.1591 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16163 to 0.15911, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1999 - acc: 0.9257 - val_loss: 0.1556 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15911 to 0.15559, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1966 - acc: 0.9306 - val_loss: 0.1562 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15559\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1913 - acc: 0.9294 - val_loss: 0.1527 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15559 to 0.15267, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9318 - val_loss: 0.1532 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15267\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1991 - acc: 0.9248 - val_loss: 0.1502 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15267 to 0.15019, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1824 - acc: 0.9343 - val_loss: 0.1452 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15019 to 0.14517, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1955 - acc: 0.9313 - val_loss: 0.1466 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14517\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1811 - acc: 0.9360 - val_loss: 0.1416 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14517 to 0.14162, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1764 - acc: 0.9333 - val_loss: 0.1396 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14162 to 0.13964, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1702 - acc: 0.9369 - val_loss: 0.1383 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13964 to 0.13831, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9403 - val_loss: 0.1341 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13831 to 0.13414, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1668 - acc: 0.9406 - val_loss: 0.1353 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.13414\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1616 - acc: 0.9394 - val_loss: 0.1293 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13414 to 0.12928, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1624 - acc: 0.9413 - val_loss: 0.1294 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.12928\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1690 - acc: 0.9411 - val_loss: 0.1250 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12928 to 0.12501, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1585 - acc: 0.9450 - val_loss: 0.1211 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12501 to 0.12114, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1475 - acc: 0.9442 - val_loss: 0.1281 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.12114\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1616 - acc: 0.9396 - val_loss: 0.1186 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12114 to 0.11861, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1442 - acc: 0.9452 - val_loss: 0.1164 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11861 to 0.11643, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1497 - acc: 0.9457 - val_loss: 0.1129 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11643 to 0.11288, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1421 - acc: 0.9491 - val_loss: 0.1123 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.11288 to 0.11229, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1402 - acc: 0.9496 - val_loss: 0.1074 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11229 to 0.10742, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1417 - acc: 0.9469 - val_loss: 0.1039 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10742 to 0.10387, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1429 - acc: 0.9474 - val_loss: 0.1024 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10387 to 0.10238, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1323 - acc: 0.9491 - val_loss: 0.1003 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10238 to 0.10026, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1318 - acc: 0.9501 - val_loss: 0.1020 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10026\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1245 - acc: 0.9530 - val_loss: 0.0959 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10026 to 0.09590, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1281 - acc: 0.9540 - val_loss: 0.0911 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09590 to 0.09105, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1217 - acc: 0.9550 - val_loss: 0.0884 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09105 to 0.08836, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1233 - acc: 0.9547 - val_loss: 0.0925 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08836\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1169 - acc: 0.9562 - val_loss: 0.0826 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08836 to 0.08255, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1168 - acc: 0.9574 - val_loss: 0.0797 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08255 to 0.07975, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1128 - acc: 0.9589 - val_loss: 0.0774 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07975 to 0.07740, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9520 - val_loss: 0.0755 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07740 to 0.07547, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1107 - acc: 0.9608 - val_loss: 0.0770 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07547\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1030 - acc: 0.9642 - val_loss: 0.0744 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07547 to 0.07444, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1112 - acc: 0.9608 - val_loss: 0.0698 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07444 to 0.06981, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1069 - acc: 0.9586 - val_loss: 0.0653 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06981 to 0.06534, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1036 - acc: 0.9618 - val_loss: 0.0623 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06534 to 0.06229, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9630 - val_loss: 0.0614 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06229 to 0.06141, saving model to best.model\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1021 - acc: 0.9625 - val_loss: 0.0647 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06141\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0908 - acc: 0.9664 - val_loss: 0.0591 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06141 to 0.05910, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1055 - acc: 0.9618 - val_loss: 0.0592 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05910\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9664 - val_loss: 0.0606 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05910\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9640 - val_loss: 0.0568 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05910 to 0.05675, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9666 - val_loss: 0.0516 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05675 to 0.05161, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9703 - val_loss: 0.0498 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05161 to 0.04984, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0901 - acc: 0.9681 - val_loss: 0.0532 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04984\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9669 - val_loss: 0.0486 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04984 to 0.04857, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0864 - acc: 0.9676 - val_loss: 0.0517 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04857\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9676 - val_loss: 0.0459 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04857 to 0.04594, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9691 - val_loss: 0.0451 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04594 to 0.04506, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9686 - val_loss: 0.0430 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04506 to 0.04297, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0785 - acc: 0.9725 - val_loss: 0.0508 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04297\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0793 - acc: 0.9722 - val_loss: 0.0407 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04297 to 0.04071, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9718 - val_loss: 0.0506 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04071\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0822 - acc: 0.9696 - val_loss: 0.0431 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04071\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9742 - val_loss: 0.0402 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04071 to 0.04025, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9732 - val_loss: 0.0401 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04025 to 0.04007, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0779 - acc: 0.9715 - val_loss: 0.0425 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04007\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9764 - val_loss: 0.0400 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04007 to 0.03998, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9771 - val_loss: 0.0394 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03998 to 0.03943, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9737 - val_loss: 0.0352 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03943 to 0.03520, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9754 - val_loss: 0.0384 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03520\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9732 - val_loss: 0.0332 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03520 to 0.03325, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9761 - val_loss: 0.0397 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03325\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9739 - val_loss: 0.0338 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03325\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9757 - val_loss: 0.0332 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03325 to 0.03315, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0660 - acc: 0.9766 - val_loss: 0.0348 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03315\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9766 - val_loss: 0.0341 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03315\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9747 - val_loss: 0.0316 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03315 to 0.03160, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9776 - val_loss: 0.0309 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03160 to 0.03092, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9783 - val_loss: 0.0333 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03092\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9810 - val_loss: 0.0320 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03092\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9810 - val_loss: 0.0305 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03092 to 0.03054, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9791 - val_loss: 0.0313 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03054\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9788 - val_loss: 0.0297 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03054 to 0.02975, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9800 - val_loss: 0.0292 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02975 to 0.02925, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9774 - val_loss: 0.0275 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02925 to 0.02746, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9749 - val_loss: 0.0339 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02746\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0586 - acc: 0.9781 - val_loss: 0.0249 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02746 to 0.02488, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0505 - acc: 0.9808 - val_loss: 0.0272 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02488\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9803 - val_loss: 0.0247 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02488 to 0.02466, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0591 - acc: 0.9788 - val_loss: 0.0329 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02466\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9822 - val_loss: 0.0245 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02466 to 0.02449, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9808 - val_loss: 0.0259 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02449\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9788 - val_loss: 0.0232 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02449 to 0.02325, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9808 - val_loss: 0.0254 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02325\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0549 - acc: 0.9791 - val_loss: 0.0283 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02325\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9808 - val_loss: 0.0222 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02325 to 0.02221, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9822 - val_loss: 0.0202 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02221 to 0.02015, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9820 - val_loss: 0.0235 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02015\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9795 - val_loss: 0.0211 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02015\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9798 - val_loss: 0.0250 - val_acc: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02015\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0444 - acc: 0.9837 - val_loss: 0.0196 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02015 to 0.01959, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0474 - acc: 0.9813 - val_loss: 0.0260 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01959\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9844 - val_loss: 0.0198 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01959\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9832 - val_loss: 0.0253 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01959\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9839 - val_loss: 0.0212 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01959\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0435 - acc: 0.9849 - val_loss: 0.0189 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01959 to 0.01887, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9834 - val_loss: 0.0227 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01887\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9827 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01887 to 0.01852, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0453 - acc: 0.9830 - val_loss: 0.0193 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01852\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9827 - val_loss: 0.0180 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01852 to 0.01795, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9827 - val_loss: 0.0225 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01795\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9815 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01795 to 0.01717, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9813 - val_loss: 0.0227 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01717\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9825 - val_loss: 0.0153 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01717 to 0.01534, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9837 - val_loss: 0.0176 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01534\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9803 - val_loss: 0.0231 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01534\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9800 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01534\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9839 - val_loss: 0.0185 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01534\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9844 - val_loss: 0.0176 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01534\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 12s - loss: 0.8450 - acc: 0.5047 - val_loss: 0.6860 - val_acc: 0.4849\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68603, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7692 - acc: 0.5284 - val_loss: 0.6622 - val_acc: 0.5151\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68603 to 0.66221, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7230 - acc: 0.5527 - val_loss: 0.6155 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66221 to 0.61553, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6607 - acc: 0.6245 - val_loss: 0.5517 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61553 to 0.55172, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5908 - acc: 0.6981 - val_loss: 0.4758 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55172 to 0.47576, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5222 - acc: 0.7633 - val_loss: 0.4211 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47576 to 0.42113, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4705 - acc: 0.7967 - val_loss: 0.3910 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42113 to 0.39104, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4286 - acc: 0.8254 - val_loss: 0.3627 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39104 to 0.36267, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4020 - acc: 0.8364 - val_loss: 0.3431 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36267 to 0.34310, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3925 - acc: 0.8386 - val_loss: 0.3321 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34310 to 0.33210, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3585 - acc: 0.8568 - val_loss: 0.3136 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33210 to 0.31362, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3579 - acc: 0.8627 - val_loss: 0.3054 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31362 to 0.30543, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3361 - acc: 0.8692 - val_loss: 0.2925 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.30543 to 0.29252, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3314 - acc: 0.8746 - val_loss: 0.2876 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.29252 to 0.28761, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3178 - acc: 0.8785 - val_loss: 0.2759 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.28761 to 0.27586, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3065 - acc: 0.8831 - val_loss: 0.2696 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27586 to 0.26955, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3014 - acc: 0.8858 - val_loss: 0.2604 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26955 to 0.26043, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2897 - acc: 0.8907 - val_loss: 0.2603 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.26043 to 0.26030, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2827 - acc: 0.8926 - val_loss: 0.2637 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26030\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2826 - acc: 0.8958 - val_loss: 0.2447 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26030 to 0.24468, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2615 - acc: 0.9055 - val_loss: 0.2389 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24468 to 0.23891, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2644 - acc: 0.9002 - val_loss: 0.2358 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23891 to 0.23577, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2583 - acc: 0.9031 - val_loss: 0.2269 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23577 to 0.22688, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2589 - acc: 0.9026 - val_loss: 0.2222 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22688 to 0.22218, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2515 - acc: 0.9043 - val_loss: 0.2244 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.22218\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2422 - acc: 0.9104 - val_loss: 0.2116 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22218 to 0.21163, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2458 - acc: 0.9070 - val_loss: 0.2189 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.21163\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2418 - acc: 0.9080 - val_loss: 0.2050 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21163 to 0.20497, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9133 - val_loss: 0.2067 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20497\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9136 - val_loss: 0.1952 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20497 to 0.19524, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2324 - acc: 0.9121 - val_loss: 0.1951 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19524 to 0.19509, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2241 - acc: 0.9140 - val_loss: 0.1894 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19509 to 0.18937, saving model to best.model\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2195 - acc: 0.9158 - val_loss: 0.1856 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18937 to 0.18557, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2068 - acc: 0.9233 - val_loss: 0.1937 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.18557\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2094 - acc: 0.9184 - val_loss: 0.1781 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18557 to 0.17811, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2118 - acc: 0.9189 - val_loss: 0.1761 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17811 to 0.17613, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2093 - acc: 0.9172 - val_loss: 0.1719 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17613 to 0.17187, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1935 - acc: 0.9260 - val_loss: 0.1671 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17187 to 0.16710, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1970 - acc: 0.9223 - val_loss: 0.1720 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16710\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1900 - acc: 0.9248 - val_loss: 0.1600 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16710 to 0.15998, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1848 - acc: 0.9304 - val_loss: 0.1549 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15998 to 0.15494, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1824 - acc: 0.9311 - val_loss: 0.1510 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15494 to 0.15102, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1823 - acc: 0.9333 - val_loss: 0.1544 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.15102\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1743 - acc: 0.9364 - val_loss: 0.1500 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15102 to 0.15003, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1784 - acc: 0.9326 - val_loss: 0.1458 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15003 to 0.14578, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1690 - acc: 0.9357 - val_loss: 0.1394 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14578 to 0.13935, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1625 - acc: 0.9352 - val_loss: 0.1466 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.13935\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1629 - acc: 0.9394 - val_loss: 0.1330 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13935 to 0.13295, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1692 - acc: 0.9352 - val_loss: 0.1315 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13295 to 0.13151, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1557 - acc: 0.9406 - val_loss: 0.1291 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.13151 to 0.12913, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1462 - acc: 0.9447 - val_loss: 0.1317 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.12913\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1582 - acc: 0.9377 - val_loss: 0.1214 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12913 to 0.12141, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1450 - acc: 0.9428 - val_loss: 0.1192 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12141 to 0.11921, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1480 - acc: 0.9442 - val_loss: 0.1269 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11921\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9464 - val_loss: 0.1185 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11921 to 0.11847, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1428 - acc: 0.9467 - val_loss: 0.1143 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.11847 to 0.11426, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1385 - acc: 0.9464 - val_loss: 0.1158 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11426\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1390 - acc: 0.9459 - val_loss: 0.1066 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11426 to 0.10665, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1313 - acc: 0.9513 - val_loss: 0.1050 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10665 to 0.10502, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1255 - acc: 0.9518 - val_loss: 0.1088 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10502\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9540 - val_loss: 0.0983 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10502 to 0.09832, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1276 - acc: 0.9518 - val_loss: 0.1042 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.09832\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9562 - val_loss: 0.0950 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09832 to 0.09496, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1136 - acc: 0.9562 - val_loss: 0.0924 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09496 to 0.09242, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1135 - acc: 0.9550 - val_loss: 0.0907 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09242 to 0.09073, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1085 - acc: 0.9584 - val_loss: 0.0884 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09073 to 0.08845, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1072 - acc: 0.9608 - val_loss: 0.0863 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08845 to 0.08631, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1075 - acc: 0.9613 - val_loss: 0.0849 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08631 to 0.08493, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1146 - acc: 0.9552 - val_loss: 0.0827 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08493 to 0.08272, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1009 - acc: 0.9608 - val_loss: 0.0833 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08272\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1114 - acc: 0.9591 - val_loss: 0.0822 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08272 to 0.08224, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1049 - acc: 0.9603 - val_loss: 0.0770 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08224 to 0.07703, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1000 - acc: 0.9642 - val_loss: 0.0751 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.07703 to 0.07506, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1069 - acc: 0.9606 - val_loss: 0.0736 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.07506 to 0.07361, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9642 - val_loss: 0.0709 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07361 to 0.07085, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9659 - val_loss: 0.0697 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07085 to 0.06969, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0872 - acc: 0.9696 - val_loss: 0.0684 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06969 to 0.06839, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0931 - acc: 0.9676 - val_loss: 0.0693 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06839\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9713 - val_loss: 0.0663 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06839 to 0.06630, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0931 - acc: 0.9679 - val_loss: 0.0626 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.06630 to 0.06257, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0917 - acc: 0.9640 - val_loss: 0.0605 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06257 to 0.06049, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0904 - acc: 0.9676 - val_loss: 0.0681 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.06049\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0911 - acc: 0.9635 - val_loss: 0.0592 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06049 to 0.05923, saving model to best.model\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0831 - acc: 0.9664 - val_loss: 0.0624 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05923\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0767 - acc: 0.9735 - val_loss: 0.0555 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05923 to 0.05548, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0781 - acc: 0.9705 - val_loss: 0.0546 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05548 to 0.05463, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9686 - val_loss: 0.0553 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05463\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9730 - val_loss: 0.0579 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05463\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9735 - val_loss: 0.0532 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05463 to 0.05318, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0746 - acc: 0.9698 - val_loss: 0.0549 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05318\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0837 - acc: 0.9705 - val_loss: 0.0590 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05318\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0747 - acc: 0.9739 - val_loss: 0.0519 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05318 to 0.05189, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9696 - val_loss: 0.0490 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05189 to 0.04900, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0711 - acc: 0.9749 - val_loss: 0.0506 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04900\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0747 - acc: 0.9725 - val_loss: 0.0535 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04900\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0805 - acc: 0.9732 - val_loss: 0.0492 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04900\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9725 - val_loss: 0.0480 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04900 to 0.04796, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9752 - val_loss: 0.0531 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04796\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0723 - acc: 0.9749 - val_loss: 0.0478 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04796 to 0.04782, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9781 - val_loss: 0.0458 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04782 to 0.04578, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9725 - val_loss: 0.0471 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04578\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0714 - acc: 0.9739 - val_loss: 0.0426 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04578 to 0.04256, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9791 - val_loss: 0.0448 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04256\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9769 - val_loss: 0.0415 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04256 to 0.04145, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9759 - val_loss: 0.0417 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04145\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0620 - acc: 0.9795 - val_loss: 0.0398 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04145 to 0.03981, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0620 - acc: 0.9783 - val_loss: 0.0437 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03981\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0697 - acc: 0.9749 - val_loss: 0.0398 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03981 to 0.03981, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9759 - val_loss: 0.0430 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03981\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9781 - val_loss: 0.0402 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03981\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9778 - val_loss: 0.0378 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03981 to 0.03780, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9795 - val_loss: 0.0381 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03780\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9771 - val_loss: 0.0353 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03780 to 0.03525, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9774 - val_loss: 0.0360 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03525\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9776 - val_loss: 0.0346 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03525 to 0.03463, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9791 - val_loss: 0.0373 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03463\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9827 - val_loss: 0.0350 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03463\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9817 - val_loss: 0.0331 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.03463 to 0.03310, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9793 - val_loss: 0.0301 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.03310 to 0.03010, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9791 - val_loss: 0.0303 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03010\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9776 - val_loss: 0.0307 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03010\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9791 - val_loss: 0.0313 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03010\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9791 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03010\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0529 - acc: 0.9808 - val_loss: 0.0307 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03010\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 12s - loss: 0.8522 - acc: 0.5013 - val_loss: 0.6918 - val_acc: 0.4654\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69184, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7734 - acc: 0.5245 - val_loss: 0.6477 - val_acc: 0.6514\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69184 to 0.64767, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7262 - acc: 0.5603 - val_loss: 0.6067 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64767 to 0.60671, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6720 - acc: 0.5965 - val_loss: 0.5401 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60671 to 0.54012, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5986 - acc: 0.6749 - val_loss: 0.4607 - val_acc: 0.8315\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54012 to 0.46071, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5152 - acc: 0.7524 - val_loss: 0.3923 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46071 to 0.39226, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4747 - acc: 0.7882 - val_loss: 0.3498 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39226 to 0.34976, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4261 - acc: 0.8220 - val_loss: 0.3221 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34976 to 0.32210, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3991 - acc: 0.8325 - val_loss: 0.3001 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32210 to 0.30009, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3818 - acc: 0.8425 - val_loss: 0.2880 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30009 to 0.28803, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3451 - acc: 0.8598 - val_loss: 0.2690 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28803 to 0.26898, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3408 - acc: 0.8641 - val_loss: 0.2570 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26898 to 0.25705, saving model to best.model\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3230 - acc: 0.8707 - val_loss: 0.2464 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25705 to 0.24637, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3154 - acc: 0.8770 - val_loss: 0.2492 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24637\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3228 - acc: 0.8683 - val_loss: 0.2312 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24637 to 0.23116, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2977 - acc: 0.8846 - val_loss: 0.2256 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.23116 to 0.22558, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2892 - acc: 0.8902 - val_loss: 0.2201 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22558 to 0.22009, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2806 - acc: 0.8948 - val_loss: 0.2121 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22009 to 0.21215, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2779 - acc: 0.8948 - val_loss: 0.2096 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.21215 to 0.20962, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2584 - acc: 0.9041 - val_loss: 0.2013 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20962 to 0.20128, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2572 - acc: 0.8994 - val_loss: 0.1958 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.20128 to 0.19577, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2615 - acc: 0.8965 - val_loss: 0.2041 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.19577\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2552 - acc: 0.9067 - val_loss: 0.1978 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.19577\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2551 - acc: 0.9050 - val_loss: 0.1858 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19577 to 0.18577, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2451 - acc: 0.9043 - val_loss: 0.1805 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18577 to 0.18047, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2417 - acc: 0.9070 - val_loss: 0.1762 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.18047 to 0.17625, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2397 - acc: 0.9131 - val_loss: 0.1732 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17625 to 0.17325, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2289 - acc: 0.9131 - val_loss: 0.1722 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.17325 to 0.17223, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2186 - acc: 0.9192 - val_loss: 0.1654 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17223 to 0.16544, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2246 - acc: 0.9172 - val_loss: 0.1621 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16544 to 0.16208, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2163 - acc: 0.9231 - val_loss: 0.1606 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.16208 to 0.16061, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2201 - acc: 0.9182 - val_loss: 0.1577 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16061 to 0.15772, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2081 - acc: 0.9245 - val_loss: 0.1517 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.15772 to 0.15175, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2096 - acc: 0.9252 - val_loss: 0.1555 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15175\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2160 - acc: 0.9189 - val_loss: 0.1473 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.15175 to 0.14726, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2007 - acc: 0.9291 - val_loss: 0.1458 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.14726 to 0.14583, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2047 - acc: 0.9240 - val_loss: 0.1428 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.14583 to 0.14279, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1951 - acc: 0.9318 - val_loss: 0.1460 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14279\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1961 - acc: 0.9284 - val_loss: 0.1390 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14279 to 0.13896, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1900 - acc: 0.9308 - val_loss: 0.1364 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.13896 to 0.13640, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9352 - val_loss: 0.1315 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13640 to 0.13149, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1902 - acc: 0.9313 - val_loss: 0.1369 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13149\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1861 - acc: 0.9323 - val_loss: 0.1269 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13149 to 0.12690, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1869 - acc: 0.9306 - val_loss: 0.1300 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12690\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1850 - acc: 0.9340 - val_loss: 0.1243 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12690 to 0.12433, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1828 - acc: 0.9345 - val_loss: 0.1214 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12433 to 0.12138, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1826 - acc: 0.9379 - val_loss: 0.1217 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.12138\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1748 - acc: 0.9377 - val_loss: 0.1152 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12138 to 0.11515, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1678 - acc: 0.9382 - val_loss: 0.1125 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11515 to 0.11253, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1632 - acc: 0.9438 - val_loss: 0.1110 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11253 to 0.11098, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1685 - acc: 0.9386 - val_loss: 0.1079 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11098 to 0.10789, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1595 - acc: 0.9435 - val_loss: 0.1054 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10789 to 0.10543, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1548 - acc: 0.9452 - val_loss: 0.1043 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10543 to 0.10429, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1564 - acc: 0.9433 - val_loss: 0.1013 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10429 to 0.10135, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1468 - acc: 0.9447 - val_loss: 0.1002 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10135 to 0.10019, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1499 - acc: 0.9457 - val_loss: 0.0976 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10019 to 0.09760, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9501 - val_loss: 0.0970 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09760 to 0.09696, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1438 - acc: 0.9435 - val_loss: 0.0961 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09696 to 0.09610, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1458 - acc: 0.9438 - val_loss: 0.0908 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09610 to 0.09085, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9459 - val_loss: 0.0873 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09085 to 0.08735, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1331 - acc: 0.9533 - val_loss: 0.0871 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08735 to 0.08708, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1316 - acc: 0.9491 - val_loss: 0.0846 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08708 to 0.08457, saving model to best.model\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1302 - acc: 0.9484 - val_loss: 0.0797 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08457 to 0.07972, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1322 - acc: 0.9520 - val_loss: 0.0773 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07972 to 0.07733, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1240 - acc: 0.9530 - val_loss: 0.0751 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07733 to 0.07506, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1245 - acc: 0.9557 - val_loss: 0.0742 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07506 to 0.07423, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1187 - acc: 0.9569 - val_loss: 0.0711 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07423 to 0.07112, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1134 - acc: 0.9586 - val_loss: 0.0670 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07112 to 0.06701, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9593 - val_loss: 0.0674 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06701\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9550 - val_loss: 0.0626 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06701 to 0.06258, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9618 - val_loss: 0.0608 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06258 to 0.06084, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1055 - acc: 0.9574 - val_loss: 0.0629 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06084\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1137 - acc: 0.9567 - val_loss: 0.0568 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06084 to 0.05681, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9610 - val_loss: 0.0574 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05681\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9591 - val_loss: 0.0557 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05681 to 0.05569, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0993 - acc: 0.9645 - val_loss: 0.0596 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05569\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1055 - acc: 0.9586 - val_loss: 0.0515 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05569 to 0.05146, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9630 - val_loss: 0.0545 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05146\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9649 - val_loss: 0.0498 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05146 to 0.04978, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9679 - val_loss: 0.0473 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04978 to 0.04733, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0967 - acc: 0.9627 - val_loss: 0.0463 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04733 to 0.04634, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0871 - acc: 0.9679 - val_loss: 0.0553 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04634\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9647 - val_loss: 0.0439 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04634 to 0.04391, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0898 - acc: 0.9640 - val_loss: 0.0414 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04391 to 0.04140, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9674 - val_loss: 0.0440 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04140\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0985 - acc: 0.9630 - val_loss: 0.0440 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04140\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1005 - acc: 0.9632 - val_loss: 0.0419 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04140\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0856 - acc: 0.9696 - val_loss: 0.0402 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04140 to 0.04025, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0805 - acc: 0.9715 - val_loss: 0.0376 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04025 to 0.03762, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0846 - acc: 0.9683 - val_loss: 0.0408 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03762\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9679 - val_loss: 0.0367 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03762 to 0.03673, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9722 - val_loss: 0.0351 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03673 to 0.03509, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9747 - val_loss: 0.0352 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03509\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9735 - val_loss: 0.0323 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03509 to 0.03233, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9747 - val_loss: 0.0328 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03233\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9735 - val_loss: 0.0297 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03233 to 0.02975, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0767 - acc: 0.9730 - val_loss: 0.0294 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02975 to 0.02936, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9725 - val_loss: 0.0304 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02936\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9769 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.02936 to 0.02860, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9727 - val_loss: 0.0276 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02860 to 0.02756, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9732 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02756\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0680 - acc: 0.9749 - val_loss: 0.0281 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02756\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0571 - acc: 0.9810 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02756 to 0.02699, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9774 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02699 to 0.02394, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9742 - val_loss: 0.0236 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02394 to 0.02363, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9761 - val_loss: 0.0276 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02363\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9781 - val_loss: 0.0214 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02363 to 0.02136, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9737 - val_loss: 0.0208 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02136 to 0.02082, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9791 - val_loss: 0.0209 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02082\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9720 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02082\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9764 - val_loss: 0.0225 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02082\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9771 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02082 to 0.02025, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9764 - val_loss: 0.0305 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02025\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9793 - val_loss: 0.0199 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02025 to 0.01990, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9795 - val_loss: 0.0209 - val_acc: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01990\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0551 - acc: 0.9786 - val_loss: 0.0189 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01990 to 0.01891, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9830 - val_loss: 0.0184 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01891 to 0.01844, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9815 - val_loss: 0.0194 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01844\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9803 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01844\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9776 - val_loss: 0.0197 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01844\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0504 - acc: 0.9815 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01844 to 0.01719, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0536 - acc: 0.9800 - val_loss: 0.0188 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01719\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9752 - val_loss: 0.0246 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01719\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9805 - val_loss: 0.0202 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01719\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9761 - val_loss: 0.0172 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01719 to 0.01719, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9803 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01719\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9815 - val_loss: 0.0175 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01719\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9766 - val_loss: 0.0235 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01719\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0514 - acc: 0.9813 - val_loss: 0.0181 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01719\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9808 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01719\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 12s - loss: 0.8460 - acc: 0.5096 - val_loss: 0.6783 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67834, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7802 - acc: 0.5184 - val_loss: 0.6464 - val_acc: 0.7702\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67834 to 0.64642, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7353 - acc: 0.5435 - val_loss: 0.6074 - val_acc: 0.7468\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64642 to 0.60743, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6699 - acc: 0.6043 - val_loss: 0.5472 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60743 to 0.54723, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6054 - acc: 0.6747 - val_loss: 0.4780 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54723 to 0.47803, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5609 - acc: 0.7210 - val_loss: 0.4285 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47803 to 0.42855, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.5040 - acc: 0.7655 - val_loss: 0.3877 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42855 to 0.38770, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4713 - acc: 0.7952 - val_loss: 0.3604 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38770 to 0.36035, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4372 - acc: 0.8081 - val_loss: 0.3384 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36035 to 0.33843, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.4181 - acc: 0.8215 - val_loss: 0.3244 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33843 to 0.32443, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.4111 - acc: 0.8266 - val_loss: 0.3084 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32443 to 0.30837, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3913 - acc: 0.8398 - val_loss: 0.2929 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30837 to 0.29289, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3797 - acc: 0.8478 - val_loss: 0.2865 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29289 to 0.28654, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3579 - acc: 0.8546 - val_loss: 0.2767 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28654 to 0.27667, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3503 - acc: 0.8546 - val_loss: 0.2651 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27667 to 0.26510, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3436 - acc: 0.8632 - val_loss: 0.2581 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26510 to 0.25807, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3365 - acc: 0.8685 - val_loss: 0.2512 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25807 to 0.25121, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3266 - acc: 0.8722 - val_loss: 0.2456 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25121 to 0.24564, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3269 - acc: 0.8753 - val_loss: 0.2425 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24564 to 0.24253, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3127 - acc: 0.8792 - val_loss: 0.2352 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24253 to 0.23519, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2987 - acc: 0.8858 - val_loss: 0.2301 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23519 to 0.23013, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.3003 - acc: 0.8853 - val_loss: 0.2273 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23013 to 0.22728, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3024 - acc: 0.8834 - val_loss: 0.2309 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.22728\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2995 - acc: 0.8880 - val_loss: 0.2249 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22728 to 0.22491, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2842 - acc: 0.8907 - val_loss: 0.2174 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22491 to 0.21735, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2871 - acc: 0.8919 - val_loss: 0.2132 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21735 to 0.21317, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2777 - acc: 0.8955 - val_loss: 0.2087 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21317 to 0.20865, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2639 - acc: 0.9019 - val_loss: 0.2052 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20865 to 0.20516, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2646 - acc: 0.9033 - val_loss: 0.2010 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20516 to 0.20103, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2593 - acc: 0.9033 - val_loss: 0.1987 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20103 to 0.19871, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2593 - acc: 0.9016 - val_loss: 0.1956 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19871 to 0.19556, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2507 - acc: 0.9075 - val_loss: 0.1937 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19556 to 0.19372, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2484 - acc: 0.9080 - val_loss: 0.1891 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19372 to 0.18913, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2456 - acc: 0.9058 - val_loss: 0.1845 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18913 to 0.18454, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2366 - acc: 0.9084 - val_loss: 0.1806 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18454 to 0.18064, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2416 - acc: 0.9063 - val_loss: 0.1782 - val_acc: 0.9318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_loss improved from 0.18064 to 0.17824, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9145 - val_loss: 0.1749 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17824 to 0.17489, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2316 - acc: 0.9136 - val_loss: 0.1697 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17489 to 0.16972, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2262 - acc: 0.9106 - val_loss: 0.1661 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16972 to 0.16613, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9175 - val_loss: 0.1634 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16613 to 0.16337, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2247 - acc: 0.9160 - val_loss: 0.1630 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16337 to 0.16297, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2140 - acc: 0.9194 - val_loss: 0.1694 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16297\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2130 - acc: 0.9175 - val_loss: 0.1564 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16297 to 0.15643, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2098 - acc: 0.9201 - val_loss: 0.1532 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15643 to 0.15322, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1998 - acc: 0.9221 - val_loss: 0.1468 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15322 to 0.14678, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1923 - acc: 0.9296 - val_loss: 0.1436 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14678 to 0.14358, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1993 - acc: 0.9245 - val_loss: 0.1393 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14358 to 0.13933, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1883 - acc: 0.9267 - val_loss: 0.1345 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13933 to 0.13449, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1774 - acc: 0.9335 - val_loss: 0.1311 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13449 to 0.13109, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9355 - val_loss: 0.1262 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.13109 to 0.12625, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1751 - acc: 0.9340 - val_loss: 0.1233 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12625 to 0.12326, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1775 - acc: 0.9277 - val_loss: 0.1197 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12326 to 0.11970, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1679 - acc: 0.9362 - val_loss: 0.1161 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11970 to 0.11614, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1636 - acc: 0.9374 - val_loss: 0.1122 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11614 to 0.11225, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9352 - val_loss: 0.1096 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11225 to 0.10961, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1540 - acc: 0.9391 - val_loss: 0.1079 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10961 to 0.10791, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1562 - acc: 0.9355 - val_loss: 0.1032 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10791 to 0.10324, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1520 - acc: 0.9425 - val_loss: 0.0985 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10324 to 0.09849, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1544 - acc: 0.9389 - val_loss: 0.1005 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.09849\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1531 - acc: 0.9416 - val_loss: 0.0932 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09849 to 0.09324, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1510 - acc: 0.9438 - val_loss: 0.0888 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09324 to 0.08882, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9489 - val_loss: 0.0854 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08882 to 0.08535, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1408 - acc: 0.9440 - val_loss: 0.0834 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08535 to 0.08342, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1296 - acc: 0.9503 - val_loss: 0.0806 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08342 to 0.08064, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1329 - acc: 0.9511 - val_loss: 0.0778 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08064 to 0.07784, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1358 - acc: 0.9486 - val_loss: 0.0744 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07784 to 0.07435, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1254 - acc: 0.9513 - val_loss: 0.0752 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07435\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1324 - acc: 0.9481 - val_loss: 0.0704 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07435 to 0.07038, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1215 - acc: 0.9537 - val_loss: 0.0679 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07038 to 0.06788, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1087 - acc: 0.9610 - val_loss: 0.0655 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06788 to 0.06549, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1147 - acc: 0.9574 - val_loss: 0.0613 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06549 to 0.06127, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1064 - acc: 0.9579 - val_loss: 0.0594 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06127 to 0.05937, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1116 - acc: 0.9596 - val_loss: 0.0582 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05937 to 0.05820, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1127 - acc: 0.9564 - val_loss: 0.0542 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05820 to 0.05418, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1075 - acc: 0.9562 - val_loss: 0.0532 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05418 to 0.05325, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9608 - val_loss: 0.0517 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05325 to 0.05170, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1010 - acc: 0.9608 - val_loss: 0.0513 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05170 to 0.05127, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1073 - acc: 0.9559 - val_loss: 0.0491 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05127 to 0.04910, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1000 - acc: 0.9632 - val_loss: 0.0471 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04910 to 0.04715, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0988 - acc: 0.9613 - val_loss: 0.0472 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04715\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0923 - acc: 0.9630 - val_loss: 0.0436 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04715 to 0.04358, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9669 - val_loss: 0.0419 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04358 to 0.04185, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0884 - acc: 0.9645 - val_loss: 0.0410 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04185 to 0.04105, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9652 - val_loss: 0.0400 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04105 to 0.03998, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9688 - val_loss: 0.0400 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03998\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0822 - acc: 0.9647 - val_loss: 0.0374 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03998 to 0.03736, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9683 - val_loss: 0.0395 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03736\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9686 - val_loss: 0.0360 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03736 to 0.03598, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0794 - acc: 0.9703 - val_loss: 0.0375 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03598\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9652 - val_loss: 0.0335 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03598 to 0.03347, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9676 - val_loss: 0.0310 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03347 to 0.03101, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0823 - acc: 0.9676 - val_loss: 0.0310 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03101 to 0.03100, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9691 - val_loss: 0.0365 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03100\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9669 - val_loss: 0.0300 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03100 to 0.02998, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9705 - val_loss: 0.0284 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.02998 to 0.02835, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0728 - acc: 0.9725 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.02835 to 0.02820, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9732 - val_loss: 0.0286 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02820\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9744 - val_loss: 0.0274 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02820 to 0.02740, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9735 - val_loss: 0.0294 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02740\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0747 - acc: 0.9722 - val_loss: 0.0271 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02740 to 0.02711, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9720 - val_loss: 0.0307 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02711\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9720 - val_loss: 0.0263 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.02711 to 0.02631, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9703 - val_loss: 0.0265 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02631\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9696 - val_loss: 0.0267 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02631\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9727 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02631 to 0.02296, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9754 - val_loss: 0.0231 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02296\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9752 - val_loss: 0.0222 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02296 to 0.02219, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9764 - val_loss: 0.0215 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02219 to 0.02147, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9752 - val_loss: 0.0205 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02147 to 0.02049, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9747 - val_loss: 0.0254 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02049\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9730 - val_loss: 0.0217 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02049\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0529 - acc: 0.9805 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02049 to 0.01995, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0583 - acc: 0.9776 - val_loss: 0.0230 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01995\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9786 - val_loss: 0.0185 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01995 to 0.01847, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9739 - val_loss: 0.0176 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.01847 to 0.01756, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9757 - val_loss: 0.0201 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.01756\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9776 - val_loss: 0.0193 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01756\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0591 - acc: 0.9786 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.01756 to 0.01660, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9725 - val_loss: 0.0267 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01660\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9800 - val_loss: 0.0192 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01660\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9781 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01660\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9791 - val_loss: 0.0166 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01660 to 0.01660, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0580 - acc: 0.9778 - val_loss: 0.0206 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01660\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9815 - val_loss: 0.0176 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01660\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9747 - val_loss: 0.0168 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01660\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9783 - val_loss: 0.0147 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01660 to 0.01466, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9783 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01466\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9837 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01466 to 0.01333, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9800 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01333 to 0.01326, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9793 - val_loss: 0.0214 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01326\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9788 - val_loss: 0.0138 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01326\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0580 - acc: 0.9783 - val_loss: 0.0142 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01326\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0549 - acc: 0.9808 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01326\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9822 - val_loss: 0.0127 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01326 to 0.01266, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0488 - acc: 0.9849 - val_loss: 0.0143 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01266\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9822 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01266\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9825 - val_loss: 0.0120 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01266 to 0.01195, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9827 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01195\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0437 - acc: 0.9839 - val_loss: 0.0111 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01195 to 0.01108, saving model to best.model\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0436 - acc: 0.9830 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01108\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9830 - val_loss: 0.0123 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01108\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9798 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01108 to 0.01000, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9808 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01000\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0477 - acc: 0.9810 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01000\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9810 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01000\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9827 - val_loss: 0.0107 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01000\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9810 - val_loss: 0.0121 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01000\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 0.8019 - acc: 0.5133 - val_loss: 0.6849 - val_acc: 0.4985\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68493, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7559 - acc: 0.5235 - val_loss: 0.6475 - val_acc: 0.7098\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68493 to 0.64754, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7034 - acc: 0.5542 - val_loss: 0.6060 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64754 to 0.60601, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6473 - acc: 0.6233 - val_loss: 0.5361 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60601 to 0.53610, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5729 - acc: 0.7020 - val_loss: 0.4640 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53610 to 0.46404, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4993 - acc: 0.7636 - val_loss: 0.4101 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46404 to 0.41006, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4454 - acc: 0.8052 - val_loss: 0.3783 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41006 to 0.37832, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4164 - acc: 0.8223 - val_loss: 0.3533 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37832 to 0.35327, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4002 - acc: 0.8318 - val_loss: 0.3432 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35327 to 0.34318, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3909 - acc: 0.8447 - val_loss: 0.3278 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34318 to 0.32783, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3716 - acc: 0.8534 - val_loss: 0.3089 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32783 to 0.30892, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3495 - acc: 0.8602 - val_loss: 0.2959 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30892 to 0.29590, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3403 - acc: 0.8680 - val_loss: 0.2902 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29590 to 0.29022, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3267 - acc: 0.8724 - val_loss: 0.2784 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.29022 to 0.27840, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3209 - acc: 0.8761 - val_loss: 0.2679 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27840 to 0.26795, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3104 - acc: 0.8814 - val_loss: 0.2621 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26795 to 0.26205, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3078 - acc: 0.8858 - val_loss: 0.2572 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26205 to 0.25715, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3040 - acc: 0.8914 - val_loss: 0.2503 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25715 to 0.25030, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2898 - acc: 0.8921 - val_loss: 0.2482 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.25030 to 0.24823, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2898 - acc: 0.8916 - val_loss: 0.2385 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24823 to 0.23848, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2889 - acc: 0.8914 - val_loss: 0.2353 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23848 to 0.23529, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2802 - acc: 0.8985 - val_loss: 0.2321 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23529 to 0.23208, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2765 - acc: 0.9014 - val_loss: 0.2250 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23208 to 0.22496, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2716 - acc: 0.9021 - val_loss: 0.2222 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22496 to 0.22223, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2661 - acc: 0.9050 - val_loss: 0.2163 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22223 to 0.21628, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2645 - acc: 0.9053 - val_loss: 0.2167 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.21628\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2597 - acc: 0.9014 - val_loss: 0.2199 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.21628\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2550 - acc: 0.9089 - val_loss: 0.2075 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21628 to 0.20750, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2532 - acc: 0.9055 - val_loss: 0.2034 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20750 to 0.20336, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2428 - acc: 0.9104 - val_loss: 0.1991 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20336 to 0.19915, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2435 - acc: 0.9087 - val_loss: 0.1929 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19915 to 0.19285, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2353 - acc: 0.9167 - val_loss: 0.1933 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.19285\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2402 - acc: 0.9153 - val_loss: 0.1862 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19285 to 0.18616, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2268 - acc: 0.9153 - val_loss: 0.1799 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18616 to 0.17994, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2233 - acc: 0.9172 - val_loss: 0.1742 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17994 to 0.17418, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2260 - acc: 0.9158 - val_loss: 0.1685 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17418 to 0.16852, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2119 - acc: 0.9150 - val_loss: 0.1638 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16852 to 0.16379, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2217 - acc: 0.9148 - val_loss: 0.1769 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16379\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2069 - acc: 0.9238 - val_loss: 0.1593 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16379 to 0.15926, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2021 - acc: 0.9267 - val_loss: 0.1498 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15926 to 0.14984, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1964 - acc: 0.9287 - val_loss: 0.1465 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14984 to 0.14646, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1998 - acc: 0.9238 - val_loss: 0.1479 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14646\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1939 - acc: 0.9287 - val_loss: 0.1364 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14646 to 0.13645, saving model to best.model\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1836 - acc: 0.9333 - val_loss: 0.1378 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.13645\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1812 - acc: 0.9330 - val_loss: 0.1293 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13645 to 0.12929, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1774 - acc: 0.9357 - val_loss: 0.1261 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12929 to 0.12606, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1776 - acc: 0.9311 - val_loss: 0.1238 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12606 to 0.12384, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1773 - acc: 0.9321 - val_loss: 0.1196 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12384 to 0.11963, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1686 - acc: 0.9355 - val_loss: 0.1187 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11963 to 0.11870, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1693 - acc: 0.9401 - val_loss: 0.1178 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11870 to 0.11779, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1617 - acc: 0.9421 - val_loss: 0.1121 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11779 to 0.11214, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1555 - acc: 0.9386 - val_loss: 0.1066 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11214 to 0.10656, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1537 - acc: 0.9411 - val_loss: 0.1098 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10656\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1523 - acc: 0.9421 - val_loss: 0.1012 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10656 to 0.10119, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1471 - acc: 0.9445 - val_loss: 0.0994 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10119 to 0.09940, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1481 - acc: 0.9440 - val_loss: 0.0987 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.09940 to 0.09866, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1379 - acc: 0.9503 - val_loss: 0.0958 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09866 to 0.09583, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9491 - val_loss: 0.0913 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09583 to 0.09132, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1425 - acc: 0.9503 - val_loss: 0.0891 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09132 to 0.08915, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1390 - acc: 0.9486 - val_loss: 0.0882 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08915 to 0.08824, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1312 - acc: 0.9511 - val_loss: 0.0863 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08824 to 0.08633, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1291 - acc: 0.9518 - val_loss: 0.0828 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08633 to 0.08276, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9501 - val_loss: 0.0799 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08276 to 0.07995, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1272 - acc: 0.9506 - val_loss: 0.0783 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07995 to 0.07829, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1230 - acc: 0.9528 - val_loss: 0.0784 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07829\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1232 - acc: 0.9535 - val_loss: 0.0766 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07829 to 0.07663, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1148 - acc: 0.9557 - val_loss: 0.0729 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07663 to 0.07292, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1133 - acc: 0.9554 - val_loss: 0.0702 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07292 to 0.07019, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1130 - acc: 0.9564 - val_loss: 0.0683 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07019 to 0.06828, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1074 - acc: 0.9598 - val_loss: 0.0676 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06828 to 0.06761, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1033 - acc: 0.9574 - val_loss: 0.0658 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06761 to 0.06580, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9625 - val_loss: 0.0697 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06580\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1093 - acc: 0.9569 - val_loss: 0.0674 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06580\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1046 - acc: 0.9615 - val_loss: 0.0638 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06580 to 0.06379, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1085 - acc: 0.9618 - val_loss: 0.0587 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06379 to 0.05870, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0950 - acc: 0.9662 - val_loss: 0.0603 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05870\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9625 - val_loss: 0.0546 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05870 to 0.05460, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1057 - acc: 0.9579 - val_loss: 0.0569 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05460\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0944 - acc: 0.9674 - val_loss: 0.0547 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05460\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0972 - acc: 0.9654 - val_loss: 0.0534 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05460 to 0.05343, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0931 - acc: 0.9649 - val_loss: 0.0510 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05343 to 0.05103, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9669 - val_loss: 0.0507 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05103 to 0.05069, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9671 - val_loss: 0.0495 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05069 to 0.04949, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0899 - acc: 0.9666 - val_loss: 0.0478 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04949 to 0.04782, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9654 - val_loss: 0.0478 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04782\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0852 - acc: 0.9696 - val_loss: 0.0481 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04782\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9737 - val_loss: 0.0473 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04782 to 0.04725, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0779 - acc: 0.9693 - val_loss: 0.0472 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04725 to 0.04719, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9718 - val_loss: 0.0433 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04719 to 0.04327, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9718 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04327 to 0.04126, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9739 - val_loss: 0.0419 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04126\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0711 - acc: 0.9742 - val_loss: 0.0415 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04126\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9705 - val_loss: 0.0424 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04126\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9710 - val_loss: 0.0406 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04126 to 0.04056, saving model to best.model\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0764 - acc: 0.9715 - val_loss: 0.0402 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04056 to 0.04019, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9735 - val_loss: 0.0400 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04019 to 0.03996, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9703 - val_loss: 0.0389 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03996 to 0.03889, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0736 - acc: 0.9739 - val_loss: 0.0392 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03889\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9761 - val_loss: 0.0364 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03889 to 0.03643, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9749 - val_loss: 0.0389 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03643\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9742 - val_loss: 0.0365 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03643\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9764 - val_loss: 0.0381 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03643\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9769 - val_loss: 0.0350 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03643 to 0.03496, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9759 - val_loss: 0.0341 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03496 to 0.03410, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9771 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03410\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9749 - val_loss: 0.0373 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03410\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0664 - acc: 0.9769 - val_loss: 0.0363 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03410\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9781 - val_loss: 0.0338 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03410 to 0.03384, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9803 - val_loss: 0.0359 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03384\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0603 - acc: 0.9764 - val_loss: 0.0339 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03384\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9808 - val_loss: 0.0317 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03384 to 0.03173, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9791 - val_loss: 0.0335 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03173\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0313 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.03173 to 0.03130, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0536 - acc: 0.9810 - val_loss: 0.0287 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.03130 to 0.02867, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9822 - val_loss: 0.0320 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02867\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9803 - val_loss: 0.0288 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02867\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0550 - acc: 0.9813 - val_loss: 0.0269 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02867 to 0.02691, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9808 - val_loss: 0.0339 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02691\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9769 - val_loss: 0.0279 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02691\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9788 - val_loss: 0.0320 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02691\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0548 - acc: 0.9769 - val_loss: 0.0269 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02691\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0490 - acc: 0.9832 - val_loss: 0.0270 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02691\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 0.7905 - acc: 0.5052 - val_loss: 0.6676 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66764, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7359 - acc: 0.5225 - val_loss: 0.6375 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66764 to 0.63752, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6818 - acc: 0.5785 - val_loss: 0.5846 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63752 to 0.58457, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6141 - acc: 0.6628 - val_loss: 0.5090 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58457 to 0.50903, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5401 - acc: 0.7331 - val_loss: 0.4319 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50903 to 0.43187, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4798 - acc: 0.7894 - val_loss: 0.3933 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43187 to 0.39334, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4615 - acc: 0.8035 - val_loss: 0.3638 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39334 to 0.36381, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4135 - acc: 0.8269 - val_loss: 0.3382 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36381 to 0.33823, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3959 - acc: 0.8415 - val_loss: 0.3245 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33823 to 0.32448, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3785 - acc: 0.8503 - val_loss: 0.3019 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32448 to 0.30193, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3544 - acc: 0.8671 - val_loss: 0.2892 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30193 to 0.28921, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3476 - acc: 0.8588 - val_loss: 0.2826 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28921 to 0.28264, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3376 - acc: 0.8685 - val_loss: 0.2756 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28264 to 0.27562, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3286 - acc: 0.8697 - val_loss: 0.2616 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27562 to 0.26165, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3252 - acc: 0.8736 - val_loss: 0.2729 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26165\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3048 - acc: 0.8858 - val_loss: 0.2503 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26165 to 0.25030, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3073 - acc: 0.8890 - val_loss: 0.2500 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25030 to 0.24999, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2987 - acc: 0.8919 - val_loss: 0.2412 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24999 to 0.24122, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2763 - acc: 0.8992 - val_loss: 0.2370 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24122 to 0.23697, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2766 - acc: 0.8990 - val_loss: 0.2403 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.23697\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2783 - acc: 0.9031 - val_loss: 0.2301 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23697 to 0.23011, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2795 - acc: 0.9024 - val_loss: 0.2288 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23011 to 0.22878, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2620 - acc: 0.9036 - val_loss: 0.2233 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22878 to 0.22327, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2590 - acc: 0.9094 - val_loss: 0.2208 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22327 to 0.22083, saving model to best.model\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2495 - acc: 0.9121 - val_loss: 0.2180 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22083 to 0.21804, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2618 - acc: 0.9050 - val_loss: 0.2232 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.21804\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2540 - acc: 0.9092 - val_loss: 0.2112 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21804 to 0.21119, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2464 - acc: 0.9123 - val_loss: 0.2095 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21119 to 0.20955, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2454 - acc: 0.9116 - val_loss: 0.2071 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20955 to 0.20714, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2335 - acc: 0.9140 - val_loss: 0.2086 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20714\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2320 - acc: 0.9162 - val_loss: 0.2002 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20714 to 0.20023, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2321 - acc: 0.9138 - val_loss: 0.1969 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20023 to 0.19689, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2319 - acc: 0.9177 - val_loss: 0.1961 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19689 to 0.19614, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2262 - acc: 0.9204 - val_loss: 0.1912 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19614 to 0.19124, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2187 - acc: 0.9177 - val_loss: 0.1890 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19124 to 0.18896, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2188 - acc: 0.9184 - val_loss: 0.1920 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.18896\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2235 - acc: 0.9177 - val_loss: 0.1835 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18896 to 0.18350, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2142 - acc: 0.9214 - val_loss: 0.1801 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18350 to 0.18013, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2103 - acc: 0.9270 - val_loss: 0.1825 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.18013\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2036 - acc: 0.9252 - val_loss: 0.1775 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18013 to 0.17747, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2028 - acc: 0.9243 - val_loss: 0.1717 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17747 to 0.17171, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2048 - acc: 0.9233 - val_loss: 0.1687 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17171 to 0.16872, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2057 - acc: 0.9248 - val_loss: 0.1663 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16872 to 0.16633, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1947 - acc: 0.9279 - val_loss: 0.1693 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16633\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9228 - val_loss: 0.1630 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16633 to 0.16304, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1896 - acc: 0.9284 - val_loss: 0.1590 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16304 to 0.15903, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1940 - acc: 0.9321 - val_loss: 0.1565 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15903 to 0.15647, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9308 - val_loss: 0.1528 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15647 to 0.15277, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1824 - acc: 0.9340 - val_loss: 0.1503 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15277 to 0.15031, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1847 - acc: 0.9323 - val_loss: 0.1461 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15031 to 0.14612, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1804 - acc: 0.9362 - val_loss: 0.1491 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.14612\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1794 - acc: 0.9299 - val_loss: 0.1409 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14612 to 0.14090, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1831 - acc: 0.9299 - val_loss: 0.1395 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14090 to 0.13951, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1780 - acc: 0.9328 - val_loss: 0.1365 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13951 to 0.13654, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1660 - acc: 0.9330 - val_loss: 0.1379 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.13654\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1644 - acc: 0.9345 - val_loss: 0.1299 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13654 to 0.12991, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1607 - acc: 0.9345 - val_loss: 0.1259 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12991 to 0.12588, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1619 - acc: 0.9384 - val_loss: 0.1235 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12588 to 0.12352, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1541 - acc: 0.9389 - val_loss: 0.1184 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12352 to 0.11840, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1573 - acc: 0.9391 - val_loss: 0.1165 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11840 to 0.11652, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1438 - acc: 0.9423 - val_loss: 0.1116 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11652 to 0.11164, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9428 - val_loss: 0.1062 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11164 to 0.10616, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1468 - acc: 0.9423 - val_loss: 0.1027 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10616 to 0.10266, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1452 - acc: 0.9418 - val_loss: 0.1002 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10266 to 0.10019, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1332 - acc: 0.9450 - val_loss: 0.0987 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10019 to 0.09873, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1348 - acc: 0.9462 - val_loss: 0.0906 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09873 to 0.09065, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9455 - val_loss: 0.0872 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09065 to 0.08717, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1373 - acc: 0.9467 - val_loss: 0.0881 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08717\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1290 - acc: 0.9459 - val_loss: 0.0829 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08717 to 0.08290, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1225 - acc: 0.9525 - val_loss: 0.0786 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08290 to 0.07864, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1194 - acc: 0.9535 - val_loss: 0.0758 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07864 to 0.07584, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9554 - val_loss: 0.0719 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07584 to 0.07187, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1164 - acc: 0.9542 - val_loss: 0.0704 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.07187 to 0.07037, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9537 - val_loss: 0.0685 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.07037 to 0.06845, saving model to best.model\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1180 - acc: 0.9550 - val_loss: 0.0633 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06845 to 0.06329, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1131 - acc: 0.9559 - val_loss: 0.0618 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06329 to 0.06182, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9554 - val_loss: 0.0676 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06182\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1143 - acc: 0.9584 - val_loss: 0.0595 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06182 to 0.05946, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9593 - val_loss: 0.0573 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05946 to 0.05726, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0933 - acc: 0.9627 - val_loss: 0.0541 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05726 to 0.05406, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9637 - val_loss: 0.0516 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05406 to 0.05157, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9627 - val_loss: 0.0523 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05157\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0990 - acc: 0.9647 - val_loss: 0.0499 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05157 to 0.04993, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9618 - val_loss: 0.0478 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04993 to 0.04780, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9659 - val_loss: 0.0488 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04780\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0858 - acc: 0.9683 - val_loss: 0.0458 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04780 to 0.04580, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0903 - acc: 0.9664 - val_loss: 0.0422 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04580 to 0.04215, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0911 - acc: 0.9649 - val_loss: 0.0436 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04215\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9669 - val_loss: 0.0426 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04215\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0842 - acc: 0.9693 - val_loss: 0.0421 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04215 to 0.04208, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9623 - val_loss: 0.0426 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04208\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0827 - acc: 0.9681 - val_loss: 0.0387 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04208 to 0.03875, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9725 - val_loss: 0.0363 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03875 to 0.03634, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0832 - acc: 0.9676 - val_loss: 0.0374 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03634\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0799 - acc: 0.9715 - val_loss: 0.0353 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03634 to 0.03529, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0704 - acc: 0.9735 - val_loss: 0.0357 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03529\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0807 - acc: 0.9710 - val_loss: 0.0346 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03529 to 0.03455, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0842 - acc: 0.9683 - val_loss: 0.0345 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03455 to 0.03454, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0741 - acc: 0.9737 - val_loss: 0.0316 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03454 to 0.03157, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9681 - val_loss: 0.0338 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03157\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0747 - acc: 0.9708 - val_loss: 0.0304 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03157 to 0.03040, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0732 - acc: 0.9703 - val_loss: 0.0334 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03040\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0704 - acc: 0.9749 - val_loss: 0.0300 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03040 to 0.03003, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9744 - val_loss: 0.0301 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03003\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9725 - val_loss: 0.0293 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03003 to 0.02935, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9825 - val_loss: 0.0282 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02935 to 0.02820, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0674 - acc: 0.9732 - val_loss: 0.0297 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02820\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0655 - acc: 0.9783 - val_loss: 0.0274 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02820 to 0.02742, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9715 - val_loss: 0.0284 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02742\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0675 - acc: 0.9739 - val_loss: 0.0252 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02742 to 0.02516, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9783 - val_loss: 0.0267 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02516\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9752 - val_loss: 0.0261 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02516\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9793 - val_loss: 0.0254 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02516\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0614 - acc: 0.9786 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02516 to 0.02349, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9766 - val_loss: 0.0258 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02349\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0591 - acc: 0.9752 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02349 to 0.02263, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9761 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02263 to 0.02222, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0573 - acc: 0.9774 - val_loss: 0.0215 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02222 to 0.02154, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9783 - val_loss: 0.0208 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02154 to 0.02080, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9781 - val_loss: 0.0267 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02080\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9781 - val_loss: 0.0221 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02080\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9798 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02080\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9791 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02080\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0547 - acc: 0.9805 - val_loss: 0.0224 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02080\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 0.8488 - acc: 0.4977 - val_loss: 0.6795 - val_acc: 0.4869\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67949, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7717 - acc: 0.5086 - val_loss: 0.6499 - val_acc: 0.7410\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67949 to 0.64986, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7112 - acc: 0.5561 - val_loss: 0.6118 - val_acc: 0.7527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 0.64986 to 0.61178, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6612 - acc: 0.6143 - val_loss: 0.5495 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61178 to 0.54950, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5913 - acc: 0.6869 - val_loss: 0.4768 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54950 to 0.47678, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5137 - acc: 0.7495 - val_loss: 0.4226 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47678 to 0.42265, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4613 - acc: 0.7901 - val_loss: 0.3887 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42265 to 0.38870, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4215 - acc: 0.8164 - val_loss: 0.3615 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38870 to 0.36150, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4037 - acc: 0.8308 - val_loss: 0.3441 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36150 to 0.34412, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3868 - acc: 0.8444 - val_loss: 0.3238 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34412 to 0.32381, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3713 - acc: 0.8500 - val_loss: 0.3174 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32381 to 0.31742, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3561 - acc: 0.8578 - val_loss: 0.2996 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31742 to 0.29958, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3419 - acc: 0.8663 - val_loss: 0.2872 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29958 to 0.28725, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3302 - acc: 0.8783 - val_loss: 0.2781 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28725 to 0.27807, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3030 - acc: 0.8860 - val_loss: 0.2751 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27807 to 0.27514, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2964 - acc: 0.8907 - val_loss: 0.2639 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27514 to 0.26393, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2956 - acc: 0.8912 - val_loss: 0.2592 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26393 to 0.25920, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2890 - acc: 0.8931 - val_loss: 0.2527 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25920 to 0.25274, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2763 - acc: 0.9002 - val_loss: 0.2490 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.25274 to 0.24896, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2770 - acc: 0.9033 - val_loss: 0.2431 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24896 to 0.24312, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2711 - acc: 0.9021 - val_loss: 0.2385 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24312 to 0.23852, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2615 - acc: 0.9046 - val_loss: 0.2354 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23852 to 0.23536, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2637 - acc: 0.9050 - val_loss: 0.2387 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.23536\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2610 - acc: 0.9072 - val_loss: 0.2324 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23536 to 0.23241, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2485 - acc: 0.9158 - val_loss: 0.2274 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23241 to 0.22744, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2508 - acc: 0.9133 - val_loss: 0.2246 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22744 to 0.22455, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2463 - acc: 0.9128 - val_loss: 0.2201 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.22455 to 0.22009, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2384 - acc: 0.9182 - val_loss: 0.2162 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22009 to 0.21623, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2393 - acc: 0.9170 - val_loss: 0.2141 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21623 to 0.21411, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2319 - acc: 0.9179 - val_loss: 0.2106 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21411 to 0.21058, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2228 - acc: 0.9206 - val_loss: 0.2074 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21058 to 0.20742, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9250 - val_loss: 0.2019 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20742 to 0.20187, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2296 - acc: 0.9172 - val_loss: 0.2174 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20187\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2278 - acc: 0.9201 - val_loss: 0.1966 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20187 to 0.19661, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2226 - acc: 0.9214 - val_loss: 0.2028 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.19661\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2244 - acc: 0.9252 - val_loss: 0.1900 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19661 to 0.18998, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2093 - acc: 0.9265 - val_loss: 0.1916 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.18998\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2129 - acc: 0.9228 - val_loss: 0.1870 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18998 to 0.18699, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9226 - val_loss: 0.1798 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18699 to 0.17976, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2002 - acc: 0.9321 - val_loss: 0.1767 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17976 to 0.17672, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2012 - acc: 0.9274 - val_loss: 0.1715 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17672 to 0.17155, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1979 - acc: 0.9291 - val_loss: 0.1668 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17155 to 0.16685, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1899 - acc: 0.9306 - val_loss: 0.1707 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16685\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1967 - acc: 0.9284 - val_loss: 0.1617 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16685 to 0.16165, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1846 - acc: 0.9340 - val_loss: 0.1588 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16165 to 0.15878, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1721 - acc: 0.9340 - val_loss: 0.1535 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15878 to 0.15348, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9294 - val_loss: 0.1490 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15348 to 0.14901, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1767 - acc: 0.9323 - val_loss: 0.1474 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14901 to 0.14742, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1688 - acc: 0.9401 - val_loss: 0.1451 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14742 to 0.14511, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1808 - acc: 0.9316 - val_loss: 0.1401 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14511 to 0.14013, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1777 - acc: 0.9369 - val_loss: 0.1425 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.14013\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1649 - acc: 0.9338 - val_loss: 0.1369 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14013 to 0.13693, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1659 - acc: 0.9396 - val_loss: 0.1385 - val_acc: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_loss did not improve from 0.13693\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1545 - acc: 0.9435 - val_loss: 0.1315 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13693 to 0.13152, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1535 - acc: 0.9433 - val_loss: 0.1247 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13152 to 0.12467, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1535 - acc: 0.9438 - val_loss: 0.1235 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12467 to 0.12349, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1625 - acc: 0.9391 - val_loss: 0.1206 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12349 to 0.12055, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9438 - val_loss: 0.1168 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12055 to 0.11682, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1506 - acc: 0.9401 - val_loss: 0.1183 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.11682\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1481 - acc: 0.9455 - val_loss: 0.1120 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11682 to 0.11203, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1412 - acc: 0.9457 - val_loss: 0.1096 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11203 to 0.10958, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1409 - acc: 0.9486 - val_loss: 0.1091 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10958 to 0.10905, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1372 - acc: 0.9477 - val_loss: 0.1057 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10905 to 0.10566, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1266 - acc: 0.9518 - val_loss: 0.1021 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10566 to 0.10210, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1307 - acc: 0.9533 - val_loss: 0.0969 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10210 to 0.09688, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1232 - acc: 0.9550 - val_loss: 0.0980 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.09688\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1260 - acc: 0.9494 - val_loss: 0.0952 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09688 to 0.09515, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1265 - acc: 0.9515 - val_loss: 0.0959 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09515\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9515 - val_loss: 0.0945 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09515 to 0.09453, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9545 - val_loss: 0.0861 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09453 to 0.08606, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1165 - acc: 0.9540 - val_loss: 0.0866 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08606\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9589 - val_loss: 0.0850 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08606 to 0.08496, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1194 - acc: 0.9550 - val_loss: 0.0826 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08496 to 0.08262, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1089 - acc: 0.9586 - val_loss: 0.0818 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08262 to 0.08184, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1150 - acc: 0.9576 - val_loss: 0.0799 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08184 to 0.07989, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1124 - acc: 0.9589 - val_loss: 0.0799 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07989\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1089 - acc: 0.9625 - val_loss: 0.0744 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.07989 to 0.07440, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1085 - acc: 0.9552 - val_loss: 0.0715 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07440 to 0.07148, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1068 - acc: 0.9574 - val_loss: 0.0781 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07148\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1030 - acc: 0.9623 - val_loss: 0.0706 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07148 to 0.07064, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1063 - acc: 0.9615 - val_loss: 0.0681 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07064 to 0.06813, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0937 - acc: 0.9647 - val_loss: 0.0664 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06813 to 0.06639, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0944 - acc: 0.9659 - val_loss: 0.0687 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06639\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9688 - val_loss: 0.0627 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06639 to 0.06269, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0888 - acc: 0.9647 - val_loss: 0.0620 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06269 to 0.06196, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9708 - val_loss: 0.0620 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06196\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0936 - acc: 0.9654 - val_loss: 0.0581 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06196 to 0.05814, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9696 - val_loss: 0.0546 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05814 to 0.05458, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9725 - val_loss: 0.0535 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05458 to 0.05349, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0899 - acc: 0.9623 - val_loss: 0.0552 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05349\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9683 - val_loss: 0.0591 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05349\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9688 - val_loss: 0.0527 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05349 to 0.05268, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9698 - val_loss: 0.0521 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05268 to 0.05212, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0797 - acc: 0.9696 - val_loss: 0.0452 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05212 to 0.04521, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0828 - acc: 0.9679 - val_loss: 0.0492 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04521\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0816 - acc: 0.9720 - val_loss: 0.0456 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04521\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0740 - acc: 0.9737 - val_loss: 0.0454 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04521\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9708 - val_loss: 0.0414 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04521 to 0.04140, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9713 - val_loss: 0.0499 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04140\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9737 - val_loss: 0.0407 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04140 to 0.04070, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9735 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04070 to 0.03968, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9749 - val_loss: 0.0374 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03968 to 0.03736, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0756 - acc: 0.9727 - val_loss: 0.0386 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03736\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9718 - val_loss: 0.0388 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03736\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9759 - val_loss: 0.0405 - val_acc: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03736\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9761 - val_loss: 0.0364 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03736 to 0.03645, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9769 - val_loss: 0.0369 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03645\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9739 - val_loss: 0.0329 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03645 to 0.03287, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9749 - val_loss: 0.0344 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03287\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9759 - val_loss: 0.0371 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03287\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9791 - val_loss: 0.0315 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03287 to 0.03151, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0673 - acc: 0.9759 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03151\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0655 - acc: 0.9764 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03151\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9749 - val_loss: 0.0303 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.03151 to 0.03033, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9759 - val_loss: 0.0293 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03033 to 0.02926, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0657 - acc: 0.9757 - val_loss: 0.0320 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02926\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9820 - val_loss: 0.0270 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02926 to 0.02699, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9769 - val_loss: 0.0248 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02699 to 0.02478, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0632 - acc: 0.9766 - val_loss: 0.0274 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02478\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9803 - val_loss: 0.0272 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02478\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9788 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02478\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9761 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02478 to 0.02310, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9744 - val_loss: 0.0313 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02310\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9793 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02310\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9788 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02310\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9798 - val_loss: 0.0251 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02310\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0529 - acc: 0.9805 - val_loss: 0.0262 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02310\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 0.7566 - acc: 0.5155 - val_loss: 0.6888 - val_acc: 0.4703\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68875, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7361 - acc: 0.5303 - val_loss: 0.6454 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68875 to 0.64535, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6835 - acc: 0.5756 - val_loss: 0.6014 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64535 to 0.60140, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6346 - acc: 0.6418 - val_loss: 0.5380 - val_acc: 0.8023\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60140 to 0.53799, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5621 - acc: 0.7290 - val_loss: 0.4661 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53799 to 0.46613, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5050 - acc: 0.7641 - val_loss: 0.4116 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46613 to 0.41162, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4546 - acc: 0.8040 - val_loss: 0.3758 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41162 to 0.37580, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4275 - acc: 0.8157 - val_loss: 0.3536 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37580 to 0.35362, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4033 - acc: 0.8356 - val_loss: 0.3294 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35362 to 0.32936, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3907 - acc: 0.8483 - val_loss: 0.3126 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32936 to 0.31264, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3628 - acc: 0.8554 - val_loss: 0.2988 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31264 to 0.29885, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3557 - acc: 0.8636 - val_loss: 0.2804 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29885 to 0.28038, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3338 - acc: 0.8710 - val_loss: 0.2681 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28038 to 0.26811, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3284 - acc: 0.8768 - val_loss: 0.2606 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26811 to 0.26060, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3262 - acc: 0.8778 - val_loss: 0.2517 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26060 to 0.25167, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3064 - acc: 0.8856 - val_loss: 0.2430 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25167 to 0.24301, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2965 - acc: 0.8972 - val_loss: 0.2379 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24301 to 0.23792, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2913 - acc: 0.8955 - val_loss: 0.2309 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23792 to 0.23087, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2845 - acc: 0.9016 - val_loss: 0.2263 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23087 to 0.22633, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2805 - acc: 0.9019 - val_loss: 0.2226 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22633 to 0.22262, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2699 - acc: 0.9048 - val_loss: 0.2203 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22262 to 0.22028, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2721 - acc: 0.9038 - val_loss: 0.2178 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22028 to 0.21776, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2639 - acc: 0.9087 - val_loss: 0.2206 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.21776\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2666 - acc: 0.9082 - val_loss: 0.2143 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21776 to 0.21426, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2596 - acc: 0.9072 - val_loss: 0.2082 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21426 to 0.20823, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2507 - acc: 0.9145 - val_loss: 0.2060 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20823 to 0.20604, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2479 - acc: 0.9148 - val_loss: 0.2054 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20604 to 0.20535, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2450 - acc: 0.9140 - val_loss: 0.2016 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20535 to 0.20159, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2418 - acc: 0.9192 - val_loss: 0.2050 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20159\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2421 - acc: 0.9206 - val_loss: 0.2008 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20159 to 0.20085, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2369 - acc: 0.9175 - val_loss: 0.1956 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20085 to 0.19561, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2311 - acc: 0.9221 - val_loss: 0.1942 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19561 to 0.19417, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2324 - acc: 0.9250 - val_loss: 0.1932 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19417 to 0.19321, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2268 - acc: 0.9245 - val_loss: 0.1909 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19321 to 0.19090, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2205 - acc: 0.9279 - val_loss: 0.1893 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19090 to 0.18935, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2262 - acc: 0.9177 - val_loss: 0.1879 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18935 to 0.18787, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2208 - acc: 0.9240 - val_loss: 0.1860 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18787 to 0.18597, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2228 - acc: 0.9238 - val_loss: 0.1826 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18597 to 0.18257, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2077 - acc: 0.9284 - val_loss: 0.1816 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18257 to 0.18160, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2165 - acc: 0.9233 - val_loss: 0.1786 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18160 to 0.17864, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2094 - acc: 0.9306 - val_loss: 0.1763 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17864 to 0.17630, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2014 - acc: 0.9306 - val_loss: 0.1767 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.17630\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9260 - val_loss: 0.1729 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17630 to 0.17294, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1999 - acc: 0.9306 - val_loss: 0.1729 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17294 to 0.17290, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1925 - acc: 0.9328 - val_loss: 0.1722 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17290 to 0.17223, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1976 - acc: 0.9323 - val_loss: 0.1663 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17223 to 0.16629, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1972 - acc: 0.9321 - val_loss: 0.1645 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16629 to 0.16449, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9357 - val_loss: 0.1628 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.16449 to 0.16281, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1860 - acc: 0.9338 - val_loss: 0.1603 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.16281 to 0.16032, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1870 - acc: 0.9308 - val_loss: 0.1573 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.16032 to 0.15729, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1865 - acc: 0.9355 - val_loss: 0.1571 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.15729 to 0.15711, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1849 - acc: 0.9362 - val_loss: 0.1543 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15711 to 0.15429, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1845 - acc: 0.9343 - val_loss: 0.1519 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.15429 to 0.15194, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1814 - acc: 0.9347 - val_loss: 0.1502 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.15194 to 0.15023, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1708 - acc: 0.9418 - val_loss: 0.1473 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.15023 to 0.14729, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1622 - acc: 0.9445 - val_loss: 0.1450 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.14729 to 0.14498, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1642 - acc: 0.9386 - val_loss: 0.1421 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.14498 to 0.14209, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1666 - acc: 0.9411 - val_loss: 0.1406 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.14209 to 0.14064, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1631 - acc: 0.9425 - val_loss: 0.1367 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.14064 to 0.13672, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1645 - acc: 0.9386 - val_loss: 0.1379 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.13672\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1642 - acc: 0.9369 - val_loss: 0.1330 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13672 to 0.13299, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1619 - acc: 0.9379 - val_loss: 0.1297 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.13299 to 0.12971, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9481 - val_loss: 0.1266 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12971 to 0.12658, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1553 - acc: 0.9447 - val_loss: 0.1246 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.12658 to 0.12456, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1596 - acc: 0.9416 - val_loss: 0.1231 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.12456 to 0.12312, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1451 - acc: 0.9511 - val_loss: 0.1209 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.12312 to 0.12087, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1469 - acc: 0.9501 - val_loss: 0.1183 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.12087 to 0.11834, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9491 - val_loss: 0.1148 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.11834 to 0.11483, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1421 - acc: 0.9501 - val_loss: 0.1150 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.11483\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1394 - acc: 0.9479 - val_loss: 0.1087 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.11483 to 0.10866, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1396 - acc: 0.9523 - val_loss: 0.1069 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.10866 to 0.10687, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1400 - acc: 0.9457 - val_loss: 0.1051 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.10687 to 0.10510, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1415 - acc: 0.9477 - val_loss: 0.1016 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.10510 to 0.10161, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9557 - val_loss: 0.0982 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.10161 to 0.09824, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9540 - val_loss: 0.0965 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.09824 to 0.09645, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1239 - acc: 0.9559 - val_loss: 0.0911 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.09645 to 0.09111, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9562 - val_loss: 0.0915 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.09111\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1207 - acc: 0.9542 - val_loss: 0.0846 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.09111 to 0.08461, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1197 - acc: 0.9552 - val_loss: 0.0868 - val_acc: 0.9698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08461\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1185 - acc: 0.9564 - val_loss: 0.0772 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.08461 to 0.07720, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1114 - acc: 0.9601 - val_loss: 0.0746 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07720 to 0.07458, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9569 - val_loss: 0.0721 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07458 to 0.07206, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1142 - acc: 0.9581 - val_loss: 0.0685 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07206 to 0.06845, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1072 - acc: 0.9554 - val_loss: 0.0699 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06845\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9593 - val_loss: 0.0659 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06845 to 0.06588, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1052 - acc: 0.9603 - val_loss: 0.0637 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06588 to 0.06374, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1015 - acc: 0.9610 - val_loss: 0.0630 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06374 to 0.06303, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0986 - acc: 0.9596 - val_loss: 0.0574 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06303 to 0.05738, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1046 - acc: 0.9618 - val_loss: 0.0584 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05738\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1084 - acc: 0.9596 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05738 to 0.05594, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0932 - acc: 0.9652 - val_loss: 0.0558 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05594 to 0.05583, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0977 - acc: 0.9637 - val_loss: 0.0542 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05583 to 0.05422, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0977 - acc: 0.9623 - val_loss: 0.0515 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05422 to 0.05155, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0895 - acc: 0.9657 - val_loss: 0.0490 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05155 to 0.04902, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9642 - val_loss: 0.0465 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04902 to 0.04651, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0898 - acc: 0.9674 - val_loss: 0.0448 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04651 to 0.04483, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9618 - val_loss: 0.0460 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04483\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9642 - val_loss: 0.0440 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04483 to 0.04404, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9664 - val_loss: 0.0423 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04404 to 0.04227, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0844 - acc: 0.9686 - val_loss: 0.0404 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04227 to 0.04041, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0835 - acc: 0.9688 - val_loss: 0.0397 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04041 to 0.03970, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0815 - acc: 0.9674 - val_loss: 0.0394 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03970 to 0.03938, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9642 - val_loss: 0.0380 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03938 to 0.03805, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0783 - acc: 0.9679 - val_loss: 0.0365 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03805 to 0.03648, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9737 - val_loss: 0.0344 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03648 to 0.03442, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9727 - val_loss: 0.0324 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03442 to 0.03239, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9747 - val_loss: 0.0317 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03239 to 0.03169, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03169\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0761 - acc: 0.9691 - val_loss: 0.0306 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03169 to 0.03064, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9771 - val_loss: 0.0285 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03064 to 0.02854, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0777 - acc: 0.9676 - val_loss: 0.0305 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02854\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0728 - acc: 0.9683 - val_loss: 0.0277 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02854 to 0.02766, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0683 - acc: 0.9764 - val_loss: 0.0264 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02766 to 0.02640, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9754 - val_loss: 0.0291 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02640\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9742 - val_loss: 0.0250 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02640 to 0.02503, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9749 - val_loss: 0.0248 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02503 to 0.02481, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9744 - val_loss: 0.0229 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02481 to 0.02292, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9781 - val_loss: 0.0220 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02292 to 0.02197, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0630 - acc: 0.9725 - val_loss: 0.0218 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02197 to 0.02185, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9783 - val_loss: 0.0230 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02185\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9788 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02185 to 0.01919, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9781 - val_loss: 0.0184 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01919 to 0.01836, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0612 - acc: 0.9735 - val_loss: 0.0215 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01836\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0585 - acc: 0.9769 - val_loss: 0.0180 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01836 to 0.01797, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9786 - val_loss: 0.0200 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01797\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0585 - acc: 0.9759 - val_loss: 0.0198 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01797\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0579 - acc: 0.9788 - val_loss: 0.0192 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01797\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9769 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01797\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9793 - val_loss: 0.0170 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01797 to 0.01697, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9766 - val_loss: 0.0185 - val_acc: 0.9912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01697\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9764 - val_loss: 0.0169 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01697 to 0.01686, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9813 - val_loss: 0.0186 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01686\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9810 - val_loss: 0.0151 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01686 to 0.01513, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9788 - val_loss: 0.0154 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01513\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9803 - val_loss: 0.0138 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01513 to 0.01382, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9781 - val_loss: 0.0180 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01382\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0514 - acc: 0.9803 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01382 to 0.01352, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9803 - val_loss: 0.0131 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01352 to 0.01305, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9803 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01305 to 0.01253, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9791 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01253\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9810 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01253\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9810 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01253\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9805 - val_loss: 0.0143 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01253\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9805 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01253\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 0.8086 - acc: 0.5198 - val_loss: 0.6914 - val_acc: 0.4888\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69144, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7671 - acc: 0.5089 - val_loss: 0.6468 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69144 to 0.64678, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7029 - acc: 0.5600 - val_loss: 0.5973 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64678 to 0.59729, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6419 - acc: 0.6299 - val_loss: 0.5264 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59729 to 0.52636, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5753 - acc: 0.7047 - val_loss: 0.4590 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52636 to 0.45899, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5153 - acc: 0.7653 - val_loss: 0.4036 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45899 to 0.40358, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4730 - acc: 0.7940 - val_loss: 0.3686 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40358 to 0.36856, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4426 - acc: 0.8059 - val_loss: 0.3431 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36856 to 0.34306, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4137 - acc: 0.8300 - val_loss: 0.3264 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34306 to 0.32642, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.4005 - acc: 0.8325 - val_loss: 0.3076 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32642 to 0.30765, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3822 - acc: 0.8507 - val_loss: 0.2913 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30765 to 0.29127, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3643 - acc: 0.8554 - val_loss: 0.2773 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29127 to 0.27725, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3565 - acc: 0.8571 - val_loss: 0.2654 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27725 to 0.26541, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3277 - acc: 0.8734 - val_loss: 0.2548 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26541 to 0.25478, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3290 - acc: 0.8680 - val_loss: 0.2480 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25478 to 0.24799, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3140 - acc: 0.8753 - val_loss: 0.2374 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24799 to 0.23742, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3015 - acc: 0.8831 - val_loss: 0.2329 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23742 to 0.23285, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3049 - acc: 0.8814 - val_loss: 0.2313 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23285 to 0.23133, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2871 - acc: 0.8943 - val_loss: 0.2221 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23133 to 0.22215, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2923 - acc: 0.8853 - val_loss: 0.2211 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22215 to 0.22106, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2778 - acc: 0.8968 - val_loss: 0.2103 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22106 to 0.21032, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2739 - acc: 0.8977 - val_loss: 0.2063 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21032 to 0.20632, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2641 - acc: 0.8980 - val_loss: 0.2022 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20632 to 0.20221, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2646 - acc: 0.9011 - val_loss: 0.1965 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20221 to 0.19649, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2596 - acc: 0.9038 - val_loss: 0.1935 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19649 to 0.19345, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2574 - acc: 0.9028 - val_loss: 0.1903 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19345 to 0.19030, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2474 - acc: 0.9084 - val_loss: 0.1856 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19030 to 0.18562, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2446 - acc: 0.9087 - val_loss: 0.1825 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18562 to 0.18252, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2563 - acc: 0.9021 - val_loss: 0.1780 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.18252 to 0.17803, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2457 - acc: 0.9092 - val_loss: 0.1781 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17803\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2381 - acc: 0.9109 - val_loss: 0.1756 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17803 to 0.17560, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2311 - acc: 0.9111 - val_loss: 0.1698 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17560 to 0.16984, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2263 - acc: 0.9170 - val_loss: 0.1684 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16984 to 0.16836, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2200 - acc: 0.9206 - val_loss: 0.1695 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16836\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2213 - acc: 0.9177 - val_loss: 0.1634 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16836 to 0.16337, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2163 - acc: 0.9189 - val_loss: 0.1627 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16337 to 0.16271, saving model to best.model\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2162 - acc: 0.9209 - val_loss: 0.1572 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16271 to 0.15719, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2204 - acc: 0.9223 - val_loss: 0.1585 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15719\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9252 - val_loss: 0.1507 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15719 to 0.15074, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2000 - acc: 0.9284 - val_loss: 0.1482 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15074 to 0.14819, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2039 - acc: 0.9233 - val_loss: 0.1495 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.14819\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1949 - acc: 0.9257 - val_loss: 0.1427 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14819 to 0.14273, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1964 - acc: 0.9267 - val_loss: 0.1416 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14273 to 0.14159, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2032 - acc: 0.9231 - val_loss: 0.1383 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14159 to 0.13825, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1833 - acc: 0.9333 - val_loss: 0.1345 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13825 to 0.13446, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1815 - acc: 0.9345 - val_loss: 0.1341 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13446 to 0.13408, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1890 - acc: 0.9289 - val_loss: 0.1304 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13408 to 0.13042, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1830 - acc: 0.9335 - val_loss: 0.1298 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13042 to 0.12975, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1740 - acc: 0.9360 - val_loss: 0.1237 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12975 to 0.12366, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1738 - acc: 0.9352 - val_loss: 0.1194 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12366 to 0.11936, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1677 - acc: 0.9384 - val_loss: 0.1175 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11936 to 0.11751, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1654 - acc: 0.9379 - val_loss: 0.1123 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11751 to 0.11227, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1647 - acc: 0.9396 - val_loss: 0.1107 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11227 to 0.11072, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1607 - acc: 0.9389 - val_loss: 0.1078 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11072 to 0.10780, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1544 - acc: 0.9452 - val_loss: 0.1038 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10780 to 0.10377, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1512 - acc: 0.9442 - val_loss: 0.1071 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10377\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1516 - acc: 0.9428 - val_loss: 0.0983 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10377 to 0.09827, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9450 - val_loss: 0.0952 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09827 to 0.09523, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1437 - acc: 0.9459 - val_loss: 0.0875 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09523 to 0.08752, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1430 - acc: 0.9479 - val_loss: 0.0911 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08752\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1429 - acc: 0.9474 - val_loss: 0.0816 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08752 to 0.08163, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1300 - acc: 0.9530 - val_loss: 0.0788 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08163 to 0.07883, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9528 - val_loss: 0.0750 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.07883 to 0.07497, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9501 - val_loss: 0.0721 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07497 to 0.07206, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1241 - acc: 0.9579 - val_loss: 0.0684 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07206 to 0.06836, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1231 - acc: 0.9530 - val_loss: 0.0639 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06836 to 0.06395, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1253 - acc: 0.9537 - val_loss: 0.0654 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06395\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1177 - acc: 0.9571 - val_loss: 0.0641 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06395\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1183 - acc: 0.9571 - val_loss: 0.0573 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06395 to 0.05728, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1093 - acc: 0.9552 - val_loss: 0.0537 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.05728 to 0.05370, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1032 - acc: 0.9620 - val_loss: 0.0542 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05370\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9610 - val_loss: 0.0519 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05370 to 0.05191, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1020 - acc: 0.9606 - val_loss: 0.0502 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05191 to 0.05015, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0976 - acc: 0.9623 - val_loss: 0.0462 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05015 to 0.04625, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1089 - acc: 0.9562 - val_loss: 0.0446 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.04625 to 0.04464, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0971 - acc: 0.9647 - val_loss: 0.0456 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04464\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1042 - acc: 0.9601 - val_loss: 0.0482 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04464\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0969 - acc: 0.9645 - val_loss: 0.0432 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04464 to 0.04319, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0953 - acc: 0.9632 - val_loss: 0.0439 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04319\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0842 - acc: 0.9647 - val_loss: 0.0400 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04319 to 0.04000, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9698 - val_loss: 0.0385 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04000 to 0.03850, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9674 - val_loss: 0.0368 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.03850 to 0.03681, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9681 - val_loss: 0.0364 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03681 to 0.03636, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9674 - val_loss: 0.0333 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.03636 to 0.03331, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9671 - val_loss: 0.0353 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03331\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0869 - acc: 0.9635 - val_loss: 0.0303 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03331 to 0.03033, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9681 - val_loss: 0.0346 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03033\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0856 - acc: 0.9654 - val_loss: 0.0305 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03033\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0768 - acc: 0.9713 - val_loss: 0.0288 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03033 to 0.02878, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9705 - val_loss: 0.0273 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.02878 to 0.02733, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0804 - acc: 0.9679 - val_loss: 0.0310 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02733\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9703 - val_loss: 0.0283 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02733\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9703 - val_loss: 0.0266 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.02733 to 0.02661, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9742 - val_loss: 0.0240 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.02661 to 0.02398, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0665 - acc: 0.9759 - val_loss: 0.0266 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02398\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0780 - acc: 0.9681 - val_loss: 0.0305 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02398\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0785 - acc: 0.9713 - val_loss: 0.0221 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02398 to 0.02208, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9715 - val_loss: 0.0213 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02208 to 0.02130, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9747 - val_loss: 0.0235 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02130\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9744 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02130 to 0.02061, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9744 - val_loss: 0.0205 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.02061 to 0.02046, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9786 - val_loss: 0.0210 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02046\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9749 - val_loss: 0.0196 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02046 to 0.01965, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9725 - val_loss: 0.0184 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.01965 to 0.01838, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9759 - val_loss: 0.0180 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.01838 to 0.01796, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0664 - acc: 0.9742 - val_loss: 0.0214 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.01796\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9774 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.01796 to 0.01689, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9813 - val_loss: 0.0150 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.01689 to 0.01497, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0586 - acc: 0.9788 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.01497\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9791 - val_loss: 0.0188 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.01497\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9803 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.01497 to 0.01464, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9771 - val_loss: 0.0187 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01464\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0580 - acc: 0.9771 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01464\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0551 - acc: 0.9813 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01464 to 0.01256, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9788 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01256\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9798 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.01256\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0610 - acc: 0.9752 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01256 to 0.01126, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9774 - val_loss: 0.0115 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01126\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0612 - acc: 0.9771 - val_loss: 0.0208 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01126\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9813 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01126\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9825 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01126\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9805 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01126\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 14s - loss: 0.7916 - acc: 0.5108 - val_loss: 0.6826 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68255, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7491 - acc: 0.5325 - val_loss: 0.6387 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68255 to 0.63873, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6969 - acc: 0.5661 - val_loss: 0.5986 - val_acc: 0.7410\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63873 to 0.59864, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6314 - acc: 0.6430 - val_loss: 0.5273 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59864 to 0.52731, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5633 - acc: 0.7205 - val_loss: 0.4421 - val_acc: 0.8238\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52731 to 0.44213, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4897 - acc: 0.7823 - val_loss: 0.3866 - val_acc: 0.8462\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44213 to 0.38658, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4465 - acc: 0.8067 - val_loss: 0.3617 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38658 to 0.36168, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4299 - acc: 0.8213 - val_loss: 0.3332 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36168 to 0.33319, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3996 - acc: 0.8425 - val_loss: 0.3044 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33319 to 0.30439, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3799 - acc: 0.8471 - val_loss: 0.2982 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30439 to 0.29821, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3623 - acc: 0.8571 - val_loss: 0.2794 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29821 to 0.27942, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3550 - acc: 0.8615 - val_loss: 0.2756 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27942 to 0.27559, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3412 - acc: 0.8627 - val_loss: 0.2611 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27559 to 0.26115, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3259 - acc: 0.8729 - val_loss: 0.2564 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26115 to 0.25643, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3201 - acc: 0.8748 - val_loss: 0.2429 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25643 to 0.24290, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3059 - acc: 0.8807 - val_loss: 0.2360 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24290 to 0.23596, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2968 - acc: 0.8836 - val_loss: 0.2360 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23596\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2877 - acc: 0.8907 - val_loss: 0.2298 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23596 to 0.22982, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2894 - acc: 0.8892 - val_loss: 0.2215 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22982 to 0.22146, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2827 - acc: 0.8885 - val_loss: 0.2197 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22146 to 0.21967, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2705 - acc: 0.8948 - val_loss: 0.2210 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.21967\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2646 - acc: 0.8994 - val_loss: 0.2090 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21967 to 0.20905, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2560 - acc: 0.9041 - val_loss: 0.2104 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20905\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2556 - acc: 0.9014 - val_loss: 0.2083 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20905 to 0.20825, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2558 - acc: 0.9014 - val_loss: 0.1966 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20825 to 0.19662, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2499 - acc: 0.9063 - val_loss: 0.1950 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19662 to 0.19495, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2389 - acc: 0.9104 - val_loss: 0.1885 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19495 to 0.18855, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2349 - acc: 0.9084 - val_loss: 0.1847 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18855 to 0.18466, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2442 - acc: 0.9063 - val_loss: 0.2003 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.18466\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2313 - acc: 0.9114 - val_loss: 0.1804 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18466 to 0.18044, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2245 - acc: 0.9133 - val_loss: 0.1785 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.18044 to 0.17854, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2254 - acc: 0.9133 - val_loss: 0.1751 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17854 to 0.17506, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2248 - acc: 0.9128 - val_loss: 0.1755 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.17506\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2193 - acc: 0.9123 - val_loss: 0.1644 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17506 to 0.16437, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2093 - acc: 0.9233 - val_loss: 0.1604 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16437 to 0.16036, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2066 - acc: 0.9201 - val_loss: 0.1563 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16036 to 0.15627, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2107 - acc: 0.9226 - val_loss: 0.1522 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15627 to 0.15216, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2080 - acc: 0.9196 - val_loss: 0.1488 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15216 to 0.14881, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1944 - acc: 0.9289 - val_loss: 0.1456 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14881 to 0.14555, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1950 - acc: 0.9243 - val_loss: 0.1424 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14555 to 0.14238, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1973 - acc: 0.9265 - val_loss: 0.1400 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14238 to 0.14003, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1872 - acc: 0.9260 - val_loss: 0.1373 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14003 to 0.13726, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1852 - acc: 0.9301 - val_loss: 0.1319 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13726 to 0.13189, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1787 - acc: 0.9311 - val_loss: 0.1317 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13189 to 0.13172, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1741 - acc: 0.9306 - val_loss: 0.1311 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13172 to 0.13113, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1773 - acc: 0.9311 - val_loss: 0.1247 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13113 to 0.12466, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1780 - acc: 0.9291 - val_loss: 0.1228 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12466 to 0.12275, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1717 - acc: 0.9316 - val_loss: 0.1195 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12275 to 0.11949, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9384 - val_loss: 0.1180 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11949 to 0.11798, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1643 - acc: 0.9335 - val_loss: 0.1143 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11798 to 0.11433, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1591 - acc: 0.9377 - val_loss: 0.1092 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11433 to 0.10925, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1588 - acc: 0.9394 - val_loss: 0.1060 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10925 to 0.10598, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1523 - acc: 0.9418 - val_loss: 0.1027 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10598 to 0.10267, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9416 - val_loss: 0.1021 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10267 to 0.10206, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1505 - acc: 0.9411 - val_loss: 0.1005 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10206 to 0.10046, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1466 - acc: 0.9457 - val_loss: 0.0969 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10046 to 0.09694, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1339 - acc: 0.9464 - val_loss: 0.0930 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09694 to 0.09298, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1328 - acc: 0.9477 - val_loss: 0.0904 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09298 to 0.09035, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9411 - val_loss: 0.0885 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09035 to 0.08851, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1398 - acc: 0.9452 - val_loss: 0.0855 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08851 to 0.08548, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9477 - val_loss: 0.0846 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08548 to 0.08459, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1298 - acc: 0.9508 - val_loss: 0.0821 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08459 to 0.08209, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1302 - acc: 0.9501 - val_loss: 0.0826 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08209\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1330 - acc: 0.9496 - val_loss: 0.0757 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08209 to 0.07568, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1230 - acc: 0.9506 - val_loss: 0.0730 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07568 to 0.07300, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1164 - acc: 0.9574 - val_loss: 0.0729 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07300 to 0.07287, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1130 - acc: 0.9552 - val_loss: 0.0683 - val_acc: 0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_loss improved from 0.07287 to 0.06829, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1122 - acc: 0.9569 - val_loss: 0.0677 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06829 to 0.06771, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1130 - acc: 0.9542 - val_loss: 0.0649 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06771 to 0.06490, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9618 - val_loss: 0.0625 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06490 to 0.06248, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1077 - acc: 0.9598 - val_loss: 0.0613 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06248 to 0.06133, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1036 - acc: 0.9596 - val_loss: 0.0597 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06133 to 0.05973, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1096 - acc: 0.9610 - val_loss: 0.0600 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05973\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1013 - acc: 0.9632 - val_loss: 0.0567 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05973 to 0.05673, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1018 - acc: 0.9591 - val_loss: 0.0554 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05673 to 0.05540, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1036 - acc: 0.9625 - val_loss: 0.0555 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05540\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0996 - acc: 0.9596 - val_loss: 0.0523 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05540 to 0.05227, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0866 - acc: 0.9691 - val_loss: 0.0501 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05227 to 0.05012, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0911 - acc: 0.9664 - val_loss: 0.0497 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05012 to 0.04971, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9632 - val_loss: 0.0480 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04971 to 0.04804, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9688 - val_loss: 0.0447 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04804 to 0.04471, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9669 - val_loss: 0.0445 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04471 to 0.04449, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0859 - acc: 0.9671 - val_loss: 0.0433 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04449 to 0.04329, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9640 - val_loss: 0.0485 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04329\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9654 - val_loss: 0.0430 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04329 to 0.04303, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0835 - acc: 0.9674 - val_loss: 0.0411 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04303 to 0.04109, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9627 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04109 to 0.04071, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0803 - acc: 0.9674 - val_loss: 0.0410 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04071\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0885 - acc: 0.9674 - val_loss: 0.0394 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04071 to 0.03937, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9691 - val_loss: 0.0390 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03937 to 0.03903, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9730 - val_loss: 0.0387 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03903 to 0.03866, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0787 - acc: 0.9713 - val_loss: 0.0385 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03866 to 0.03852, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9742 - val_loss: 0.0364 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03852 to 0.03644, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0783 - acc: 0.9691 - val_loss: 0.0363 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03644 to 0.03629, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9718 - val_loss: 0.0352 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03629 to 0.03523, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0718 - acc: 0.9722 - val_loss: 0.0335 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03523 to 0.03348, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9744 - val_loss: 0.0333 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03348 to 0.03333, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9771 - val_loss: 0.0321 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03333 to 0.03214, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9754 - val_loss: 0.0309 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03214 to 0.03093, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9737 - val_loss: 0.0301 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03093 to 0.03015, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9752 - val_loss: 0.0315 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03015\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9742 - val_loss: 0.0293 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03015 to 0.02930, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9747 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02930 to 0.02904, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9774 - val_loss: 0.0316 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02904\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9720 - val_loss: 0.0303 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02904\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0628 - acc: 0.9754 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02904\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9781 - val_loss: 0.0269 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02904 to 0.02694, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0634 - acc: 0.9793 - val_loss: 0.0270 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02694\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9739 - val_loss: 0.0268 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02694 to 0.02679, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0615 - acc: 0.9766 - val_loss: 0.0296 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02679\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9747 - val_loss: 0.0244 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02679 to 0.02438, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9791 - val_loss: 0.0268 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02438\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9759 - val_loss: 0.0238 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02438 to 0.02379, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9769 - val_loss: 0.0238 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02379 to 0.02378, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9810 - val_loss: 0.0239 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02378\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9754 - val_loss: 0.0238 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02378\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9822 - val_loss: 0.0250 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02378\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0551 - acc: 0.9805 - val_loss: 0.0228 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02378 to 0.02282, saving model to best.model\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0590 - acc: 0.9783 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02282\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9798 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02282\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9798 - val_loss: 0.0227 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02282 to 0.02269, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9783 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02269\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9827 - val_loss: 0.0221 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.02269 to 0.02207, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0500 - acc: 0.9832 - val_loss: 0.0202 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.02207 to 0.02025, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9803 - val_loss: 0.0232 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02025\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9810 - val_loss: 0.0206 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02025\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0444 - acc: 0.9832 - val_loss: 0.0205 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02025\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9817 - val_loss: 0.0208 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02025\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9839 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.02025 to 0.01992, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0466 - acc: 0.9827 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01992\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9820 - val_loss: 0.0181 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01992 to 0.01806, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9810 - val_loss: 0.0175 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01806 to 0.01749, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9781 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01749\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0479 - acc: 0.9820 - val_loss: 0.0182 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01749\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9839 - val_loss: 0.0194 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01749\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9793 - val_loss: 0.0185 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01749\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9825 - val_loss: 0.0175 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01749 to 0.01748, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9834 - val_loss: 0.0215 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01748\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9800 - val_loss: 0.0178 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01748\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0490 - acc: 0.9793 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01748\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0424 - acc: 0.9856 - val_loss: 0.0160 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01748 to 0.01595, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0477 - acc: 0.9825 - val_loss: 0.0200 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01595\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9808 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01595\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9844 - val_loss: 0.0168 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01595\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9847 - val_loss: 0.0158 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.01595 to 0.01581, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9866 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01581\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9854 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01581\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9842 - val_loss: 0.0161 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01581\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0399 - acc: 0.9832 - val_loss: 0.0154 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.01581 to 0.01545, saving model to best.model\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0414 - acc: 0.9839 - val_loss: 0.0157 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01545\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9849 - val_loss: 0.0158 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01545\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9847 - val_loss: 0.0170 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01545\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0398 - acc: 0.9837 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01545 to 0.01393, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9861 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01393\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9847 - val_loss: 0.0151 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01393\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9849 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01393\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0350 - acc: 0.9859 - val_loss: 0.0140 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01393\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9839 - val_loss: 0.0135 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.01393 to 0.01351, saving model to best.model\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9876 - val_loss: 0.0143 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01351\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9859 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01351\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0124 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.01351 to 0.01241, saving model to best.model\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9866 - val_loss: 0.0164 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01241\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01241\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0335 - acc: 0.9871 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01241\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0350 - acc: 0.9878 - val_loss: 0.0137 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01241\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0335 - acc: 0.9878 - val_loss: 0.0135 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01241\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 14s - loss: 0.8154 - acc: 0.5052 - val_loss: 0.6763 - val_acc: 0.6972\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67626, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7399 - acc: 0.5310 - val_loss: 0.6528 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67626 to 0.65275, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6993 - acc: 0.5715 - val_loss: 0.6130 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65275 to 0.61301, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6414 - acc: 0.6360 - val_loss: 0.5477 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61301 to 0.54772, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5579 - acc: 0.7173 - val_loss: 0.4750 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54772 to 0.47499, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4859 - acc: 0.7782 - val_loss: 0.4215 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47499 to 0.42153, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4474 - acc: 0.8128 - val_loss: 0.3947 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42153 to 0.39468, saving model to best.model\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4078 - acc: 0.8335 - val_loss: 0.3669 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39468 to 0.36692, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3822 - acc: 0.8437 - val_loss: 0.3461 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36692 to 0.34607, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3668 - acc: 0.8500 - val_loss: 0.3338 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34607 to 0.33375, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3577 - acc: 0.8546 - val_loss: 0.3199 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33375 to 0.31988, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3453 - acc: 0.8654 - val_loss: 0.3054 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31988 to 0.30539, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3279 - acc: 0.8787 - val_loss: 0.2957 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.30539 to 0.29567, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3136 - acc: 0.8831 - val_loss: 0.2892 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.29567 to 0.28924, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3014 - acc: 0.8904 - val_loss: 0.2726 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.28924 to 0.27260, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2991 - acc: 0.8865 - val_loss: 0.2654 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27260 to 0.26537, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2868 - acc: 0.8916 - val_loss: 0.2679 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26537\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2826 - acc: 0.8965 - val_loss: 0.2592 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.26537 to 0.25917, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2681 - acc: 0.9028 - val_loss: 0.2512 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.25917 to 0.25118, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2775 - acc: 0.9019 - val_loss: 0.2440 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.25118 to 0.24401, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2665 - acc: 0.9009 - val_loss: 0.2585 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24401\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2608 - acc: 0.9058 - val_loss: 0.2359 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24401 to 0.23587, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2542 - acc: 0.9053 - val_loss: 0.2357 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23587 to 0.23572, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2463 - acc: 0.9084 - val_loss: 0.2374 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.23572\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2463 - acc: 0.9089 - val_loss: 0.2352 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23572 to 0.23522, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2443 - acc: 0.9131 - val_loss: 0.2214 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23522 to 0.22144, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2366 - acc: 0.9162 - val_loss: 0.2280 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22144\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2302 - acc: 0.9175 - val_loss: 0.2123 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22144 to 0.21231, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2262 - acc: 0.9206 - val_loss: 0.2142 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.21231\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2265 - acc: 0.9165 - val_loss: 0.2114 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21231 to 0.21144, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2199 - acc: 0.9187 - val_loss: 0.2031 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21144 to 0.20312, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2229 - acc: 0.9221 - val_loss: 0.2135 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20312\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2227 - acc: 0.9170 - val_loss: 0.1958 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20312 to 0.19583, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2194 - acc: 0.9218 - val_loss: 0.1982 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.19583\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2093 - acc: 0.9211 - val_loss: 0.1923 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19583 to 0.19228, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2020 - acc: 0.9250 - val_loss: 0.1891 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19228 to 0.18905, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1994 - acc: 0.9257 - val_loss: 0.1889 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18905 to 0.18886, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2015 - acc: 0.9238 - val_loss: 0.1849 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18886 to 0.18486, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2062 - acc: 0.9265 - val_loss: 0.1813 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18486 to 0.18127, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1916 - acc: 0.9301 - val_loss: 0.1743 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18127 to 0.17426, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9277 - val_loss: 0.1821 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.17426\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1869 - acc: 0.9321 - val_loss: 0.1680 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17426 to 0.16798, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1949 - acc: 0.9299 - val_loss: 0.1748 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16798\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1807 - acc: 0.9352 - val_loss: 0.1661 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16798 to 0.16615, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1822 - acc: 0.9338 - val_loss: 0.1659 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16615 to 0.16588, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1740 - acc: 0.9318 - val_loss: 0.1588 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.16588 to 0.15875, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1682 - acc: 0.9394 - val_loss: 0.1570 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15875 to 0.15697, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1706 - acc: 0.9428 - val_loss: 0.1534 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15697 to 0.15338, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1624 - acc: 0.9389 - val_loss: 0.1438 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15338 to 0.14381, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1622 - acc: 0.9379 - val_loss: 0.1435 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14381 to 0.14352, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9413 - val_loss: 0.1503 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.14352\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1587 - acc: 0.9435 - val_loss: 0.1439 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.14352\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1543 - acc: 0.9445 - val_loss: 0.1282 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14352 to 0.12825, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1589 - acc: 0.9411 - val_loss: 0.1360 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.12825\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1539 - acc: 0.9406 - val_loss: 0.1200 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12825 to 0.11998, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1498 - acc: 0.9418 - val_loss: 0.1148 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.11998 to 0.11478, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1471 - acc: 0.9474 - val_loss: 0.1157 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11478\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1437 - acc: 0.9469 - val_loss: 0.1148 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.11478\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1361 - acc: 0.9494 - val_loss: 0.1084 - val_acc: 0.9591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_loss improved from 0.11478 to 0.10839, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9496 - val_loss: 0.1022 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10839 to 0.10222, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1319 - acc: 0.9513 - val_loss: 0.1033 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10222\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1291 - acc: 0.9501 - val_loss: 0.0980 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10222 to 0.09801, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1263 - acc: 0.9567 - val_loss: 0.0910 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09801 to 0.09096, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1208 - acc: 0.9557 - val_loss: 0.0895 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09096 to 0.08953, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1197 - acc: 0.9552 - val_loss: 0.0920 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08953\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1224 - acc: 0.9564 - val_loss: 0.0846 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08953 to 0.08460, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1235 - acc: 0.9537 - val_loss: 0.0856 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08460\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1122 - acc: 0.9593 - val_loss: 0.0785 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08460 to 0.07851, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1130 - acc: 0.9559 - val_loss: 0.0788 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07851\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1134 - acc: 0.9601 - val_loss: 0.0727 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07851 to 0.07267, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1061 - acc: 0.9603 - val_loss: 0.0701 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07267 to 0.07012, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1055 - acc: 0.9618 - val_loss: 0.0674 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07012 to 0.06741, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9645 - val_loss: 0.0663 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06741 to 0.06632, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1053 - acc: 0.9564 - val_loss: 0.0652 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06632 to 0.06519, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1085 - acc: 0.9598 - val_loss: 0.0626 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06519 to 0.06262, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1005 - acc: 0.9623 - val_loss: 0.0615 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06262 to 0.06155, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1013 - acc: 0.9610 - val_loss: 0.0587 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06155 to 0.05867, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1041 - acc: 0.9586 - val_loss: 0.0583 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05867 to 0.05828, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9637 - val_loss: 0.0547 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05828 to 0.05472, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0963 - acc: 0.9637 - val_loss: 0.0536 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05472 to 0.05363, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0908 - acc: 0.9640 - val_loss: 0.0612 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05363\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0943 - acc: 0.9679 - val_loss: 0.0531 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05363 to 0.05309, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9664 - val_loss: 0.0558 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.05309\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9693 - val_loss: 0.0575 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05309\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0844 - acc: 0.9720 - val_loss: 0.0512 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05309 to 0.05119, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0832 - acc: 0.9701 - val_loss: 0.0509 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05119 to 0.05090, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9722 - val_loss: 0.0469 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05090 to 0.04687, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9725 - val_loss: 0.0487 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04687\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0787 - acc: 0.9715 - val_loss: 0.0455 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04687 to 0.04547, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9701 - val_loss: 0.0433 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04547 to 0.04335, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9688 - val_loss: 0.0440 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04335\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9720 - val_loss: 0.0431 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04335 to 0.04306, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9730 - val_loss: 0.0382 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04306 to 0.03819, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9701 - val_loss: 0.0410 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03819\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9752 - val_loss: 0.0370 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03819 to 0.03705, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0712 - acc: 0.9749 - val_loss: 0.0381 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03705\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9774 - val_loss: 0.0380 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03705\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0800 - acc: 0.9710 - val_loss: 0.0350 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03705 to 0.03495, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9713 - val_loss: 0.0365 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03495\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9732 - val_loss: 0.0353 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03495\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9764 - val_loss: 0.0343 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03495 to 0.03434, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0615 - acc: 0.9798 - val_loss: 0.0349 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03434\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9752 - val_loss: 0.0327 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03434 to 0.03270, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9737 - val_loss: 0.0372 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03270\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0660 - acc: 0.9759 - val_loss: 0.0311 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03270 to 0.03112, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9764 - val_loss: 0.0332 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03112\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9766 - val_loss: 0.0309 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03112 to 0.03090, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9761 - val_loss: 0.0300 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03090 to 0.03001, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9737 - val_loss: 0.0309 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03001\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9783 - val_loss: 0.0273 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03001 to 0.02726, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9774 - val_loss: 0.0333 - val_acc: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02726\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0683 - acc: 0.9766 - val_loss: 0.0287 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02726\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9783 - val_loss: 0.0273 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02726\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9754 - val_loss: 0.0285 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02726\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9759 - val_loss: 0.0284 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02726\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 14s - loss: 0.8062 - acc: 0.5043 - val_loss: 0.6767 - val_acc: 0.4839\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67670, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7413 - acc: 0.5271 - val_loss: 0.6486 - val_acc: 0.7264\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67670 to 0.64865, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6970 - acc: 0.5749 - val_loss: 0.6046 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64865 to 0.60459, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6465 - acc: 0.6267 - val_loss: 0.5365 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60459 to 0.53649, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5696 - acc: 0.7098 - val_loss: 0.4626 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53649 to 0.46256, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5002 - acc: 0.7694 - val_loss: 0.4145 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46256 to 0.41448, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4611 - acc: 0.8006 - val_loss: 0.3905 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41448 to 0.39054, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4317 - acc: 0.8188 - val_loss: 0.3637 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39054 to 0.36367, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3947 - acc: 0.8417 - val_loss: 0.3559 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36367 to 0.35593, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3943 - acc: 0.8364 - val_loss: 0.3318 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35593 to 0.33178, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3740 - acc: 0.8507 - val_loss: 0.3195 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33178 to 0.31947, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3605 - acc: 0.8576 - val_loss: 0.3118 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31947 to 0.31176, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3428 - acc: 0.8658 - val_loss: 0.3092 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.31176 to 0.30919, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3385 - acc: 0.8683 - val_loss: 0.2909 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.30919 to 0.29086, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3230 - acc: 0.8802 - val_loss: 0.2874 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.29086 to 0.28737, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3165 - acc: 0.8829 - val_loss: 0.2776 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.28737 to 0.27762, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3187 - acc: 0.8734 - val_loss: 0.2780 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.27762\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3088 - acc: 0.8856 - val_loss: 0.2677 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27762 to 0.26771, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3022 - acc: 0.8880 - val_loss: 0.2679 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26771\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2858 - acc: 0.8912 - val_loss: 0.2598 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26771 to 0.25978, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2927 - acc: 0.8892 - val_loss: 0.2568 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25978 to 0.25684, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2856 - acc: 0.8919 - val_loss: 0.2524 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25684 to 0.25236, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2801 - acc: 0.8924 - val_loss: 0.2525 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.25236\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2764 - acc: 0.8943 - val_loss: 0.2431 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.25236 to 0.24314, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2651 - acc: 0.9024 - val_loss: 0.2397 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24314 to 0.23970, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2562 - acc: 0.9053 - val_loss: 0.2373 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23970 to 0.23731, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2556 - acc: 0.9038 - val_loss: 0.2341 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23731 to 0.23408, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2613 - acc: 0.9033 - val_loss: 0.2319 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.23408 to 0.23193, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2609 - acc: 0.9021 - val_loss: 0.2254 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23193 to 0.22542, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2531 - acc: 0.9053 - val_loss: 0.2218 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22542 to 0.22179, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2450 - acc: 0.9087 - val_loss: 0.2191 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.22179 to 0.21909, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2503 - acc: 0.9011 - val_loss: 0.2170 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21909 to 0.21702, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2453 - acc: 0.9106 - val_loss: 0.2127 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.21702 to 0.21275, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2312 - acc: 0.9106 - val_loss: 0.2089 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.21275 to 0.20895, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2320 - acc: 0.9165 - val_loss: 0.2043 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20895 to 0.20433, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2227 - acc: 0.9121 - val_loss: 0.1994 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20433 to 0.19938, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2228 - acc: 0.9143 - val_loss: 0.1986 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19938 to 0.19865, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2182 - acc: 0.9204 - val_loss: 0.1936 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19865 to 0.19363, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2116 - acc: 0.9209 - val_loss: 0.1909 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19363 to 0.19087, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2113 - acc: 0.9138 - val_loss: 0.1832 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19087 to 0.18321, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2096 - acc: 0.9196 - val_loss: 0.1776 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18321 to 0.17765, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1996 - acc: 0.9238 - val_loss: 0.1754 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17765 to 0.17545, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9243 - val_loss: 0.1722 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17545 to 0.17216, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2001 - acc: 0.9228 - val_loss: 0.1653 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17216 to 0.16534, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1935 - acc: 0.9272 - val_loss: 0.1641 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16534 to 0.16408, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1853 - acc: 0.9289 - val_loss: 0.1635 - val_acc: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_loss improved from 0.16408 to 0.16354, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1861 - acc: 0.9294 - val_loss: 0.1537 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16354 to 0.15368, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1849 - acc: 0.9299 - val_loss: 0.1494 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15368 to 0.14940, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1853 - acc: 0.9328 - val_loss: 0.1451 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14940 to 0.14506, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1776 - acc: 0.9333 - val_loss: 0.1419 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14506 to 0.14187, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9362 - val_loss: 0.1465 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.14187\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9406 - val_loss: 0.1361 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14187 to 0.13614, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1638 - acc: 0.9364 - val_loss: 0.1389 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.13614\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1719 - acc: 0.9350 - val_loss: 0.1274 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13614 to 0.12740, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1592 - acc: 0.9364 - val_loss: 0.1247 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12740 to 0.12472, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1565 - acc: 0.9459 - val_loss: 0.1230 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12472 to 0.12302, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1545 - acc: 0.9411 - val_loss: 0.1245 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12302\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1467 - acc: 0.9423 - val_loss: 0.1177 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12302 to 0.11766, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1462 - acc: 0.9433 - val_loss: 0.1095 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11766 to 0.10953, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1434 - acc: 0.9469 - val_loss: 0.1084 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10953 to 0.10838, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9472 - val_loss: 0.1032 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10838 to 0.10316, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1429 - acc: 0.9423 - val_loss: 0.1008 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10316 to 0.10075, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1371 - acc: 0.9484 - val_loss: 0.1058 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10075\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1370 - acc: 0.9503 - val_loss: 0.0979 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10075 to 0.09792, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1423 - acc: 0.9430 - val_loss: 0.1002 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.09792\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1299 - acc: 0.9525 - val_loss: 0.0939 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09792 to 0.09391, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1295 - acc: 0.9518 - val_loss: 0.0907 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09391 to 0.09066, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1227 - acc: 0.9498 - val_loss: 0.0831 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09066 to 0.08310, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1312 - acc: 0.9472 - val_loss: 0.0899 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08310\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1280 - acc: 0.9496 - val_loss: 0.0884 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08310\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1219 - acc: 0.9537 - val_loss: 0.0785 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08310 to 0.07854, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1187 - acc: 0.9542 - val_loss: 0.0758 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07854 to 0.07577, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1177 - acc: 0.9554 - val_loss: 0.0745 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.07577 to 0.07447, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1120 - acc: 0.9589 - val_loss: 0.0721 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.07447 to 0.07210, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1078 - acc: 0.9581 - val_loss: 0.0691 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07210 to 0.06911, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9574 - val_loss: 0.0680 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06911 to 0.06805, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1004 - acc: 0.9613 - val_loss: 0.0682 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06805\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9613 - val_loss: 0.0602 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06805 to 0.06020, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1033 - acc: 0.9598 - val_loss: 0.0585 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06020 to 0.05849, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1014 - acc: 0.9589 - val_loss: 0.0572 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05849 to 0.05718, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1245 - acc: 0.9511 - val_loss: 0.0658 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05718\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9674 - val_loss: 0.0568 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05718 to 0.05683, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1008 - acc: 0.9627 - val_loss: 0.0544 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05683 to 0.05443, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9620 - val_loss: 0.0539 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05443 to 0.05393, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0875 - acc: 0.9662 - val_loss: 0.0535 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05393 to 0.05354, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0961 - acc: 0.9620 - val_loss: 0.0513 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05354 to 0.05133, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9657 - val_loss: 0.0494 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05133 to 0.04937, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9625 - val_loss: 0.0477 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04937 to 0.04772, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0937 - acc: 0.9627 - val_loss: 0.0508 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04772\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0901 - acc: 0.9652 - val_loss: 0.0453 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04772 to 0.04531, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9664 - val_loss: 0.0477 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04531\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0910 - acc: 0.9635 - val_loss: 0.0453 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04531\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0815 - acc: 0.9676 - val_loss: 0.0441 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04531 to 0.04408, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0875 - acc: 0.9686 - val_loss: 0.0465 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04408\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0808 - acc: 0.9683 - val_loss: 0.0433 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04408 to 0.04327, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0722 - acc: 0.9735 - val_loss: 0.0415 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04327 to 0.04148, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9701 - val_loss: 0.0422 - val_acc: 0.9805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04148\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0691 - acc: 0.9739 - val_loss: 0.0415 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04148\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0793 - acc: 0.9669 - val_loss: 0.0378 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04148 to 0.03779, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0740 - acc: 0.9730 - val_loss: 0.0440 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03779\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9744 - val_loss: 0.0354 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03779 to 0.03539, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9725 - val_loss: 0.0366 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03539\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9749 - val_loss: 0.0344 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03539 to 0.03445, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0695 - acc: 0.9735 - val_loss: 0.0345 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03445\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9749 - val_loss: 0.0366 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03445\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9701 - val_loss: 0.0321 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03445 to 0.03213, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9752 - val_loss: 0.0323 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03213\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9727 - val_loss: 0.0303 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03213 to 0.03028, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9749 - val_loss: 0.0306 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03028\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0614 - acc: 0.9761 - val_loss: 0.0278 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03028 to 0.02783, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9783 - val_loss: 0.0271 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02783 to 0.02706, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0697 - acc: 0.9732 - val_loss: 0.0316 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02706\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9771 - val_loss: 0.0279 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02706\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9776 - val_loss: 0.0352 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02706\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0609 - acc: 0.9764 - val_loss: 0.0282 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02706\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0770 - acc: 0.9703 - val_loss: 0.0291 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02706\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 14s - loss: 0.7996 - acc: 0.5106 - val_loss: 0.6623 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66229, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7343 - acc: 0.5418 - val_loss: 0.6261 - val_acc: 0.7167\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66229 to 0.62611, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6849 - acc: 0.5900 - val_loss: 0.5699 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62611 to 0.56994, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6027 - acc: 0.6793 - val_loss: 0.4965 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56994 to 0.49652, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5362 - acc: 0.7387 - val_loss: 0.4262 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49652 to 0.42619, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4698 - acc: 0.7882 - val_loss: 0.3808 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42619 to 0.38082, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4268 - acc: 0.8108 - val_loss: 0.3498 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38082 to 0.34975, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4093 - acc: 0.8325 - val_loss: 0.3253 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34975 to 0.32525, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3818 - acc: 0.8466 - val_loss: 0.3089 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32525 to 0.30886, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3636 - acc: 0.8532 - val_loss: 0.2921 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30886 to 0.29212, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3420 - acc: 0.8622 - val_loss: 0.2787 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29212 to 0.27872, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3281 - acc: 0.8710 - val_loss: 0.2660 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27872 to 0.26599, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3265 - acc: 0.8751 - val_loss: 0.2563 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.26599 to 0.25627, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3205 - acc: 0.8753 - val_loss: 0.2494 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25627 to 0.24939, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3019 - acc: 0.8860 - val_loss: 0.2441 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24939 to 0.24409, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2968 - acc: 0.8899 - val_loss: 0.2360 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24409 to 0.23595, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2882 - acc: 0.8963 - val_loss: 0.2348 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23595 to 0.23478, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2831 - acc: 0.8941 - val_loss: 0.2266 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23478 to 0.22662, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2738 - acc: 0.8963 - val_loss: 0.2221 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22662 to 0.22215, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2752 - acc: 0.8992 - val_loss: 0.2196 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22215 to 0.21960, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2630 - acc: 0.9050 - val_loss: 0.2188 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.21960 to 0.21882, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2574 - acc: 0.9031 - val_loss: 0.2119 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21882 to 0.21194, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2603 - acc: 0.9080 - val_loss: 0.2092 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21194 to 0.20922, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2477 - acc: 0.9092 - val_loss: 0.2064 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20922 to 0.20637, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2525 - acc: 0.9104 - val_loss: 0.2044 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20637 to 0.20435, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2523 - acc: 0.9106 - val_loss: 0.2010 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20435 to 0.20105, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2367 - acc: 0.9153 - val_loss: 0.1982 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20105 to 0.19820, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2439 - acc: 0.9145 - val_loss: 0.1945 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19820 to 0.19454, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2294 - acc: 0.9162 - val_loss: 0.1928 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19454 to 0.19276, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2347 - acc: 0.9133 - val_loss: 0.1890 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19276 to 0.18901, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2332 - acc: 0.9145 - val_loss: 0.1865 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.18901 to 0.18649, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2311 - acc: 0.9155 - val_loss: 0.1826 - val_acc: 0.9309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_loss improved from 0.18649 to 0.18261, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2133 - acc: 0.9233 - val_loss: 0.1808 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18261 to 0.18083, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2252 - acc: 0.9131 - val_loss: 0.1775 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18083 to 0.17754, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2140 - acc: 0.9206 - val_loss: 0.1777 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.17754\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2094 - acc: 0.9238 - val_loss: 0.1722 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17754 to 0.17220, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2087 - acc: 0.9223 - val_loss: 0.1692 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17220 to 0.16922, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9243 - val_loss: 0.1651 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16922 to 0.16513, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1997 - acc: 0.9194 - val_loss: 0.1659 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16513\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1986 - acc: 0.9255 - val_loss: 0.1610 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16513 to 0.16095, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1965 - acc: 0.9262 - val_loss: 0.1571 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16095 to 0.15711, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1932 - acc: 0.9270 - val_loss: 0.1532 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15711 to 0.15321, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1879 - acc: 0.9294 - val_loss: 0.1515 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15321 to 0.15149, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1930 - acc: 0.9265 - val_loss: 0.1476 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15149 to 0.14763, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1907 - acc: 0.9326 - val_loss: 0.1433 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14763 to 0.14334, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1858 - acc: 0.9265 - val_loss: 0.1405 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14334 to 0.14046, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1774 - acc: 0.9296 - val_loss: 0.1371 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14046 to 0.13709, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1749 - acc: 0.9321 - val_loss: 0.1336 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13709 to 0.13360, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9357 - val_loss: 0.1305 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13360 to 0.13053, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1660 - acc: 0.9355 - val_loss: 0.1314 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.13053\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1735 - acc: 0.9289 - val_loss: 0.1246 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13053 to 0.12456, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1613 - acc: 0.9382 - val_loss: 0.1197 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12456 to 0.11965, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1619 - acc: 0.9384 - val_loss: 0.1171 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11965 to 0.11713, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1579 - acc: 0.9406 - val_loss: 0.1116 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11713 to 0.11159, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1502 - acc: 0.9442 - val_loss: 0.1091 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11159 to 0.10909, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1476 - acc: 0.9406 - val_loss: 0.1056 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10909 to 0.10563, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1422 - acc: 0.9433 - val_loss: 0.1008 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10563 to 0.10075, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1440 - acc: 0.9438 - val_loss: 0.0949 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10075 to 0.09490, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1417 - acc: 0.9450 - val_loss: 0.0924 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09490 to 0.09235, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1364 - acc: 0.9472 - val_loss: 0.0889 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09235 to 0.08894, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1317 - acc: 0.9462 - val_loss: 0.0855 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08894 to 0.08554, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1357 - acc: 0.9491 - val_loss: 0.0808 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08554 to 0.08076, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1345 - acc: 0.9462 - val_loss: 0.0772 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08076 to 0.07720, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1207 - acc: 0.9515 - val_loss: 0.0748 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07720 to 0.07479, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1276 - acc: 0.9484 - val_loss: 0.0707 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07479 to 0.07067, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1254 - acc: 0.9571 - val_loss: 0.0676 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07067 to 0.06755, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1239 - acc: 0.9474 - val_loss: 0.0648 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.06755 to 0.06483, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1173 - acc: 0.9515 - val_loss: 0.0626 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06483 to 0.06264, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1165 - acc: 0.9545 - val_loss: 0.0625 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06264 to 0.06253, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1091 - acc: 0.9596 - val_loss: 0.0615 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06253 to 0.06154, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1082 - acc: 0.9589 - val_loss: 0.0570 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06154 to 0.05698, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1059 - acc: 0.9596 - val_loss: 0.0548 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05698 to 0.05480, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1083 - acc: 0.9576 - val_loss: 0.0526 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05480 to 0.05262, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1006 - acc: 0.9581 - val_loss: 0.0508 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05262 to 0.05083, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9623 - val_loss: 0.0496 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05083 to 0.04959, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9540 - val_loss: 0.0491 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.04959 to 0.04910, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0949 - acc: 0.9618 - val_loss: 0.0479 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.04910 to 0.04793, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0982 - acc: 0.9615 - val_loss: 0.0469 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04793 to 0.04686, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0933 - acc: 0.9637 - val_loss: 0.0451 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04686 to 0.04511, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0910 - acc: 0.9664 - val_loss: 0.0444 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04511 to 0.04439, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0939 - acc: 0.9654 - val_loss: 0.0408 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04439 to 0.04082, saving model to best.model\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0856 - acc: 0.9686 - val_loss: 0.0403 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04082 to 0.04027, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0978 - acc: 0.9615 - val_loss: 0.0422 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04027\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9627 - val_loss: 0.0427 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04027\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9654 - val_loss: 0.0382 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04027 to 0.03824, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0843 - acc: 0.9681 - val_loss: 0.0373 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03824 to 0.03726, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0811 - acc: 0.9674 - val_loss: 0.0356 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.03726 to 0.03565, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9679 - val_loss: 0.0333 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03565 to 0.03335, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9686 - val_loss: 0.0320 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03335 to 0.03205, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0839 - acc: 0.9666 - val_loss: 0.0327 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03205\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0758 - acc: 0.9703 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03205 to 0.03066, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0799 - acc: 0.9693 - val_loss: 0.0294 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03066 to 0.02943, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9698 - val_loss: 0.0298 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02943\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9713 - val_loss: 0.0305 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02943\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0759 - acc: 0.9715 - val_loss: 0.0295 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02943\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0808 - acc: 0.9671 - val_loss: 0.0298 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02943\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9710 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02943 to 0.02793, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0751 - acc: 0.9703 - val_loss: 0.0273 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02793 to 0.02734, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0730 - acc: 0.9696 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.02734 to 0.02626, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9730 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02626 to 0.02437, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9735 - val_loss: 0.0263 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02437\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0724 - acc: 0.9735 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.02437 to 0.02351, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9742 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02351 to 0.02296, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9747 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02296 to 0.02138, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9786 - val_loss: 0.0211 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02138 to 0.02108, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9730 - val_loss: 0.0217 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02108\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9747 - val_loss: 0.0204 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02108 to 0.02042, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9757 - val_loss: 0.0209 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02042\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9761 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02042\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9742 - val_loss: 0.0210 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02042\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9791 - val_loss: 0.0195 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02042 to 0.01950, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9781 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.01950 to 0.01855, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9749 - val_loss: 0.0214 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01855\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9747 - val_loss: 0.0196 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01855\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9769 - val_loss: 0.0177 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.01855 to 0.01767, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9778 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01767 to 0.01729, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0548 - acc: 0.9793 - val_loss: 0.0163 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01729 to 0.01634, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9766 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01634\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9795 - val_loss: 0.0165 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01634\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0630 - acc: 0.9771 - val_loss: 0.0161 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.01634 to 0.01613, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9776 - val_loss: 0.0161 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01613\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9783 - val_loss: 0.0159 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01613 to 0.01586, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9781 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01586 to 0.01541, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9766 - val_loss: 0.0172 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01541\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9769 - val_loss: 0.0156 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01541\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9800 - val_loss: 0.0156 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01541\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9825 - val_loss: 0.0143 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01541 to 0.01425, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9805 - val_loss: 0.0150 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01425\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9805 - val_loss: 0.0136 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01425 to 0.01356, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0507 - acc: 0.9803 - val_loss: 0.0130 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01356 to 0.01301, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9798 - val_loss: 0.0131 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01301\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9793 - val_loss: 0.0128 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01301 to 0.01280, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9803 - val_loss: 0.0129 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01280\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0467 - acc: 0.9825 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01280\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0483 - acc: 0.9805 - val_loss: 0.0128 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01280 to 0.01275, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9837 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01275 to 0.01211, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0477 - acc: 0.9808 - val_loss: 0.0106 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01211 to 0.01059, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9813 - val_loss: 0.0100 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01059 to 0.01004, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9815 - val_loss: 0.0100 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01004 to 0.00998, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9842 - val_loss: 0.0099 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00998 to 0.00985, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9825 - val_loss: 0.0104 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00985\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9825 - val_loss: 0.0096 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00985 to 0.00960, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0392 - acc: 0.9866 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00960 to 0.00873, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9830 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00873 to 0.00861, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0430 - acc: 0.9822 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00861\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9832 - val_loss: 0.0089 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00861\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9830 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00861 to 0.00834, saving model to best.model\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0393 - acc: 0.9873 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00834 to 0.00810, saving model to best.model\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0393 - acc: 0.9854 - val_loss: 0.0078 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00810 to 0.00783, saving model to best.model\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9830 - val_loss: 0.0074 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00783 to 0.00738, saving model to best.model\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0404 - acc: 0.9849 - val_loss: 0.0072 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00738 to 0.00718, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9837 - val_loss: 0.0074 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00718\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9834 - val_loss: 0.0079 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00718\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0343 - acc: 0.9883 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00718 to 0.00685, saving model to best.model\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9854 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00685 to 0.00683, saving model to best.model\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0381 - acc: 0.9856 - val_loss: 0.0066 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00683 to 0.00660, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9832 - val_loss: 0.0072 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00660\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9822 - val_loss: 0.0078 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00660\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0077 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00660\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0395 - acc: 0.9856 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00660\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9871 - val_loss: 0.0079 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00660\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 14s - loss: 0.8133 - acc: 0.5159 - val_loss: 0.6762 - val_acc: 0.7371\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67617, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7692 - acc: 0.5213 - val_loss: 0.6593 - val_acc: 0.5326\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67617 to 0.65932, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7191 - acc: 0.5505 - val_loss: 0.6149 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65932 to 0.61485, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6673 - acc: 0.6063 - val_loss: 0.5493 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61485 to 0.54933, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5981 - acc: 0.6910 - val_loss: 0.4772 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54933 to 0.47723, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5545 - acc: 0.7219 - val_loss: 0.4151 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47723 to 0.41511, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.5046 - acc: 0.7633 - val_loss: 0.3784 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41511 to 0.37835, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4708 - acc: 0.7899 - val_loss: 0.3431 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37835 to 0.34307, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4370 - acc: 0.8157 - val_loss: 0.3190 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34307 to 0.31901, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.4219 - acc: 0.8279 - val_loss: 0.3028 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31901 to 0.30278, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.4020 - acc: 0.8271 - val_loss: 0.2941 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.30278 to 0.29411, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3811 - acc: 0.8481 - val_loss: 0.2784 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29411 to 0.27840, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3686 - acc: 0.8539 - val_loss: 0.2681 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27840 to 0.26809, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3584 - acc: 0.8578 - val_loss: 0.2601 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26809 to 0.26011, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3393 - acc: 0.8705 - val_loss: 0.2536 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26011 to 0.25355, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3390 - acc: 0.8700 - val_loss: 0.2484 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25355 to 0.24838, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3246 - acc: 0.8812 - val_loss: 0.2439 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24838 to 0.24392, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3307 - acc: 0.8761 - val_loss: 0.2431 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24392 to 0.24313, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3272 - acc: 0.8768 - val_loss: 0.2387 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24313 to 0.23870, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2956 - acc: 0.8921 - val_loss: 0.2328 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23870 to 0.23282, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3055 - acc: 0.8938 - val_loss: 0.2288 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23282 to 0.22876, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2951 - acc: 0.8943 - val_loss: 0.2260 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22876 to 0.22604, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2913 - acc: 0.8907 - val_loss: 0.2224 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22604 to 0.22242, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2893 - acc: 0.8968 - val_loss: 0.2208 - val_acc: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss improved from 0.22242 to 0.22079, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2884 - acc: 0.8958 - val_loss: 0.2201 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22079 to 0.22006, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2827 - acc: 0.8958 - val_loss: 0.2153 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22006 to 0.21528, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2625 - acc: 0.9072 - val_loss: 0.2159 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.21528\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2695 - acc: 0.9014 - val_loss: 0.2086 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21528 to 0.20860, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2613 - acc: 0.9075 - val_loss: 0.2075 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20860 to 0.20753, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2621 - acc: 0.9048 - val_loss: 0.2018 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20753 to 0.20178, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2554 - acc: 0.9072 - val_loss: 0.1980 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20178 to 0.19799, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2603 - acc: 0.9055 - val_loss: 0.1963 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19799 to 0.19631, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2497 - acc: 0.9104 - val_loss: 0.1940 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19631 to 0.19402, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2490 - acc: 0.9065 - val_loss: 0.1884 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19402 to 0.18845, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2427 - acc: 0.9140 - val_loss: 0.1852 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18845 to 0.18519, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2392 - acc: 0.9080 - val_loss: 0.1838 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18519 to 0.18384, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2376 - acc: 0.9084 - val_loss: 0.1777 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18384 to 0.17768, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2322 - acc: 0.9092 - val_loss: 0.1759 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17768 to 0.17585, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2388 - acc: 0.9097 - val_loss: 0.1738 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17585 to 0.17377, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2294 - acc: 0.9165 - val_loss: 0.1715 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17377 to 0.17149, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2226 - acc: 0.9153 - val_loss: 0.1680 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17149 to 0.16805, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2176 - acc: 0.9160 - val_loss: 0.1661 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.16805 to 0.16607, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2191 - acc: 0.9209 - val_loss: 0.1646 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16607 to 0.16464, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2060 - acc: 0.9162 - val_loss: 0.1605 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16464 to 0.16046, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2103 - acc: 0.9204 - val_loss: 0.1553 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16046 to 0.15533, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2063 - acc: 0.9211 - val_loss: 0.1545 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15533 to 0.15447, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1998 - acc: 0.9231 - val_loss: 0.1522 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15447 to 0.15218, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2119 - acc: 0.9175 - val_loss: 0.1489 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15218 to 0.14888, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2045 - acc: 0.9245 - val_loss: 0.1443 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14888 to 0.14433, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1862 - acc: 0.9338 - val_loss: 0.1406 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14433 to 0.14065, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1855 - acc: 0.9284 - val_loss: 0.1390 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14065 to 0.13903, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1947 - acc: 0.9270 - val_loss: 0.1372 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13903 to 0.13722, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1840 - acc: 0.9294 - val_loss: 0.1334 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13722 to 0.13341, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1820 - acc: 0.9335 - val_loss: 0.1315 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13341 to 0.13153, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1785 - acc: 0.9279 - val_loss: 0.1282 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13153 to 0.12816, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1818 - acc: 0.9311 - val_loss: 0.1234 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12816 to 0.12341, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1714 - acc: 0.9374 - val_loss: 0.1221 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12341 to 0.12209, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1723 - acc: 0.9296 - val_loss: 0.1192 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12209 to 0.11915, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1738 - acc: 0.9313 - val_loss: 0.1212 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.11915\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1673 - acc: 0.9338 - val_loss: 0.1135 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11915 to 0.11345, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1638 - acc: 0.9355 - val_loss: 0.1097 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11345 to 0.10969, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1609 - acc: 0.9421 - val_loss: 0.1085 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10969 to 0.10848, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1569 - acc: 0.9403 - val_loss: 0.1056 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10848 to 0.10557, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1464 - acc: 0.9450 - val_loss: 0.1009 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10557 to 0.10091, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1538 - acc: 0.9406 - val_loss: 0.0982 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10091 to 0.09817, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9452 - val_loss: 0.0947 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09817 to 0.09472, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1462 - acc: 0.9418 - val_loss: 0.0945 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09472 to 0.09448, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1459 - acc: 0.9418 - val_loss: 0.0911 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09448 to 0.09106, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1379 - acc: 0.9462 - val_loss: 0.0864 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09106 to 0.08636, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9479 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08636 to 0.08108, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1333 - acc: 0.9464 - val_loss: 0.0790 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08108 to 0.07899, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1263 - acc: 0.9494 - val_loss: 0.0755 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07899 to 0.07547, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1204 - acc: 0.9537 - val_loss: 0.0783 - val_acc: 0.9757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07547\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1263 - acc: 0.9515 - val_loss: 0.0713 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.07547 to 0.07133, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1233 - acc: 0.9542 - val_loss: 0.0697 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07133 to 0.06975, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1196 - acc: 0.9550 - val_loss: 0.0690 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06975 to 0.06904, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1166 - acc: 0.9506 - val_loss: 0.0661 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06904 to 0.06613, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1171 - acc: 0.9574 - val_loss: 0.0628 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06613 to 0.06281, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9542 - val_loss: 0.0602 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06281 to 0.06016, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9567 - val_loss: 0.0565 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.06016 to 0.05648, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0995 - acc: 0.9574 - val_loss: 0.0530 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05648 to 0.05296, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9576 - val_loss: 0.0514 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05296 to 0.05140, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9642 - val_loss: 0.0492 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05140 to 0.04917, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0950 - acc: 0.9630 - val_loss: 0.0478 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04917 to 0.04778, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0967 - acc: 0.9627 - val_loss: 0.0454 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04778 to 0.04538, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0984 - acc: 0.9618 - val_loss: 0.0443 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04538 to 0.04425, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9652 - val_loss: 0.0422 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04425 to 0.04216, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0948 - acc: 0.9630 - val_loss: 0.0405 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04216 to 0.04052, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0891 - acc: 0.9640 - val_loss: 0.0414 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04052\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0864 - acc: 0.9649 - val_loss: 0.0400 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04052 to 0.04004, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0864 - acc: 0.9676 - val_loss: 0.0403 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04004\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9696 - val_loss: 0.0372 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04004 to 0.03722, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9681 - val_loss: 0.0347 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03722 to 0.03467, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0841 - acc: 0.9681 - val_loss: 0.0372 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03467\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0832 - acc: 0.9683 - val_loss: 0.0359 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03467\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0695 - acc: 0.9747 - val_loss: 0.0340 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03467 to 0.03396, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9679 - val_loss: 0.0337 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03396 to 0.03367, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0823 - acc: 0.9681 - val_loss: 0.0323 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03367 to 0.03234, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9705 - val_loss: 0.0309 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03234 to 0.03094, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9703 - val_loss: 0.0307 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03094 to 0.03072, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0705 - acc: 0.9730 - val_loss: 0.0295 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03072 to 0.02948, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0723 - acc: 0.9720 - val_loss: 0.0296 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02948\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9718 - val_loss: 0.0296 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02948\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0740 - acc: 0.9715 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02948 to 0.02905, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9739 - val_loss: 0.0269 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02905 to 0.02687, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9696 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02687\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9727 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02687\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0657 - acc: 0.9742 - val_loss: 0.0266 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02687 to 0.02659, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9749 - val_loss: 0.0262 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02659 to 0.02617, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9759 - val_loss: 0.0255 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02617 to 0.02552, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9757 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02552 to 0.02490, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0724 - acc: 0.9715 - val_loss: 0.0274 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02490\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0848 - acc: 0.9681 - val_loss: 0.0293 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02490\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0681 - acc: 0.9735 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02490 to 0.02390, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0758 - acc: 0.9713 - val_loss: 0.0243 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02390\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9722 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02390\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9800 - val_loss: 0.0227 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02390 to 0.02269, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9776 - val_loss: 0.0226 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02269 to 0.02256, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9771 - val_loss: 0.0210 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02256 to 0.02097, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9788 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02097\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0610 - acc: 0.9774 - val_loss: 0.0215 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02097\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9769 - val_loss: 0.0219 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02097\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0614 - acc: 0.9761 - val_loss: 0.0198 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.02097 to 0.01985, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9771 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01985 to 0.01918, saving model to best.model\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0621 - acc: 0.9764 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01918 to 0.01897, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9810 - val_loss: 0.0199 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01897\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9839 - val_loss: 0.0191 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01897\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9793 - val_loss: 0.0205 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01897\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9766 - val_loss: 0.0188 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01897 to 0.01883, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0537 - acc: 0.9808 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01883\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0610 - acc: 0.9764 - val_loss: 0.0182 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01883 to 0.01816, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9781 - val_loss: 0.0171 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01816 to 0.01706, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9803 - val_loss: 0.0187 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01706\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9793 - val_loss: 0.0175 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01706\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9820 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01706\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9825 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01706 to 0.01649, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9832 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01649\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9827 - val_loss: 0.0160 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01649 to 0.01598, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9781 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01598 to 0.01576, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0453 - acc: 0.9839 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01576\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9791 - val_loss: 0.0160 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01576\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9856 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01576 to 0.01424, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9810 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01424\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9815 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01424\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9832 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01424\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9842 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01424\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0402 - acc: 0.9849 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01424\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 15s - loss: 0.7817 - acc: 0.5118 - val_loss: 0.6672 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66723, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7358 - acc: 0.5310 - val_loss: 0.6378 - val_acc: 0.8014\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66723 to 0.63776, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6889 - acc: 0.5776 - val_loss: 0.5883 - val_acc: 0.8053\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63776 to 0.58832, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6261 - acc: 0.6521 - val_loss: 0.5248 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58832 to 0.52481, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5637 - acc: 0.7144 - val_loss: 0.4563 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52481 to 0.45629, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4964 - acc: 0.7711 - val_loss: 0.4084 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45629 to 0.40836, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4525 - acc: 0.8023 - val_loss: 0.3785 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40836 to 0.37852, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4143 - acc: 0.8264 - val_loss: 0.3549 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37852 to 0.35486, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3958 - acc: 0.8405 - val_loss: 0.3343 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35486 to 0.33434, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3683 - acc: 0.8539 - val_loss: 0.3170 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33434 to 0.31696, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3544 - acc: 0.8593 - val_loss: 0.3044 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31696 to 0.30440, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3422 - acc: 0.8714 - val_loss: 0.2910 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30440 to 0.29099, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3269 - acc: 0.8727 - val_loss: 0.2864 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29099 to 0.28645, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3128 - acc: 0.8809 - val_loss: 0.2738 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28645 to 0.27381, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3035 - acc: 0.8858 - val_loss: 0.2658 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27381 to 0.26582, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2937 - acc: 0.8899 - val_loss: 0.2683 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26582\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2912 - acc: 0.8948 - val_loss: 0.2541 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26582 to 0.25409, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2746 - acc: 0.8992 - val_loss: 0.2479 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25409 to 0.24788, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2650 - acc: 0.9060 - val_loss: 0.2425 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24788 to 0.24254, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2680 - acc: 0.9036 - val_loss: 0.2385 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24254 to 0.23852, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2560 - acc: 0.9070 - val_loss: 0.2351 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23852 to 0.23507, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2660 - acc: 0.9058 - val_loss: 0.2330 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23507 to 0.23296, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2566 - acc: 0.9116 - val_loss: 0.2269 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23296 to 0.22694, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9133 - val_loss: 0.2212 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22694 to 0.22121, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2478 - acc: 0.9116 - val_loss: 0.2219 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.22121\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2333 - acc: 0.9162 - val_loss: 0.2154 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22121 to 0.21536, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2365 - acc: 0.9143 - val_loss: 0.2106 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21536 to 0.21058, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2360 - acc: 0.9187 - val_loss: 0.2074 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21058 to 0.20741, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2272 - acc: 0.9158 - val_loss: 0.2067 - val_acc: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_loss improved from 0.20741 to 0.20670, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2233 - acc: 0.9196 - val_loss: 0.1989 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20670 to 0.19894, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2182 - acc: 0.9231 - val_loss: 0.1966 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19894 to 0.19661, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2126 - acc: 0.9233 - val_loss: 0.1971 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.19661\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9287 - val_loss: 0.1901 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19661 to 0.19011, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2175 - acc: 0.9211 - val_loss: 0.1851 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19011 to 0.18508, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2038 - acc: 0.9279 - val_loss: 0.1825 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18508 to 0.18246, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1988 - acc: 0.9323 - val_loss: 0.1795 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18246 to 0.17948, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1994 - acc: 0.9304 - val_loss: 0.1771 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17948 to 0.17707, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1956 - acc: 0.9321 - val_loss: 0.1729 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17707 to 0.17292, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2004 - acc: 0.9250 - val_loss: 0.1728 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17292 to 0.17284, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1928 - acc: 0.9294 - val_loss: 0.1679 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17284 to 0.16793, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1833 - acc: 0.9367 - val_loss: 0.1636 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16793 to 0.16359, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1790 - acc: 0.9345 - val_loss: 0.1632 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.16359 to 0.16322, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1865 - acc: 0.9340 - val_loss: 0.1572 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16322 to 0.15720, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1842 - acc: 0.9311 - val_loss: 0.1561 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15720 to 0.15606, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1734 - acc: 0.9416 - val_loss: 0.1546 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15606 to 0.15462, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1731 - acc: 0.9403 - val_loss: 0.1526 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15462 to 0.15256, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1672 - acc: 0.9403 - val_loss: 0.1460 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15256 to 0.14598, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1691 - acc: 0.9430 - val_loss: 0.1441 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14598 to 0.14410, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1647 - acc: 0.9433 - val_loss: 0.1406 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14410 to 0.14060, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1598 - acc: 0.9462 - val_loss: 0.1366 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14060 to 0.13661, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1559 - acc: 0.9506 - val_loss: 0.1344 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13661 to 0.13441, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1524 - acc: 0.9450 - val_loss: 0.1293 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13441 to 0.12930, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1474 - acc: 0.9489 - val_loss: 0.1285 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12930 to 0.12851, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1482 - acc: 0.9479 - val_loss: 0.1225 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12851 to 0.12254, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1428 - acc: 0.9494 - val_loss: 0.1202 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12254 to 0.12016, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1446 - acc: 0.9525 - val_loss: 0.1237 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.12016\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9518 - val_loss: 0.1144 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12016 to 0.11444, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1432 - acc: 0.9481 - val_loss: 0.1143 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11444 to 0.11434, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1425 - acc: 0.9496 - val_loss: 0.1065 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11434 to 0.10646, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1373 - acc: 0.9506 - val_loss: 0.1051 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10646 to 0.10514, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1362 - acc: 0.9528 - val_loss: 0.1033 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10514 to 0.10335, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1342 - acc: 0.9525 - val_loss: 0.0977 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10335 to 0.09772, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1281 - acc: 0.9586 - val_loss: 0.0945 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09772 to 0.09449, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1254 - acc: 0.9567 - val_loss: 0.0930 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09449 to 0.09301, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1272 - acc: 0.9535 - val_loss: 0.0887 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09301 to 0.08866, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1224 - acc: 0.9586 - val_loss: 0.0836 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08866 to 0.08365, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1228 - acc: 0.9540 - val_loss: 0.0806 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08365 to 0.08062, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9625 - val_loss: 0.0781 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08062 to 0.07812, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1183 - acc: 0.9598 - val_loss: 0.0752 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07812 to 0.07520, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1179 - acc: 0.9581 - val_loss: 0.0798 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07520\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9618 - val_loss: 0.0723 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07520 to 0.07225, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9620 - val_loss: 0.0691 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07225 to 0.06914, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1097 - acc: 0.9627 - val_loss: 0.0703 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06914\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1069 - acc: 0.9640 - val_loss: 0.0679 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06914 to 0.06788, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0991 - acc: 0.9669 - val_loss: 0.0637 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06788 to 0.06368, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1014 - acc: 0.9615 - val_loss: 0.0608 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06368 to 0.06080, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9645 - val_loss: 0.0623 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06080\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0966 - acc: 0.9674 - val_loss: 0.0590 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06080 to 0.05900, saving model to best.model\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0947 - acc: 0.9683 - val_loss: 0.0564 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05900 to 0.05638, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1019 - acc: 0.9613 - val_loss: 0.0552 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05638 to 0.05523, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0980 - acc: 0.9645 - val_loss: 0.0556 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05523\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0961 - acc: 0.9642 - val_loss: 0.0554 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05523\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0911 - acc: 0.9664 - val_loss: 0.0521 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05523 to 0.05210, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9693 - val_loss: 0.0488 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05210 to 0.04879, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9679 - val_loss: 0.0457 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04879 to 0.04570, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0837 - acc: 0.9696 - val_loss: 0.0453 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04570 to 0.04535, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9705 - val_loss: 0.0431 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04535 to 0.04313, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0866 - acc: 0.9696 - val_loss: 0.0423 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04313 to 0.04229, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0848 - acc: 0.9720 - val_loss: 0.0423 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04229 to 0.04226, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0853 - acc: 0.9659 - val_loss: 0.0386 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04226 to 0.03859, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0822 - acc: 0.9701 - val_loss: 0.0377 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03859 to 0.03773, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9725 - val_loss: 0.0377 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03773 to 0.03767, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0815 - acc: 0.9688 - val_loss: 0.0388 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03767\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9725 - val_loss: 0.0358 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03767 to 0.03579, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9747 - val_loss: 0.0347 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03579 to 0.03472, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9739 - val_loss: 0.0343 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03472 to 0.03429, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9754 - val_loss: 0.0319 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03429 to 0.03192, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9730 - val_loss: 0.0324 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03192\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9718 - val_loss: 0.0332 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03192\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9742 - val_loss: 0.0304 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03192 to 0.03042, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9766 - val_loss: 0.0313 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03042\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0775 - acc: 0.9739 - val_loss: 0.0280 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03042 to 0.02805, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9769 - val_loss: 0.0304 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02805\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9749 - val_loss: 0.0266 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02805 to 0.02662, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9754 - val_loss: 0.0284 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02662\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9788 - val_loss: 0.0244 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02662 to 0.02442, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9732 - val_loss: 0.0287 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02442\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9742 - val_loss: 0.0247 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02442\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9708 - val_loss: 0.0266 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02442\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9766 - val_loss: 0.0229 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02442 to 0.02292, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0603 - acc: 0.9793 - val_loss: 0.0260 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02292\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9778 - val_loss: 0.0223 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02292 to 0.02227, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9786 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02227 to 0.02216, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9805 - val_loss: 0.0218 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02216 to 0.02181, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0553 - acc: 0.9813 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02181 to 0.02015, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9771 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02015\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9778 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02015\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9771 - val_loss: 0.0219 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02015\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9791 - val_loss: 0.0200 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02015 to 0.02004, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9810 - val_loss: 0.0200 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02004 to 0.02004, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9803 - val_loss: 0.0175 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02004 to 0.01754, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9803 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01754 to 0.01726, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9820 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01726\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9798 - val_loss: 0.0193 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01726\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9825 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01726\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9795 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01726 to 0.01689, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9808 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01689 to 0.01675, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9825 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01675 to 0.01626, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9832 - val_loss: 0.0151 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01626 to 0.01508, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0452 - acc: 0.9847 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01508 to 0.01504, saving model to best.model\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0489 - acc: 0.9847 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.01504 to 0.01348, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9830 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01348\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9800 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01348\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9822 - val_loss: 0.0168 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01348\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9805 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01348\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0549 - acc: 0.9808 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01348\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 15s - loss: 0.8529 - acc: 0.4933 - val_loss: 0.6938 - val_acc: 0.4859\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69378, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7691 - acc: 0.5125 - val_loss: 0.6673 - val_acc: 0.5141\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69378 to 0.66733, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7240 - acc: 0.5447 - val_loss: 0.6293 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66733 to 0.62932, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6816 - acc: 0.5888 - val_loss: 0.5772 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62932 to 0.57724, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6204 - acc: 0.6562 - val_loss: 0.5068 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57724 to 0.50675, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5562 - acc: 0.7241 - val_loss: 0.4426 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50675 to 0.44259, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.5010 - acc: 0.7675 - val_loss: 0.3966 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44259 to 0.39657, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4518 - acc: 0.8001 - val_loss: 0.3641 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39657 to 0.36408, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4179 - acc: 0.8181 - val_loss: 0.3400 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36408 to 0.33998, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3920 - acc: 0.8391 - val_loss: 0.3212 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33998 to 0.32119, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3769 - acc: 0.8481 - val_loss: 0.3046 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32119 to 0.30465, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3656 - acc: 0.8568 - val_loss: 0.2971 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30465 to 0.29705, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3506 - acc: 0.8683 - val_loss: 0.2841 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29705 to 0.28411, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3293 - acc: 0.8783 - val_loss: 0.2732 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28411 to 0.27323, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3259 - acc: 0.8807 - val_loss: 0.2669 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27323 to 0.26692, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3125 - acc: 0.8853 - val_loss: 0.2585 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26692 to 0.25849, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2935 - acc: 0.8972 - val_loss: 0.2524 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25849 to 0.25242, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2980 - acc: 0.8929 - val_loss: 0.2477 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25242 to 0.24772, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2954 - acc: 0.8953 - val_loss: 0.2435 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24772 to 0.24352, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2822 - acc: 0.8987 - val_loss: 0.2401 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24352 to 0.24014, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2796 - acc: 0.9053 - val_loss: 0.2360 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24014 to 0.23597, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2774 - acc: 0.9036 - val_loss: 0.2329 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23597 to 0.23287, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2690 - acc: 0.9065 - val_loss: 0.2330 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.23287\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2618 - acc: 0.9116 - val_loss: 0.2253 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23287 to 0.22530, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2651 - acc: 0.9099 - val_loss: 0.2230 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22530 to 0.22301, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2571 - acc: 0.9160 - val_loss: 0.2220 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22301 to 0.22196, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2457 - acc: 0.9143 - val_loss: 0.2196 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.22196 to 0.21956, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2637 - acc: 0.9075 - val_loss: 0.2188 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21956 to 0.21879, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2505 - acc: 0.9143 - val_loss: 0.2128 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21879 to 0.21278, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2471 - acc: 0.9184 - val_loss: 0.2087 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21278 to 0.20868, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2436 - acc: 0.9167 - val_loss: 0.2063 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20868 to 0.20627, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2379 - acc: 0.9170 - val_loss: 0.2027 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20627 to 0.20270, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2288 - acc: 0.9189 - val_loss: 0.1993 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20270 to 0.19928, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9172 - val_loss: 0.1960 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19928 to 0.19596, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2284 - acc: 0.9182 - val_loss: 0.1930 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19596 to 0.19303, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2249 - acc: 0.9170 - val_loss: 0.1905 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19303 to 0.19048, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2215 - acc: 0.9170 - val_loss: 0.1852 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19048 to 0.18524, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2190 - acc: 0.9235 - val_loss: 0.1824 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18524 to 0.18239, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2122 - acc: 0.9216 - val_loss: 0.1791 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18239 to 0.17915, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2174 - acc: 0.9228 - val_loss: 0.1771 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17915 to 0.17705, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2065 - acc: 0.9279 - val_loss: 0.1718 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17705 to 0.17185, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2134 - acc: 0.9209 - val_loss: 0.1681 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17185 to 0.16815, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1982 - acc: 0.9277 - val_loss: 0.1658 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16815 to 0.16580, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1957 - acc: 0.9299 - val_loss: 0.1645 - val_acc: 0.9328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_loss improved from 0.16580 to 0.16451, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1973 - acc: 0.9235 - val_loss: 0.1587 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16451 to 0.15866, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1909 - acc: 0.9299 - val_loss: 0.1587 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.15866\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1911 - acc: 0.9260 - val_loss: 0.1524 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15866 to 0.15240, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1865 - acc: 0.9306 - val_loss: 0.1471 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15240 to 0.14714, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1865 - acc: 0.9277 - val_loss: 0.1433 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14714 to 0.14329, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1766 - acc: 0.9323 - val_loss: 0.1384 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14329 to 0.13839, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1730 - acc: 0.9299 - val_loss: 0.1355 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13839 to 0.13547, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1686 - acc: 0.9360 - val_loss: 0.1289 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13547 to 0.12890, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1690 - acc: 0.9328 - val_loss: 0.1251 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12890 to 0.12507, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1646 - acc: 0.9364 - val_loss: 0.1227 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12507 to 0.12265, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1632 - acc: 0.9374 - val_loss: 0.1162 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12265 to 0.11622, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1540 - acc: 0.9416 - val_loss: 0.1132 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.11622 to 0.11319, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1453 - acc: 0.9413 - val_loss: 0.1092 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11319 to 0.10917, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1388 - acc: 0.9469 - val_loss: 0.1062 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10917 to 0.10624, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1443 - acc: 0.9411 - val_loss: 0.1013 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10624 to 0.10133, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9457 - val_loss: 0.1003 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10133 to 0.10026, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1357 - acc: 0.9484 - val_loss: 0.0992 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10026 to 0.09916, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1375 - acc: 0.9489 - val_loss: 0.0912 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09916 to 0.09116, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9523 - val_loss: 0.0887 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09116 to 0.08867, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1368 - acc: 0.9477 - val_loss: 0.0860 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08867 to 0.08603, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1264 - acc: 0.9508 - val_loss: 0.0825 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08603 to 0.08248, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1271 - acc: 0.9525 - val_loss: 0.0805 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08248 to 0.08045, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1138 - acc: 0.9554 - val_loss: 0.0777 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08045 to 0.07774, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1138 - acc: 0.9552 - val_loss: 0.0737 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07774 to 0.07369, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1152 - acc: 0.9528 - val_loss: 0.0718 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07369 to 0.07179, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9564 - val_loss: 0.0693 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07179 to 0.06927, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1127 - acc: 0.9569 - val_loss: 0.0700 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06927\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1066 - acc: 0.9596 - val_loss: 0.0676 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06927 to 0.06762, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9603 - val_loss: 0.0702 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06762\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9608 - val_loss: 0.0653 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06762 to 0.06526, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9635 - val_loss: 0.0625 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06526 to 0.06249, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1005 - acc: 0.9606 - val_loss: 0.0590 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06249 to 0.05898, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9620 - val_loss: 0.0554 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05898 to 0.05537, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9625 - val_loss: 0.0548 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05537 to 0.05479, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1026 - acc: 0.9608 - val_loss: 0.0535 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05479 to 0.05349, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9603 - val_loss: 0.0541 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05349\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0929 - acc: 0.9623 - val_loss: 0.0542 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05349\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0875 - acc: 0.9649 - val_loss: 0.0533 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05349 to 0.05333, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9637 - val_loss: 0.0471 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05333 to 0.04709, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9664 - val_loss: 0.0473 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04709\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0824 - acc: 0.9688 - val_loss: 0.0440 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04709 to 0.04404, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0794 - acc: 0.9696 - val_loss: 0.0441 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04404\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9715 - val_loss: 0.0435 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04404 to 0.04353, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0785 - acc: 0.9705 - val_loss: 0.0419 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04353 to 0.04194, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9698 - val_loss: 0.0409 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04194 to 0.04093, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9725 - val_loss: 0.0394 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04093 to 0.03937, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9737 - val_loss: 0.0402 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03937\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9737 - val_loss: 0.0367 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03937 to 0.03669, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9749 - val_loss: 0.0351 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03669 to 0.03514, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9735 - val_loss: 0.0339 - val_acc: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00094: val_loss improved from 0.03514 to 0.03388, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9730 - val_loss: 0.0317 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03388 to 0.03168, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9766 - val_loss: 0.0312 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03168 to 0.03121, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0728 - acc: 0.9720 - val_loss: 0.0306 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03121 to 0.03062, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9720 - val_loss: 0.0308 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03062\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0649 - acc: 0.9761 - val_loss: 0.0293 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03062 to 0.02927, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9752 - val_loss: 0.0300 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02927\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9766 - val_loss: 0.0274 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.02927 to 0.02737, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9739 - val_loss: 0.0287 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02737\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9744 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02737 to 0.02692, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9788 - val_loss: 0.0252 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02692 to 0.02519, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9749 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02519\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0565 - acc: 0.9795 - val_loss: 0.0262 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02519\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0547 - acc: 0.9798 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02519 to 0.02484, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9791 - val_loss: 0.0241 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02484 to 0.02407, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0580 - acc: 0.9759 - val_loss: 0.0231 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02407 to 0.02305, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9783 - val_loss: 0.0297 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02305\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0553 - acc: 0.9783 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02305 to 0.02188, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0607 - acc: 0.9764 - val_loss: 0.0219 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02188 to 0.02185, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9822 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02185 to 0.02127, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0562 - acc: 0.9788 - val_loss: 0.0203 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02127 to 0.02027, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0514 - acc: 0.9808 - val_loss: 0.0225 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02027\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9793 - val_loss: 0.0190 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02027 to 0.01899, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9817 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01899 to 0.01796, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9798 - val_loss: 0.0233 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01796\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9788 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01796\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9805 - val_loss: 0.0213 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01796\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9786 - val_loss: 0.0188 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01796\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9803 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01796\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 15s - loss: 0.8430 - acc: 0.5028 - val_loss: 0.6845 - val_acc: 0.5170\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68453, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7724 - acc: 0.5262 - val_loss: 0.6731 - val_acc: 0.4830\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68453 to 0.67309, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7212 - acc: 0.5532 - val_loss: 0.6368 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67309 to 0.63682, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6813 - acc: 0.5997 - val_loss: 0.5955 - val_acc: 0.7293\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63682 to 0.59547, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6192 - acc: 0.6538 - val_loss: 0.5308 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59547 to 0.53084, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5531 - acc: 0.7300 - val_loss: 0.4788 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.53084 to 0.47881, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4883 - acc: 0.7692 - val_loss: 0.4473 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47881 to 0.44725, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4463 - acc: 0.8020 - val_loss: 0.4063 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44725 to 0.40630, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4073 - acc: 0.8300 - val_loss: 0.3821 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40630 to 0.38205, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3878 - acc: 0.8405 - val_loss: 0.3607 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38205 to 0.36072, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3611 - acc: 0.8607 - val_loss: 0.3411 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36072 to 0.34110, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3554 - acc: 0.8617 - val_loss: 0.3257 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34110 to 0.32567, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3347 - acc: 0.8727 - val_loss: 0.3085 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32567 to 0.30855, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3279 - acc: 0.8697 - val_loss: 0.2976 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.30855 to 0.29755, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3142 - acc: 0.8751 - val_loss: 0.3020 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.29755\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3096 - acc: 0.8817 - val_loss: 0.2904 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.29755 to 0.29038, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3024 - acc: 0.8860 - val_loss: 0.2816 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.29038 to 0.28162, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2896 - acc: 0.8919 - val_loss: 0.2707 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.28162 to 0.27070, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2942 - acc: 0.8907 - val_loss: 0.2662 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.27070 to 0.26622, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2770 - acc: 0.9004 - val_loss: 0.2598 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26622 to 0.25982, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2792 - acc: 0.8963 - val_loss: 0.2595 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25982 to 0.25946, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2659 - acc: 0.8968 - val_loss: 0.2507 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25946 to 0.25074, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2699 - acc: 0.9011 - val_loss: 0.2467 - val_acc: 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_loss improved from 0.25074 to 0.24667, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2572 - acc: 0.9050 - val_loss: 0.2427 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.24667 to 0.24266, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2598 - acc: 0.9011 - val_loss: 0.2396 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24266 to 0.23961, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2456 - acc: 0.9089 - val_loss: 0.2297 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23961 to 0.22967, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2442 - acc: 0.9111 - val_loss: 0.2452 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22967\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2382 - acc: 0.9109 - val_loss: 0.2220 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22967 to 0.22198, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2432 - acc: 0.9111 - val_loss: 0.2190 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22198 to 0.21896, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2485 - acc: 0.9104 - val_loss: 0.2176 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21896 to 0.21757, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2296 - acc: 0.9165 - val_loss: 0.2099 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21757 to 0.20991, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2280 - acc: 0.9148 - val_loss: 0.2052 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20991 to 0.20522, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9189 - val_loss: 0.2041 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20522 to 0.20412, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2172 - acc: 0.9196 - val_loss: 0.2008 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20412 to 0.20077, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2116 - acc: 0.9172 - val_loss: 0.1926 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20077 to 0.19265, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2122 - acc: 0.9226 - val_loss: 0.1897 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19265 to 0.18974, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2018 - acc: 0.9231 - val_loss: 0.1830 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18974 to 0.18303, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9243 - val_loss: 0.1852 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.18303\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1993 - acc: 0.9262 - val_loss: 0.1764 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18303 to 0.17641, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1988 - acc: 0.9270 - val_loss: 0.1736 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17641 to 0.17358, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1909 - acc: 0.9328 - val_loss: 0.1661 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17358 to 0.16607, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1822 - acc: 0.9345 - val_loss: 0.1596 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.16607 to 0.15961, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1913 - acc: 0.9306 - val_loss: 0.1613 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.15961\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1773 - acc: 0.9352 - val_loss: 0.1635 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.15961\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1820 - acc: 0.9343 - val_loss: 0.1519 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15961 to 0.15193, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1806 - acc: 0.9355 - val_loss: 0.1558 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.15193\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1734 - acc: 0.9338 - val_loss: 0.1569 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.15193\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1726 - acc: 0.9386 - val_loss: 0.1412 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.15193 to 0.14122, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1742 - acc: 0.9406 - val_loss: 0.1421 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.14122\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1698 - acc: 0.9386 - val_loss: 0.1341 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14122 to 0.13414, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1578 - acc: 0.9462 - val_loss: 0.1547 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.13414\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1630 - acc: 0.9403 - val_loss: 0.1290 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13414 to 0.12895, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1589 - acc: 0.9425 - val_loss: 0.1260 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12895 to 0.12598, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1536 - acc: 0.9464 - val_loss: 0.1234 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12598 to 0.12337, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1477 - acc: 0.9467 - val_loss: 0.1244 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.12337\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1509 - acc: 0.9452 - val_loss: 0.1240 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.12337\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1494 - acc: 0.9472 - val_loss: 0.1211 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12337 to 0.12111, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1388 - acc: 0.9530 - val_loss: 0.1163 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12111 to 0.11633, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1423 - acc: 0.9477 - val_loss: 0.1159 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11633 to 0.11589, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1392 - acc: 0.9508 - val_loss: 0.1158 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11589 to 0.11577, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1362 - acc: 0.9520 - val_loss: 0.1124 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11577 to 0.11240, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1323 - acc: 0.9506 - val_loss: 0.1079 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11240 to 0.10790, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1319 - acc: 0.9525 - val_loss: 0.1059 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10790 to 0.10590, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1304 - acc: 0.9547 - val_loss: 0.1030 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10590 to 0.10300, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1282 - acc: 0.9525 - val_loss: 0.1001 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10300 to 0.10006, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1222 - acc: 0.9562 - val_loss: 0.0966 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10006 to 0.09655, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1211 - acc: 0.9571 - val_loss: 0.0957 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09655 to 0.09565, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1201 - acc: 0.9571 - val_loss: 0.0993 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09565\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1164 - acc: 0.9576 - val_loss: 0.0894 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09565 to 0.08940, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1166 - acc: 0.9581 - val_loss: 0.0947 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08940\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1190 - acc: 0.9576 - val_loss: 0.0876 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08940 to 0.08761, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1168 - acc: 0.9613 - val_loss: 0.0843 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08761 to 0.08425, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1202 - acc: 0.9557 - val_loss: 0.0880 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08425\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9603 - val_loss: 0.0959 - val_acc: 0.9737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08425\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9627 - val_loss: 0.0796 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08425 to 0.07963, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1102 - acc: 0.9635 - val_loss: 0.0774 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07963 to 0.07735, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1081 - acc: 0.9610 - val_loss: 0.0942 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07735\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9564 - val_loss: 0.0793 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07735\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1111 - acc: 0.9615 - val_loss: 0.0875 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07735\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0993 - acc: 0.9623 - val_loss: 0.0726 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07735 to 0.07264, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1019 - acc: 0.9647 - val_loss: 0.0746 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07264\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0906 - acc: 0.9657 - val_loss: 0.0720 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07264 to 0.07199, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0961 - acc: 0.9652 - val_loss: 0.0676 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07199 to 0.06763, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9618 - val_loss: 0.0751 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06763\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9686 - val_loss: 0.0665 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06763 to 0.06654, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0901 - acc: 0.9659 - val_loss: 0.0670 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06654\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0837 - acc: 0.9713 - val_loss: 0.0626 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06654 to 0.06263, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0906 - acc: 0.9669 - val_loss: 0.0715 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06263\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0865 - acc: 0.9686 - val_loss: 0.0618 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06263 to 0.06184, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9698 - val_loss: 0.0615 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06184 to 0.06155, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0891 - acc: 0.9676 - val_loss: 0.0547 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.06155 to 0.05470, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9657 - val_loss: 0.0547 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05470\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0846 - acc: 0.9710 - val_loss: 0.0642 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05470\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0803 - acc: 0.9691 - val_loss: 0.0564 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05470\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9722 - val_loss: 0.0524 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05470 to 0.05236, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0793 - acc: 0.9708 - val_loss: 0.0625 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05236\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0829 - acc: 0.9722 - val_loss: 0.0525 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05236\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9754 - val_loss: 0.0531 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05236\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9727 - val_loss: 0.0522 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05236 to 0.05223, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9739 - val_loss: 0.0523 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05223\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9747 - val_loss: 0.0466 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05223 to 0.04663, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0756 - acc: 0.9737 - val_loss: 0.0469 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04663\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0657 - acc: 0.9747 - val_loss: 0.0467 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04663\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9769 - val_loss: 0.0409 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04663 to 0.04092, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9749 - val_loss: 0.0500 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04092\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9783 - val_loss: 0.0442 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04092\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9747 - val_loss: 0.0422 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04092\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9757 - val_loss: 0.0429 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04092\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9769 - val_loss: 0.0416 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04092\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 15s - loss: 0.7787 - acc: 0.5274 - val_loss: 0.6694 - val_acc: 0.5180\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66938, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7372 - acc: 0.5325 - val_loss: 0.6406 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66938 to 0.64064, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6895 - acc: 0.5805 - val_loss: 0.5824 - val_acc: 0.7751\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64064 to 0.58240, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6000 - acc: 0.6764 - val_loss: 0.4934 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58240 to 0.49336, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5285 - acc: 0.7495 - val_loss: 0.4335 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49336 to 0.43347, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4641 - acc: 0.7952 - val_loss: 0.3887 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43347 to 0.38870, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4373 - acc: 0.8118 - val_loss: 0.3606 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38870 to 0.36055, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3968 - acc: 0.8376 - val_loss: 0.3465 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36055 to 0.34647, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3849 - acc: 0.8473 - val_loss: 0.3263 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34647 to 0.32626, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3660 - acc: 0.8544 - val_loss: 0.3106 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32626 to 0.31057, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3472 - acc: 0.8702 - val_loss: 0.2931 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31057 to 0.29311, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3261 - acc: 0.8719 - val_loss: 0.2855 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29311 to 0.28546, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3221 - acc: 0.8795 - val_loss: 0.2659 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28546 to 0.26589, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3151 - acc: 0.8797 - val_loss: 0.2524 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26589 to 0.25237, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3078 - acc: 0.8817 - val_loss: 0.2457 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25237 to 0.24570, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2960 - acc: 0.8814 - val_loss: 0.2507 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24570\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2849 - acc: 0.8890 - val_loss: 0.2310 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24570 to 0.23102, saving model to best.model\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2781 - acc: 0.8931 - val_loss: 0.2304 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23102 to 0.23039, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2792 - acc: 0.8987 - val_loss: 0.2270 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23039 to 0.22699, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2726 - acc: 0.8965 - val_loss: 0.2117 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22699 to 0.21170, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2703 - acc: 0.8992 - val_loss: 0.2162 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.21170\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2573 - acc: 0.9043 - val_loss: 0.2060 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21170 to 0.20598, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2571 - acc: 0.9097 - val_loss: 0.1988 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20598 to 0.19882, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2571 - acc: 0.9009 - val_loss: 0.2025 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19882\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2508 - acc: 0.9063 - val_loss: 0.1951 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19882 to 0.19507, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2349 - acc: 0.9123 - val_loss: 0.1876 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19507 to 0.18763, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2434 - acc: 0.9075 - val_loss: 0.1933 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.18763\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9160 - val_loss: 0.1794 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18763 to 0.17939, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2298 - acc: 0.9128 - val_loss: 0.1759 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17939 to 0.17587, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2228 - acc: 0.9182 - val_loss: 0.1880 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17587\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2211 - acc: 0.9228 - val_loss: 0.1684 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17587 to 0.16843, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2213 - acc: 0.9204 - val_loss: 0.1660 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16843 to 0.16596, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2148 - acc: 0.9155 - val_loss: 0.1615 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16596 to 0.16146, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2152 - acc: 0.9192 - val_loss: 0.1573 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16146 to 0.15725, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2195 - acc: 0.9143 - val_loss: 0.1627 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15725\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2047 - acc: 0.9221 - val_loss: 0.1546 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15725 to 0.15460, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2058 - acc: 0.9209 - val_loss: 0.1564 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15460\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1962 - acc: 0.9287 - val_loss: 0.1466 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15460 to 0.14658, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2016 - acc: 0.9223 - val_loss: 0.1498 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14658\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1919 - acc: 0.9272 - val_loss: 0.1387 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14658 to 0.13875, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9287 - val_loss: 0.1352 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13875 to 0.13517, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1827 - acc: 0.9347 - val_loss: 0.1369 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13517\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1809 - acc: 0.9311 - val_loss: 0.1303 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13517 to 0.13030, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1749 - acc: 0.9360 - val_loss: 0.1288 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13030 to 0.12879, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1828 - acc: 0.9352 - val_loss: 0.1369 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.12879\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1805 - acc: 0.9308 - val_loss: 0.1268 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12879 to 0.12676, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1764 - acc: 0.9360 - val_loss: 0.1214 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12676 to 0.12139, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1714 - acc: 0.9379 - val_loss: 0.1222 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.12139\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1662 - acc: 0.9369 - val_loss: 0.1170 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12139 to 0.11698, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1667 - acc: 0.9364 - val_loss: 0.1165 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11698 to 0.11648, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1633 - acc: 0.9386 - val_loss: 0.1178 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.11648\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1584 - acc: 0.9416 - val_loss: 0.1103 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11648 to 0.11025, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1531 - acc: 0.9423 - val_loss: 0.1097 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11025 to 0.10969, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1642 - acc: 0.9406 - val_loss: 0.1051 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10969 to 0.10512, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1571 - acc: 0.9396 - val_loss: 0.1073 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10512\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1466 - acc: 0.9455 - val_loss: 0.1000 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10512 to 0.10000, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1551 - acc: 0.9423 - val_loss: 0.0989 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10000 to 0.09888, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1468 - acc: 0.9433 - val_loss: 0.1015 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.09888\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1458 - acc: 0.9438 - val_loss: 0.0953 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09888 to 0.09529, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1388 - acc: 0.9484 - val_loss: 0.0927 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09529 to 0.09273, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1413 - acc: 0.9433 - val_loss: 0.0917 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09273 to 0.09172, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1419 - acc: 0.9438 - val_loss: 0.0928 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.09172\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1381 - acc: 0.9457 - val_loss: 0.0861 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09172 to 0.08613, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1289 - acc: 0.9523 - val_loss: 0.0866 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08613\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9550 - val_loss: 0.0828 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08613 to 0.08279, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9542 - val_loss: 0.0799 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08279 to 0.07986, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1232 - acc: 0.9513 - val_loss: 0.0789 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07986 to 0.07892, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1242 - acc: 0.9545 - val_loss: 0.0853 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.07892\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9498 - val_loss: 0.0763 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07892 to 0.07632, saving model to best.model\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1248 - acc: 0.9513 - val_loss: 0.0729 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07632 to 0.07289, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1251 - acc: 0.9525 - val_loss: 0.0712 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07289 to 0.07115, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1211 - acc: 0.9545 - val_loss: 0.0720 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07115\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1128 - acc: 0.9574 - val_loss: 0.0695 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.07115 to 0.06951, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1155 - acc: 0.9550 - val_loss: 0.0672 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06951 to 0.06721, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1065 - acc: 0.9618 - val_loss: 0.0681 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06721\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9618 - val_loss: 0.0608 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06721 to 0.06077, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1017 - acc: 0.9613 - val_loss: 0.0571 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06077 to 0.05713, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1039 - acc: 0.9598 - val_loss: 0.0560 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05713 to 0.05604, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9569 - val_loss: 0.0547 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05604 to 0.05471, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1023 - acc: 0.9610 - val_loss: 0.0511 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05471 to 0.05113, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1003 - acc: 0.9603 - val_loss: 0.0561 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05113\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0975 - acc: 0.9620 - val_loss: 0.0477 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05113 to 0.04770, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9620 - val_loss: 0.0464 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04770 to 0.04644, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0962 - acc: 0.9608 - val_loss: 0.0469 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04644\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0956 - acc: 0.9601 - val_loss: 0.0490 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04644\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0909 - acc: 0.9645 - val_loss: 0.0452 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04644 to 0.04522, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9662 - val_loss: 0.0417 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04522 to 0.04172, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0853 - acc: 0.9681 - val_loss: 0.0440 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04172\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9664 - val_loss: 0.0395 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04172 to 0.03954, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0871 - acc: 0.9642 - val_loss: 0.0410 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03954\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0856 - acc: 0.9647 - val_loss: 0.0408 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03954\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0808 - acc: 0.9686 - val_loss: 0.0412 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03954\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9657 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03954 to 0.03663, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0769 - acc: 0.9708 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03663 to 0.03600, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9730 - val_loss: 0.0361 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03600\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0779 - acc: 0.9705 - val_loss: 0.0351 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03600 to 0.03506, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9703 - val_loss: 0.0324 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03506 to 0.03242, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9683 - val_loss: 0.0356 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03242\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0724 - acc: 0.9696 - val_loss: 0.0322 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03242 to 0.03219, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9749 - val_loss: 0.0336 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03219\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9710 - val_loss: 0.0305 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03219 to 0.03047, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9727 - val_loss: 0.0308 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03047\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9725 - val_loss: 0.0373 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03047\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9722 - val_loss: 0.0294 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03047 to 0.02937, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9708 - val_loss: 0.0286 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02937 to 0.02859, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9715 - val_loss: 0.0264 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02859 to 0.02640, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0670 - acc: 0.9730 - val_loss: 0.0252 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02640 to 0.02524, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9786 - val_loss: 0.0277 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02524\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9732 - val_loss: 0.0251 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02524 to 0.02510, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9737 - val_loss: 0.0274 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02510\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9720 - val_loss: 0.0248 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02510 to 0.02478, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9749 - val_loss: 0.0253 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02478\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9688 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02478 to 0.02477, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9725 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02477\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9727 - val_loss: 0.0232 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02477 to 0.02318, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9737 - val_loss: 0.0248 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02318\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9800 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02318 to 0.02175, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9781 - val_loss: 0.0224 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02175\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9798 - val_loss: 0.0201 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02175 to 0.02006, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9786 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02006 to 0.01959, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9803 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01959\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9778 - val_loss: 0.0214 - val_acc: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01959\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9774 - val_loss: 0.0181 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01959 to 0.01809, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0565 - acc: 0.9800 - val_loss: 0.0190 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01809\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9798 - val_loss: 0.0173 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01809 to 0.01726, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9798 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01726\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9795 - val_loss: 0.0182 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01726\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9847 - val_loss: 0.0188 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01726\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0565 - acc: 0.9791 - val_loss: 0.0150 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01726 to 0.01499, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9791 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01499\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9849 - val_loss: 0.0158 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01499\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0489 - acc: 0.9798 - val_loss: 0.0147 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01499 to 0.01468, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0470 - acc: 0.9837 - val_loss: 0.0146 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01468 to 0.01464, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9839 - val_loss: 0.0165 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01464\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9803 - val_loss: 0.0150 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01464\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9815 - val_loss: 0.0144 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01464 to 0.01438, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9856 - val_loss: 0.0149 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01438\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9827 - val_loss: 0.0135 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01438 to 0.01350, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9827 - val_loss: 0.0149 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01350\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9832 - val_loss: 0.0141 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01350\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9842 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01350 to 0.01242, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9830 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01242\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9849 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01242\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01242\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9842 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01242\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9849 - val_loss: 0.0131 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01242\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 16s - loss: 0.8154 - acc: 0.5004 - val_loss: 0.6680 - val_acc: 0.6280\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66804, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7437 - acc: 0.5340 - val_loss: 0.6410 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66804 to 0.64101, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6876 - acc: 0.5805 - val_loss: 0.6088 - val_acc: 0.7118\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64101 to 0.60884, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6390 - acc: 0.6377 - val_loss: 0.5366 - val_acc: 0.8238\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60884 to 0.53664, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5623 - acc: 0.7185 - val_loss: 0.4568 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53664 to 0.45683, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5043 - acc: 0.7653 - val_loss: 0.3965 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45683 to 0.39654, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4608 - acc: 0.8050 - val_loss: 0.3635 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39654 to 0.36351, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4299 - acc: 0.8237 - val_loss: 0.3282 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36351 to 0.32822, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4072 - acc: 0.8412 - val_loss: 0.3051 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32822 to 0.30510, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3889 - acc: 0.8464 - val_loss: 0.2825 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30510 to 0.28250, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3571 - acc: 0.8666 - val_loss: 0.2679 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28250 to 0.26785, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3471 - acc: 0.8651 - val_loss: 0.2522 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26785 to 0.25221, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3437 - acc: 0.8627 - val_loss: 0.2397 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25221 to 0.23973, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3329 - acc: 0.8685 - val_loss: 0.2338 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.23973 to 0.23385, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3239 - acc: 0.8790 - val_loss: 0.2244 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.23385 to 0.22437, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3060 - acc: 0.8882 - val_loss: 0.2221 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22437 to 0.22210, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2917 - acc: 0.8919 - val_loss: 0.2144 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22210 to 0.21439, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2901 - acc: 0.9011 - val_loss: 0.2071 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.21439 to 0.20706, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2915 - acc: 0.8899 - val_loss: 0.2056 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20706 to 0.20563, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2788 - acc: 0.8980 - val_loss: 0.1988 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20563 to 0.19880, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2796 - acc: 0.8963 - val_loss: 0.2047 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.19880\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2747 - acc: 0.8965 - val_loss: 0.1917 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.19880 to 0.19174, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2649 - acc: 0.9053 - val_loss: 0.1863 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.19174 to 0.18627, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2697 - acc: 0.9036 - val_loss: 0.1891 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.18627\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2565 - acc: 0.9102 - val_loss: 0.1847 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18627 to 0.18469, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2565 - acc: 0.9116 - val_loss: 0.1796 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.18469 to 0.17963, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2405 - acc: 0.9138 - val_loss: 0.1742 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17963 to 0.17422, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2475 - acc: 0.9116 - val_loss: 0.1760 - val_acc: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 0.17422\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2528 - acc: 0.9055 - val_loss: 0.1714 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17422 to 0.17142, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2417 - acc: 0.9133 - val_loss: 0.1726 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17142\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2363 - acc: 0.9136 - val_loss: 0.1662 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17142 to 0.16624, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2330 - acc: 0.9153 - val_loss: 0.1641 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16624 to 0.16412, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2344 - acc: 0.9153 - val_loss: 0.1602 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16412 to 0.16022, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2263 - acc: 0.9145 - val_loss: 0.1577 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16022 to 0.15774, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2356 - acc: 0.9140 - val_loss: 0.1550 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.15774 to 0.15500, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2133 - acc: 0.9218 - val_loss: 0.1552 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15500\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2279 - acc: 0.9192 - val_loss: 0.1486 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15500 to 0.14856, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2144 - acc: 0.9209 - val_loss: 0.1469 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.14856 to 0.14687, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2218 - acc: 0.9145 - val_loss: 0.1520 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14687\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2001 - acc: 0.9274 - val_loss: 0.1419 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14687 to 0.14188, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9245 - val_loss: 0.1372 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14188 to 0.13715, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2031 - acc: 0.9206 - val_loss: 0.1360 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.13715 to 0.13603, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1966 - acc: 0.9216 - val_loss: 0.1337 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13603 to 0.13367, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1962 - acc: 0.9284 - val_loss: 0.1276 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13367 to 0.12761, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1881 - acc: 0.9279 - val_loss: 0.1246 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12761 to 0.12462, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1926 - acc: 0.9267 - val_loss: 0.1213 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12462 to 0.12127, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1792 - acc: 0.9294 - val_loss: 0.1191 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12127 to 0.11913, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1771 - acc: 0.9299 - val_loss: 0.1193 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11913\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1778 - acc: 0.9296 - val_loss: 0.1119 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11913 to 0.11186, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1720 - acc: 0.9316 - val_loss: 0.1081 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11186 to 0.10814, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1683 - acc: 0.9335 - val_loss: 0.1086 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10814\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1630 - acc: 0.9350 - val_loss: 0.1076 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10814 to 0.10765, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1647 - acc: 0.9362 - val_loss: 0.1014 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10765 to 0.10142, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1611 - acc: 0.9374 - val_loss: 0.0982 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10142 to 0.09822, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1484 - acc: 0.9421 - val_loss: 0.0986 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.09822\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1596 - acc: 0.9413 - val_loss: 0.0943 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.09822 to 0.09429, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1520 - acc: 0.9474 - val_loss: 0.0937 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09429 to 0.09369, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1485 - acc: 0.9459 - val_loss: 0.0897 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09369 to 0.08974, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1486 - acc: 0.9435 - val_loss: 0.0861 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08974 to 0.08606, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1461 - acc: 0.9472 - val_loss: 0.0832 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08606 to 0.08319, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1414 - acc: 0.9479 - val_loss: 0.0823 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08319 to 0.08232, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9479 - val_loss: 0.0857 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.08232\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1439 - acc: 0.9459 - val_loss: 0.0904 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08232\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1429 - acc: 0.9455 - val_loss: 0.0802 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08232 to 0.08021, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1346 - acc: 0.9498 - val_loss: 0.0769 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08021 to 0.07690, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1304 - acc: 0.9513 - val_loss: 0.0742 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07690 to 0.07419, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1258 - acc: 0.9523 - val_loss: 0.0711 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07419 to 0.07108, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1238 - acc: 0.9520 - val_loss: 0.0702 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07108 to 0.07021, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1278 - acc: 0.9542 - val_loss: 0.0687 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07021 to 0.06875, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1190 - acc: 0.9562 - val_loss: 0.0689 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06875\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1190 - acc: 0.9562 - val_loss: 0.0635 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06875 to 0.06348, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1186 - acc: 0.9554 - val_loss: 0.0617 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06348 to 0.06173, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1182 - acc: 0.9581 - val_loss: 0.0625 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06173\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1106 - acc: 0.9635 - val_loss: 0.0615 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06173 to 0.06152, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1139 - acc: 0.9567 - val_loss: 0.0582 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06152 to 0.05815, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1135 - acc: 0.9579 - val_loss: 0.0553 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05815 to 0.05535, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1100 - acc: 0.9576 - val_loss: 0.0541 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05535 to 0.05408, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1103 - acc: 0.9589 - val_loss: 0.0564 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05408\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1048 - acc: 0.9623 - val_loss: 0.0521 - val_acc: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00079: val_loss improved from 0.05408 to 0.05214, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1014 - acc: 0.9625 - val_loss: 0.0531 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05214\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0862 - acc: 0.9693 - val_loss: 0.0492 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05214 to 0.04922, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9671 - val_loss: 0.0470 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04922 to 0.04699, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1000 - acc: 0.9654 - val_loss: 0.0469 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04699 to 0.04686, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0947 - acc: 0.9642 - val_loss: 0.0476 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04686\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0979 - acc: 0.9657 - val_loss: 0.0422 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04686 to 0.04224, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9681 - val_loss: 0.0416 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04224 to 0.04165, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0899 - acc: 0.9683 - val_loss: 0.0434 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04165\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9635 - val_loss: 0.0422 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04165\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9679 - val_loss: 0.0415 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04165 to 0.04154, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0816 - acc: 0.9735 - val_loss: 0.0396 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04154 to 0.03956, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9696 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03956\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0835 - acc: 0.9705 - val_loss: 0.0428 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03956\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0827 - acc: 0.9679 - val_loss: 0.0392 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03956 to 0.03919, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0933 - acc: 0.9669 - val_loss: 0.0426 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03919\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0852 - acc: 0.9722 - val_loss: 0.0411 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03919\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9703 - val_loss: 0.0385 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03919 to 0.03847, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9732 - val_loss: 0.0382 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03847 to 0.03824, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9708 - val_loss: 0.0367 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03824 to 0.03669, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0413 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03669\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9744 - val_loss: 0.0363 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03669 to 0.03625, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0822 - acc: 0.9693 - val_loss: 0.0358 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03625 to 0.03576, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9739 - val_loss: 0.0320 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03576 to 0.03197, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0748 - acc: 0.9725 - val_loss: 0.0337 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03197\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9742 - val_loss: 0.0303 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03197 to 0.03034, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9778 - val_loss: 0.0323 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03034\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0707 - acc: 0.9754 - val_loss: 0.0296 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03034 to 0.02955, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9766 - val_loss: 0.0291 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02955 to 0.02910, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9747 - val_loss: 0.0297 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02910\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0675 - acc: 0.9764 - val_loss: 0.0296 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02910\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0632 - acc: 0.9778 - val_loss: 0.0261 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02910 to 0.02612, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9752 - val_loss: 0.0279 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02612\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9708 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02612\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9713 - val_loss: 0.0286 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02612\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9757 - val_loss: 0.0271 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02612\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9786 - val_loss: 0.0306 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02612\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 16s - loss: 0.8631 - acc: 0.4809 - val_loss: 0.6805 - val_acc: 0.4684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68047, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7733 - acc: 0.5262 - val_loss: 0.6486 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68047 to 0.64858, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7285 - acc: 0.5508 - val_loss: 0.6145 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64858 to 0.61445, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6690 - acc: 0.6056 - val_loss: 0.5548 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61445 to 0.55483, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6020 - acc: 0.6791 - val_loss: 0.4855 - val_acc: 0.8208\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55483 to 0.48551, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5273 - acc: 0.7473 - val_loss: 0.4250 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48551 to 0.42497, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4902 - acc: 0.7775 - val_loss: 0.3921 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42497 to 0.39214, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4466 - acc: 0.8115 - val_loss: 0.3569 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39214 to 0.35687, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4207 - acc: 0.8203 - val_loss: 0.3339 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35687 to 0.33395, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3944 - acc: 0.8371 - val_loss: 0.3157 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33395 to 0.31572, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3629 - acc: 0.8573 - val_loss: 0.3057 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31572 to 0.30568, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3540 - acc: 0.8649 - val_loss: 0.2869 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30568 to 0.28694, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3402 - acc: 0.8707 - val_loss: 0.2794 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28694 to 0.27937, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3221 - acc: 0.8795 - val_loss: 0.2686 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27937 to 0.26859, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3201 - acc: 0.8822 - val_loss: 0.2621 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26859 to 0.26210, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3044 - acc: 0.8873 - val_loss: 0.2548 - val_acc: 0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.26210 to 0.25484, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2948 - acc: 0.8914 - val_loss: 0.2577 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25484\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2840 - acc: 0.8948 - val_loss: 0.2474 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25484 to 0.24739, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2784 - acc: 0.9004 - val_loss: 0.2389 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24739 to 0.23891, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2729 - acc: 0.9063 - val_loss: 0.2365 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23891 to 0.23650, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2797 - acc: 0.9046 - val_loss: 0.2318 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23650 to 0.23178, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2648 - acc: 0.9038 - val_loss: 0.2274 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23178 to 0.22742, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2625 - acc: 0.9082 - val_loss: 0.2267 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22742 to 0.22670, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2582 - acc: 0.9082 - val_loss: 0.2222 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22670 to 0.22215, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2433 - acc: 0.9121 - val_loss: 0.2241 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.22215\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2530 - acc: 0.9109 - val_loss: 0.2134 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22215 to 0.21343, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2403 - acc: 0.9126 - val_loss: 0.2104 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21343 to 0.21035, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2397 - acc: 0.9153 - val_loss: 0.2119 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.21035\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2375 - acc: 0.9175 - val_loss: 0.2045 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21035 to 0.20452, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2366 - acc: 0.9153 - val_loss: 0.2029 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20452 to 0.20293, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2329 - acc: 0.9165 - val_loss: 0.1992 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20293 to 0.19922, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2335 - acc: 0.9177 - val_loss: 0.1936 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19922 to 0.19359, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2308 - acc: 0.9184 - val_loss: 0.1931 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19359 to 0.19313, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2291 - acc: 0.9187 - val_loss: 0.1924 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19313 to 0.19238, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2162 - acc: 0.9223 - val_loss: 0.1881 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19238 to 0.18809, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2112 - acc: 0.9274 - val_loss: 0.1809 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18809 to 0.18087, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2095 - acc: 0.9248 - val_loss: 0.1778 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18087 to 0.17780, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2130 - acc: 0.9226 - val_loss: 0.1772 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17780 to 0.17722, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2039 - acc: 0.9270 - val_loss: 0.1732 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17722 to 0.17322, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2010 - acc: 0.9326 - val_loss: 0.1690 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17322 to 0.16896, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1959 - acc: 0.9252 - val_loss: 0.1696 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16896\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1991 - acc: 0.9265 - val_loss: 0.1665 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.16896 to 0.16652, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1920 - acc: 0.9289 - val_loss: 0.1589 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16652 to 0.15888, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1882 - acc: 0.9372 - val_loss: 0.1551 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15888 to 0.15509, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1826 - acc: 0.9367 - val_loss: 0.1564 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.15509\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1865 - acc: 0.9326 - val_loss: 0.1490 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15509 to 0.14900, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1783 - acc: 0.9374 - val_loss: 0.1468 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14900 to 0.14683, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1682 - acc: 0.9369 - val_loss: 0.1425 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14683 to 0.14251, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1691 - acc: 0.9440 - val_loss: 0.1493 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.14251\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1719 - acc: 0.9369 - val_loss: 0.1374 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14251 to 0.13736, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1678 - acc: 0.9406 - val_loss: 0.1347 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13736 to 0.13469, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1635 - acc: 0.9399 - val_loss: 0.1380 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.13469\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1553 - acc: 0.9455 - val_loss: 0.1283 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13469 to 0.12830, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1546 - acc: 0.9452 - val_loss: 0.1259 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12830 to 0.12586, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1452 - acc: 0.9501 - val_loss: 0.1218 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12586 to 0.12177, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1520 - acc: 0.9440 - val_loss: 0.1210 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12177 to 0.12103, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1555 - acc: 0.9423 - val_loss: 0.1238 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12103\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1511 - acc: 0.9464 - val_loss: 0.1212 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.12103\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1566 - acc: 0.9486 - val_loss: 0.1173 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12103 to 0.11734, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1374 - acc: 0.9501 - val_loss: 0.1110 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11734 to 0.11099, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9537 - val_loss: 0.1076 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11099 to 0.10756, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1413 - acc: 0.9515 - val_loss: 0.1188 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10756\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1304 - acc: 0.9554 - val_loss: 0.1061 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10756 to 0.10610, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1401 - acc: 0.9498 - val_loss: 0.1029 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10610 to 0.10294, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1274 - acc: 0.9567 - val_loss: 0.0997 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10294 to 0.09973, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1198 - acc: 0.9606 - val_loss: 0.0977 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09973 to 0.09767, saving model to best.model\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1206 - acc: 0.9589 - val_loss: 0.0945 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09767 to 0.09451, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1218 - acc: 0.9567 - val_loss: 0.0936 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09451 to 0.09359, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1215 - acc: 0.9598 - val_loss: 0.0904 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09359 to 0.09044, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1173 - acc: 0.9608 - val_loss: 0.0893 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09044 to 0.08930, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1205 - acc: 0.9591 - val_loss: 0.0972 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08930\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1325 - acc: 0.9557 - val_loss: 0.0890 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08930 to 0.08895, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1198 - acc: 0.9564 - val_loss: 0.0855 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08895 to 0.08548, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1173 - acc: 0.9606 - val_loss: 0.0853 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08548 to 0.08528, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1081 - acc: 0.9625 - val_loss: 0.0821 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08528 to 0.08206, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9627 - val_loss: 0.0819 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08206 to 0.08195, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0987 - acc: 0.9659 - val_loss: 0.0794 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.08195 to 0.07940, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1084 - acc: 0.9635 - val_loss: 0.0762 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.07940 to 0.07619, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9642 - val_loss: 0.0763 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07619\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9618 - val_loss: 0.0723 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07619 to 0.07231, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1066 - acc: 0.9652 - val_loss: 0.0755 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07231\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1006 - acc: 0.9652 - val_loss: 0.0718 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07231 to 0.07176, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9647 - val_loss: 0.0695 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.07176 to 0.06951, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0932 - acc: 0.9703 - val_loss: 0.0727 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06951\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9654 - val_loss: 0.0670 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06951 to 0.06704, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0989 - acc: 0.9686 - val_loss: 0.0637 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06704 to 0.06366, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0967 - acc: 0.9659 - val_loss: 0.0635 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06366 to 0.06354, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0881 - acc: 0.9730 - val_loss: 0.0666 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06354\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0908 - acc: 0.9691 - val_loss: 0.0626 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06354 to 0.06263, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9688 - val_loss: 0.0579 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06263 to 0.05791, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9727 - val_loss: 0.0571 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05791 to 0.05705, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0875 - acc: 0.9703 - val_loss: 0.0546 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05705 to 0.05462, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9735 - val_loss: 0.0531 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05462 to 0.05308, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0852 - acc: 0.9703 - val_loss: 0.0533 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05308\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9715 - val_loss: 0.0496 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05308 to 0.04962, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9720 - val_loss: 0.0491 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04962 to 0.04912, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0800 - acc: 0.9718 - val_loss: 0.0466 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04912 to 0.04661, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0855 - acc: 0.9686 - val_loss: 0.0472 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04661\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0809 - acc: 0.9735 - val_loss: 0.0438 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04661 to 0.04385, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0770 - acc: 0.9737 - val_loss: 0.0424 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04385 to 0.04240, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0785 - acc: 0.9730 - val_loss: 0.0408 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.04240 to 0.04077, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9739 - val_loss: 0.0407 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04077 to 0.04075, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0835 - acc: 0.9715 - val_loss: 0.0408 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04075\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9730 - val_loss: 0.0378 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.04075 to 0.03781, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9749 - val_loss: 0.0424 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03781\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0734 - acc: 0.9737 - val_loss: 0.0372 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03781 to 0.03716, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0722 - acc: 0.9769 - val_loss: 0.0337 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03716 to 0.03370, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0783 - acc: 0.9720 - val_loss: 0.0316 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.03370 to 0.03162, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9761 - val_loss: 0.0302 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03162 to 0.03022, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9774 - val_loss: 0.0334 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03022\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9759 - val_loss: 0.0269 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.03022 to 0.02693, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9771 - val_loss: 0.0258 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02693 to 0.02583, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9769 - val_loss: 0.0238 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02583 to 0.02379, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9752 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02379\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9800 - val_loss: 0.0211 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02379 to 0.02115, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9757 - val_loss: 0.0279 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02115\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9808 - val_loss: 0.0245 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02115\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0611 - acc: 0.9759 - val_loss: 0.0212 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02115\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9783 - val_loss: 0.0228 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02115\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0575 - acc: 0.9798 - val_loss: 0.0199 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02115 to 0.01992, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9781 - val_loss: 0.0192 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01992 to 0.01918, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9800 - val_loss: 0.0183 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01918 to 0.01829, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9822 - val_loss: 0.0179 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01829 to 0.01789, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0670 - acc: 0.9786 - val_loss: 0.0172 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01789 to 0.01719, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9788 - val_loss: 0.0180 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01719\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9805 - val_loss: 0.0182 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01719\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9820 - val_loss: 0.0155 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01719 to 0.01553, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9813 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01553 to 0.01514, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9815 - val_loss: 0.0159 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01514\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9832 - val_loss: 0.0157 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01514\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9830 - val_loss: 0.0161 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01514\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9815 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01514 to 0.01387, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9830 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01387\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9827 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01387 to 0.01344, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0470 - acc: 0.9839 - val_loss: 0.0138 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01344\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9805 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01344 to 0.01310, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9849 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01310\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0488 - acc: 0.9830 - val_loss: 0.0144 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01310\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9822 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01310\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9822 - val_loss: 0.0141 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01310\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9834 - val_loss: 0.0116 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01310 to 0.01159, saving model to best.model\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9849 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01159\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9851 - val_loss: 0.0108 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01159 to 0.01083, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9856 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01083\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9822 - val_loss: 0.0158 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01083\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9815 - val_loss: 0.0127 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01083\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9837 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01083\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9878 - val_loss: 0.0110 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01083\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 16s - loss: 0.8102 - acc: 0.5194 - val_loss: 0.6676 - val_acc: 0.6933\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66757, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7419 - acc: 0.5439 - val_loss: 0.6362 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66757 to 0.63616, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6841 - acc: 0.5905 - val_loss: 0.5857 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63616 to 0.58571, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6154 - acc: 0.6701 - val_loss: 0.4998 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58571 to 0.49980, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5387 - acc: 0.7373 - val_loss: 0.4350 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49980 to 0.43500, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4855 - acc: 0.7821 - val_loss: 0.3895 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43500 to 0.38946, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4446 - acc: 0.8137 - val_loss: 0.3764 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38946 to 0.37643, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4306 - acc: 0.8230 - val_loss: 0.3423 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37643 to 0.34226, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4060 - acc: 0.8386 - val_loss: 0.3266 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34226 to 0.32662, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3855 - acc: 0.8422 - val_loss: 0.3104 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32662 to 0.31035, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3761 - acc: 0.8573 - val_loss: 0.2994 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31035 to 0.29936, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3624 - acc: 0.8578 - val_loss: 0.2846 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29936 to 0.28459, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3494 - acc: 0.8588 - val_loss: 0.2740 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28459 to 0.27401, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3352 - acc: 0.8661 - val_loss: 0.2657 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27401 to 0.26573, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3225 - acc: 0.8707 - val_loss: 0.2542 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26573 to 0.25423, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3154 - acc: 0.8775 - val_loss: 0.2508 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25423 to 0.25081, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3089 - acc: 0.8812 - val_loss: 0.2401 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25081 to 0.24013, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3027 - acc: 0.8856 - val_loss: 0.2335 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24013 to 0.23345, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2974 - acc: 0.8824 - val_loss: 0.2321 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23345 to 0.23214, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2906 - acc: 0.8885 - val_loss: 0.2231 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23214 to 0.22313, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2770 - acc: 0.8975 - val_loss: 0.2164 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22313 to 0.21640, saving model to best.model\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2726 - acc: 0.8975 - val_loss: 0.2152 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21640 to 0.21521, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2722 - acc: 0.8992 - val_loss: 0.2097 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21521 to 0.20971, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2732 - acc: 0.8985 - val_loss: 0.2048 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20971 to 0.20476, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2675 - acc: 0.9038 - val_loss: 0.2025 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20476 to 0.20247, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2596 - acc: 0.9002 - val_loss: 0.2020 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20247 to 0.20201, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2556 - acc: 0.9058 - val_loss: 0.1965 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20201 to 0.19648, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2561 - acc: 0.9046 - val_loss: 0.1960 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19648 to 0.19598, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2438 - acc: 0.9070 - val_loss: 0.1905 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19598 to 0.19048, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2539 - acc: 0.9060 - val_loss: 0.1890 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19048 to 0.18900, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9084 - val_loss: 0.1846 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.18900 to 0.18461, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2387 - acc: 0.9082 - val_loss: 0.1826 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.18461 to 0.18262, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9119 - val_loss: 0.1789 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18262 to 0.17886, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2327 - acc: 0.9067 - val_loss: 0.1754 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17886 to 0.17536, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2238 - acc: 0.9128 - val_loss: 0.1713 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17536 to 0.17129, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2265 - acc: 0.9133 - val_loss: 0.1695 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17129 to 0.16954, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2266 - acc: 0.9097 - val_loss: 0.1656 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16954 to 0.16563, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2087 - acc: 0.9158 - val_loss: 0.1621 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16563 to 0.16209, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2106 - acc: 0.9123 - val_loss: 0.1580 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16209 to 0.15804, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2041 - acc: 0.9209 - val_loss: 0.1551 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15804 to 0.15507, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9189 - val_loss: 0.1519 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15507 to 0.15185, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9175 - val_loss: 0.1497 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15185 to 0.14969, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1918 - acc: 0.9270 - val_loss: 0.1456 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14969 to 0.14556, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1948 - acc: 0.9267 - val_loss: 0.1413 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14556 to 0.14125, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1821 - acc: 0.9255 - val_loss: 0.1390 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14125 to 0.13896, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1855 - acc: 0.9265 - val_loss: 0.1358 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13896 to 0.13585, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1744 - acc: 0.9304 - val_loss: 0.1305 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13585 to 0.13049, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1847 - acc: 0.9296 - val_loss: 0.1290 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13049 to 0.12899, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1701 - acc: 0.9340 - val_loss: 0.1260 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12899 to 0.12603, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1780 - acc: 0.9326 - val_loss: 0.1243 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12603 to 0.12431, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1646 - acc: 0.9384 - val_loss: 0.1195 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12431 to 0.11948, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1723 - acc: 0.9306 - val_loss: 0.1150 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11948 to 0.11501, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1645 - acc: 0.9335 - val_loss: 0.1125 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11501 to 0.11254, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1546 - acc: 0.9384 - val_loss: 0.1132 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11254\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1577 - acc: 0.9369 - val_loss: 0.1081 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11254 to 0.10810, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1573 - acc: 0.9413 - val_loss: 0.1039 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10810 to 0.10389, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1521 - acc: 0.9418 - val_loss: 0.1019 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10389 to 0.10185, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9481 - val_loss: 0.0996 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10185 to 0.09955, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1538 - acc: 0.9418 - val_loss: 0.0990 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09955 to 0.09901, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1491 - acc: 0.9416 - val_loss: 0.0956 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09901 to 0.09556, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1365 - acc: 0.9464 - val_loss: 0.0926 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09556 to 0.09256, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1398 - acc: 0.9467 - val_loss: 0.0896 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09256 to 0.08961, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1316 - acc: 0.9508 - val_loss: 0.0895 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08961 to 0.08950, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1317 - acc: 0.9501 - val_loss: 0.0862 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08950 to 0.08621, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1342 - acc: 0.9508 - val_loss: 0.0835 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08621 to 0.08348, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1200 - acc: 0.9511 - val_loss: 0.0813 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08348 to 0.08126, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1253 - acc: 0.9489 - val_loss: 0.0782 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08126 to 0.07824, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1107 - acc: 0.9557 - val_loss: 0.0760 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07824 to 0.07602, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1196 - acc: 0.9535 - val_loss: 0.0770 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07602\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1161 - acc: 0.9511 - val_loss: 0.0726 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07602 to 0.07262, saving model to best.model\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1218 - acc: 0.9533 - val_loss: 0.0707 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07262 to 0.07072, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1067 - acc: 0.9603 - val_loss: 0.0673 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.07072 to 0.06726, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9552 - val_loss: 0.0662 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06726 to 0.06622, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9574 - val_loss: 0.0669 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06622\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1055 - acc: 0.9623 - val_loss: 0.0643 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06622 to 0.06432, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1078 - acc: 0.9550 - val_loss: 0.0612 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06432 to 0.06123, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1042 - acc: 0.9567 - val_loss: 0.0605 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06123 to 0.06050, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0956 - acc: 0.9623 - val_loss: 0.0586 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06050 to 0.05861, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1036 - acc: 0.9579 - val_loss: 0.0564 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05861 to 0.05635, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9640 - val_loss: 0.0584 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05635\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0996 - acc: 0.9637 - val_loss: 0.0555 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05635 to 0.05555, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1006 - acc: 0.9598 - val_loss: 0.0554 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05555 to 0.05536, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9645 - val_loss: 0.0548 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05536 to 0.05484, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0905 - acc: 0.9674 - val_loss: 0.0511 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05484 to 0.05110, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9683 - val_loss: 0.0515 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05110\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0895 - acc: 0.9642 - val_loss: 0.0488 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05110 to 0.04885, saving model to best.model\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9671 - val_loss: 0.0501 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04885\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0910 - acc: 0.9630 - val_loss: 0.0478 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04885 to 0.04781, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9691 - val_loss: 0.0468 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04781 to 0.04683, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9671 - val_loss: 0.0458 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04683 to 0.04581, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0859 - acc: 0.9669 - val_loss: 0.0437 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.04581 to 0.04368, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9674 - val_loss: 0.0480 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04368\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9710 - val_loss: 0.0429 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04368 to 0.04289, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0829 - acc: 0.9681 - val_loss: 0.0417 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04289 to 0.04173, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9688 - val_loss: 0.0415 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04173 to 0.04148, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0793 - acc: 0.9666 - val_loss: 0.0423 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04148\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9715 - val_loss: 0.0408 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04148 to 0.04078, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9739 - val_loss: 0.0392 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04078 to 0.03922, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0779 - acc: 0.9710 - val_loss: 0.0377 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03922 to 0.03767, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0759 - acc: 0.9718 - val_loss: 0.0357 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03767 to 0.03570, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9701 - val_loss: 0.0384 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03570\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9715 - val_loss: 0.0363 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03570\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9732 - val_loss: 0.0336 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03570 to 0.03361, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9732 - val_loss: 0.0339 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03361\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9754 - val_loss: 0.0338 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03361\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0674 - acc: 0.9739 - val_loss: 0.0326 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03361 to 0.03261, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9739 - val_loss: 0.0322 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03261 to 0.03218, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0701 - acc: 0.9759 - val_loss: 0.0331 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03218\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9735 - val_loss: 0.0308 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03218 to 0.03082, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9727 - val_loss: 0.0298 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.03082 to 0.02978, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9747 - val_loss: 0.0307 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02978\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9735 - val_loss: 0.0280 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02978 to 0.02803, saving model to best.model\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9747 - val_loss: 0.0275 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02803 to 0.02755, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9774 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02755\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9769 - val_loss: 0.0274 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02755 to 0.02735, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9757 - val_loss: 0.0277 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02735\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0586 - acc: 0.9769 - val_loss: 0.0254 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02735 to 0.02538, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9800 - val_loss: 0.0238 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02538 to 0.02384, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9778 - val_loss: 0.0258 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02384\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9793 - val_loss: 0.0239 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02384\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9805 - val_loss: 0.0237 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02384 to 0.02373, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9778 - val_loss: 0.0251 - val_acc: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02373\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9800 - val_loss: 0.0247 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02373\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0549 - acc: 0.9803 - val_loss: 0.0238 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02373\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0514 - acc: 0.9800 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02373 to 0.02130, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9832 - val_loss: 0.0227 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02130\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9778 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02130 to 0.02095, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9810 - val_loss: 0.0209 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.02095 to 0.02091, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9825 - val_loss: 0.0220 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02091\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9793 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02091 to 0.02089, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9793 - val_loss: 0.0206 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02089 to 0.02065, saving model to best.model\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0477 - acc: 0.9825 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02065\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02065\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9791 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02065\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9832 - val_loss: 0.0217 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02065\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9832 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.02065 to 0.01848, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9834 - val_loss: 0.0185 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01848\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9795 - val_loss: 0.0194 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01848\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9791 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01848 to 0.01729, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0399 - acc: 0.9842 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.01729 to 0.01722, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9832 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01722\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0500 - acc: 0.9808 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01722 to 0.01633, saving model to best.model\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0415 - acc: 0.9844 - val_loss: 0.0181 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01633\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9851 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01633\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0371 - acc: 0.9869 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01633\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9813 - val_loss: 0.0161 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01633 to 0.01611, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9834 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01611\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9864 - val_loss: 0.0169 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01611\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0435 - acc: 0.9834 - val_loss: 0.0164 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01611\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9834 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01611\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9844 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.01611 to 0.01567, saving model to best.model\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0402 - acc: 0.9859 - val_loss: 0.0164 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01567\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9878 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01567\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0324 - acc: 0.9871 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01567 to 0.01429, saving model to best.model\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9866 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.01429 to 0.01401, saving model to best.model\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0377 - acc: 0.9864 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01401\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9847 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01401\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9849 - val_loss: 0.0157 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01401\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0365 - acc: 0.9859 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01401\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9849 - val_loss: 0.0134 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.01401 to 0.01337, saving model to best.model\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9834 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01337\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9839 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01337\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9859 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01337\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9839 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01337\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9878 - val_loss: 0.0162 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01337\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 16s - loss: 0.8078 - acc: 0.5021 - val_loss: 0.6602 - val_acc: 0.5531\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66021, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7590 - acc: 0.5218 - val_loss: 0.6451 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66021 to 0.64509, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6976 - acc: 0.5664 - val_loss: 0.5941 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64509 to 0.59405, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6345 - acc: 0.6355 - val_loss: 0.5161 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59405 to 0.51607, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5524 - acc: 0.7314 - val_loss: 0.4502 - val_acc: 0.8179\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51607 to 0.45017, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5021 - acc: 0.7692 - val_loss: 0.4119 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45017 to 0.41190, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4557 - acc: 0.8072 - val_loss: 0.3786 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41190 to 0.37863, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4255 - acc: 0.8291 - val_loss: 0.3519 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37863 to 0.35192, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3942 - acc: 0.8330 - val_loss: 0.3298 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35192 to 0.32983, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3689 - acc: 0.8539 - val_loss: 0.3131 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32983 to 0.31307, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3503 - acc: 0.8627 - val_loss: 0.2952 - val_acc: 0.8754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss improved from 0.31307 to 0.29525, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3285 - acc: 0.8731 - val_loss: 0.2836 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29525 to 0.28361, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3228 - acc: 0.8780 - val_loss: 0.2750 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28361 to 0.27504, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3128 - acc: 0.8802 - val_loss: 0.2662 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27504 to 0.26619, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3074 - acc: 0.8814 - val_loss: 0.2686 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26619\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2914 - acc: 0.8897 - val_loss: 0.2617 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26619 to 0.26166, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2831 - acc: 0.8934 - val_loss: 0.2500 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26166 to 0.25000, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2764 - acc: 0.8921 - val_loss: 0.2496 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25000 to 0.24957, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2679 - acc: 0.8990 - val_loss: 0.2469 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24957 to 0.24691, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2580 - acc: 0.9038 - val_loss: 0.2406 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24691 to 0.24058, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2544 - acc: 0.9063 - val_loss: 0.2353 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24058 to 0.23526, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9087 - val_loss: 0.2316 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23526 to 0.23164, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2466 - acc: 0.9070 - val_loss: 0.2309 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23164 to 0.23087, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2442 - acc: 0.9116 - val_loss: 0.2285 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23087 to 0.22854, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2363 - acc: 0.9097 - val_loss: 0.2239 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22854 to 0.22393, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2325 - acc: 0.9119 - val_loss: 0.2249 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.22393\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2221 - acc: 0.9187 - val_loss: 0.2158 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.22393 to 0.21577, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2141 - acc: 0.9194 - val_loss: 0.2141 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21577 to 0.21409, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2198 - acc: 0.9196 - val_loss: 0.2092 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21409 to 0.20920, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2107 - acc: 0.9235 - val_loss: 0.2066 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20920 to 0.20663, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2263 - acc: 0.9123 - val_loss: 0.2091 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20663\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2140 - acc: 0.9231 - val_loss: 0.1992 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20663 to 0.19918, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2072 - acc: 0.9245 - val_loss: 0.2070 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.19918\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1969 - acc: 0.9287 - val_loss: 0.1905 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19918 to 0.19048, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1957 - acc: 0.9235 - val_loss: 0.1896 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19048 to 0.18958, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1886 - acc: 0.9326 - val_loss: 0.1815 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18958 to 0.18152, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1845 - acc: 0.9352 - val_loss: 0.1774 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18152 to 0.17738, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1847 - acc: 0.9362 - val_loss: 0.1745 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17738 to 0.17447, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1751 - acc: 0.9401 - val_loss: 0.1700 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.17447 to 0.16997, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9418 - val_loss: 0.1675 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16997 to 0.16745, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1742 - acc: 0.9382 - val_loss: 0.1635 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16745 to 0.16346, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1688 - acc: 0.9418 - val_loss: 0.1602 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.16346 to 0.16021, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1577 - acc: 0.9442 - val_loss: 0.1565 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.16021 to 0.15652, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1626 - acc: 0.9413 - val_loss: 0.1590 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.15652\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1633 - acc: 0.9435 - val_loss: 0.1488 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15652 to 0.14878, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1517 - acc: 0.9494 - val_loss: 0.1468 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14878 to 0.14680, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1566 - acc: 0.9464 - val_loss: 0.1459 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14680 to 0.14586, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1518 - acc: 0.9462 - val_loss: 0.1441 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14586 to 0.14412, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1477 - acc: 0.9511 - val_loss: 0.1412 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14412 to 0.14120, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9498 - val_loss: 0.1399 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14120 to 0.13987, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9498 - val_loss: 0.1356 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13987 to 0.13556, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1390 - acc: 0.9511 - val_loss: 0.1364 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.13556\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1342 - acc: 0.9559 - val_loss: 0.1322 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13556 to 0.13221, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1371 - acc: 0.9540 - val_loss: 0.1308 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13221 to 0.13076, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1384 - acc: 0.9523 - val_loss: 0.1269 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13076 to 0.12688, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1322 - acc: 0.9562 - val_loss: 0.1252 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12688 to 0.12524, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1343 - acc: 0.9523 - val_loss: 0.1254 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12524\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1260 - acc: 0.9569 - val_loss: 0.1216 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12524 to 0.12165, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9535 - val_loss: 0.1167 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12165 to 0.11667, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1266 - acc: 0.9552 - val_loss: 0.1192 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.11667\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1217 - acc: 0.9601 - val_loss: 0.1174 - val_acc: 0.9698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00061: val_loss did not improve from 0.11667\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1156 - acc: 0.9603 - val_loss: 0.1177 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.11667\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9603 - val_loss: 0.1150 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11667 to 0.11499, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1120 - acc: 0.9645 - val_loss: 0.1157 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.11499\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1150 - acc: 0.9623 - val_loss: 0.1114 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.11499 to 0.11143, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1161 - acc: 0.9598 - val_loss: 0.1091 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11143 to 0.10907, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1195 - acc: 0.9601 - val_loss: 0.1130 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10907\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1083 - acc: 0.9642 - val_loss: 0.1098 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10907\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1150 - acc: 0.9625 - val_loss: 0.1072 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10907 to 0.10719, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9664 - val_loss: 0.1140 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10719\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1140 - acc: 0.9623 - val_loss: 0.1031 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.10719 to 0.10309, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0982 - acc: 0.9698 - val_loss: 0.1015 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.10309 to 0.10153, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1053 - acc: 0.9635 - val_loss: 0.1019 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10153\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1041 - acc: 0.9674 - val_loss: 0.1030 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10153\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1053 - acc: 0.9647 - val_loss: 0.1012 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.10153 to 0.10116, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9686 - val_loss: 0.0989 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.10116 to 0.09889, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1082 - acc: 0.9649 - val_loss: 0.0996 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.09889\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9701 - val_loss: 0.0947 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.09889 to 0.09471, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0987 - acc: 0.9674 - val_loss: 0.0932 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.09471 to 0.09316, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1081 - acc: 0.9649 - val_loss: 0.0957 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.09316\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0973 - acc: 0.9659 - val_loss: 0.0973 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.09316\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9683 - val_loss: 0.0899 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.09316 to 0.08991, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0961 - acc: 0.9674 - val_loss: 0.0922 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08991\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9703 - val_loss: 0.0895 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.08991 to 0.08946, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9715 - val_loss: 0.0905 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08946\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9710 - val_loss: 0.0918 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.08946\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0955 - acc: 0.9701 - val_loss: 0.0856 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.08946 to 0.08563, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9725 - val_loss: 0.0867 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08563\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0904 - acc: 0.9698 - val_loss: 0.0853 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.08563 to 0.08528, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9727 - val_loss: 0.0850 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.08528 to 0.08499, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0806 - acc: 0.9732 - val_loss: 0.0829 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.08499 to 0.08288, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0789 - acc: 0.9757 - val_loss: 0.0830 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.08288\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9749 - val_loss: 0.0837 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08288\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9747 - val_loss: 0.0812 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.08288 to 0.08116, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9732 - val_loss: 0.0833 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08116\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0751 - acc: 0.9732 - val_loss: 0.0828 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08116\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0841 - acc: 0.9730 - val_loss: 0.0822 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.08116\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9749 - val_loss: 0.0817 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.08116\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9739 - val_loss: 0.0786 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.08116 to 0.07857, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0797 - acc: 0.9774 - val_loss: 0.0813 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.07857\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9769 - val_loss: 0.0816 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.07857\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0777 - acc: 0.9754 - val_loss: 0.0779 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.07857 to 0.07787, saving model to best.model\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9732 - val_loss: 0.0774 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.07787 to 0.07738, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9757 - val_loss: 0.0751 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.07738 to 0.07513, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9781 - val_loss: 0.0764 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.07513\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0712 - acc: 0.9754 - val_loss: 0.0747 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.07513 to 0.07469, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0768 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.07469\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9742 - val_loss: 0.0770 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.07469\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9783 - val_loss: 0.0723 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.07469 to 0.07234, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0736 - acc: 0.9786 - val_loss: 0.0742 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.07234\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9774 - val_loss: 0.0721 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.07234 to 0.07210, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9815 - val_loss: 0.0755 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.07210\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0723 - acc: 0.9771 - val_loss: 0.0690 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.07210 to 0.06902, saving model to best.model\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9803 - val_loss: 0.0686 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.06902 to 0.06861, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9798 - val_loss: 0.0685 - val_acc: 0.9854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00115: val_loss improved from 0.06861 to 0.06850, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9769 - val_loss: 0.0701 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.06850\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9781 - val_loss: 0.0729 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.06850\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9778 - val_loss: 0.0666 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.06850 to 0.06656, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9808 - val_loss: 0.0691 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.06656\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9788 - val_loss: 0.0696 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.06656\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0688 - acc: 0.9783 - val_loss: 0.0661 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.06656 to 0.06615, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9788 - val_loss: 0.0725 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.06615\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9798 - val_loss: 0.0668 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.06615\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9774 - val_loss: 0.0670 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.06615\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9808 - val_loss: 0.0676 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.06615\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0663 - acc: 0.9805 - val_loss: 0.0683 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.06615\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 16s - loss: 0.9366 - acc: 0.4999 - val_loss: 0.7387 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73867, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.7938 - acc: 0.5077 - val_loss: 0.6667 - val_acc: 0.7069\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73867 to 0.66672, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7457 - acc: 0.5430 - val_loss: 0.6429 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66672 to 0.64294, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.7184 - acc: 0.5554 - val_loss: 0.6163 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64294 to 0.61625, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6647 - acc: 0.6004 - val_loss: 0.5568 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61625 to 0.55683, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5912 - acc: 0.6913 - val_loss: 0.4901 - val_acc: 0.8023\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55683 to 0.49006, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.5297 - acc: 0.7375 - val_loss: 0.4411 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49006 to 0.44107, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4849 - acc: 0.7852 - val_loss: 0.4177 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44107 to 0.41768, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4435 - acc: 0.8074 - val_loss: 0.3822 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41768 to 0.38216, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.4185 - acc: 0.8269 - val_loss: 0.3598 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38216 to 0.35980, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3960 - acc: 0.8444 - val_loss: 0.3409 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.35980 to 0.34088, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3751 - acc: 0.8549 - val_loss: 0.3238 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34088 to 0.32382, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3462 - acc: 0.8632 - val_loss: 0.3125 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32382 to 0.31247, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3381 - acc: 0.8639 - val_loss: 0.3064 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.31247 to 0.30639, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3320 - acc: 0.8787 - val_loss: 0.2849 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.30639 to 0.28487, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3160 - acc: 0.8860 - val_loss: 0.2765 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.28487 to 0.27653, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3046 - acc: 0.8873 - val_loss: 0.2674 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.27653 to 0.26744, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2943 - acc: 0.8899 - val_loss: 0.2682 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26744\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2829 - acc: 0.8948 - val_loss: 0.2624 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.26744 to 0.26240, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2847 - acc: 0.8982 - val_loss: 0.2496 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26240 to 0.24964, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2691 - acc: 0.9058 - val_loss: 0.2473 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24964 to 0.24729, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2600 - acc: 0.9099 - val_loss: 0.2485 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24729\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2503 - acc: 0.9104 - val_loss: 0.2390 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24729 to 0.23901, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2409 - acc: 0.9099 - val_loss: 0.2354 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23901 to 0.23544, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2484 - acc: 0.9133 - val_loss: 0.2333 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23544 to 0.23329, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2506 - acc: 0.9131 - val_loss: 0.2352 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.23329\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2453 - acc: 0.9136 - val_loss: 0.2312 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23329 to 0.23122, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2367 - acc: 0.9153 - val_loss: 0.2230 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.23122 to 0.22296, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2275 - acc: 0.9233 - val_loss: 0.2262 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.22296\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2242 - acc: 0.9235 - val_loss: 0.2199 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22296 to 0.21988, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2301 - acc: 0.9187 - val_loss: 0.2162 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21988 to 0.21620, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2223 - acc: 0.9238 - val_loss: 0.2163 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.21620\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2212 - acc: 0.9228 - val_loss: 0.2082 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.21620 to 0.20818, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2199 - acc: 0.9250 - val_loss: 0.2101 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20818\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2120 - acc: 0.9282 - val_loss: 0.2073 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20818 to 0.20729, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2094 - acc: 0.9260 - val_loss: 0.2006 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20729 to 0.20055, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2082 - acc: 0.9260 - val_loss: 0.1940 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.20055 to 0.19405, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2104 - acc: 0.9238 - val_loss: 0.1942 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.19405\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2029 - acc: 0.9226 - val_loss: 0.1885 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19405 to 0.18847, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1956 - acc: 0.9274 - val_loss: 0.1847 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18847 to 0.18473, saving model to best.model\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1951 - acc: 0.9274 - val_loss: 0.1822 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18473 to 0.18216, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2025 - acc: 0.9291 - val_loss: 0.1900 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.18216\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1842 - acc: 0.9323 - val_loss: 0.1773 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.18216 to 0.17730, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1838 - acc: 0.9326 - val_loss: 0.1731 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17730 to 0.17313, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1812 - acc: 0.9321 - val_loss: 0.1683 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17313 to 0.16832, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1791 - acc: 0.9355 - val_loss: 0.1686 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16832\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1754 - acc: 0.9345 - val_loss: 0.1610 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16832 to 0.16104, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9372 - val_loss: 0.1655 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16104\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1707 - acc: 0.9352 - val_loss: 0.1531 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.16104 to 0.15306, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1655 - acc: 0.9374 - val_loss: 0.1510 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15306 to 0.15099, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1630 - acc: 0.9372 - val_loss: 0.1454 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.15099 to 0.14536, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1609 - acc: 0.9367 - val_loss: 0.1380 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14536 to 0.13799, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1591 - acc: 0.9391 - val_loss: 0.1393 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.13799\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1579 - acc: 0.9408 - val_loss: 0.1308 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.13799 to 0.13078, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1522 - acc: 0.9423 - val_loss: 0.1279 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13078 to 0.12794, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1431 - acc: 0.9416 - val_loss: 0.1301 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.12794\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1503 - acc: 0.9401 - val_loss: 0.1147 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12794 to 0.11474, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1446 - acc: 0.9428 - val_loss: 0.1105 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11474 to 0.11046, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1355 - acc: 0.9479 - val_loss: 0.1078 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11046 to 0.10780, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1333 - acc: 0.9481 - val_loss: 0.1050 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10780 to 0.10498, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1267 - acc: 0.9518 - val_loss: 0.0990 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10498 to 0.09901, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1272 - acc: 0.9481 - val_loss: 0.0926 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09901 to 0.09261, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1238 - acc: 0.9540 - val_loss: 0.0864 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.09261 to 0.08636, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1243 - acc: 0.9501 - val_loss: 0.0866 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08636\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1126 - acc: 0.9576 - val_loss: 0.0826 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08636 to 0.08257, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1276 - acc: 0.9484 - val_loss: 0.0884 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08257\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1143 - acc: 0.9545 - val_loss: 0.0842 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08257\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1197 - acc: 0.9530 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08257 to 0.07860, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9606 - val_loss: 0.0771 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07860 to 0.07711, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1041 - acc: 0.9613 - val_loss: 0.0723 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07711 to 0.07232, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1015 - acc: 0.9584 - val_loss: 0.0696 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07232 to 0.06962, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1040 - acc: 0.9596 - val_loss: 0.0689 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06962 to 0.06894, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9603 - val_loss: 0.0661 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06894 to 0.06609, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0972 - acc: 0.9615 - val_loss: 0.0634 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06609 to 0.06344, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0947 - acc: 0.9632 - val_loss: 0.0670 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06344\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0982 - acc: 0.9610 - val_loss: 0.0609 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06344 to 0.06089, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0953 - acc: 0.9637 - val_loss: 0.0608 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06089 to 0.06076, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9671 - val_loss: 0.0582 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06076 to 0.05824, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9635 - val_loss: 0.0572 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05824 to 0.05720, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0899 - acc: 0.9645 - val_loss: 0.0547 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05720 to 0.05467, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9681 - val_loss: 0.0517 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05467 to 0.05167, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0832 - acc: 0.9696 - val_loss: 0.0504 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05167 to 0.05045, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9698 - val_loss: 0.0512 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.05045\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0887 - acc: 0.9645 - val_loss: 0.0469 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05045 to 0.04693, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0807 - acc: 0.9691 - val_loss: 0.0484 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04693\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0825 - acc: 0.9681 - val_loss: 0.0479 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04693\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9649 - val_loss: 0.0491 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04693\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9703 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04693 to 0.04512, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9688 - val_loss: 0.0439 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04512 to 0.04388, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9688 - val_loss: 0.0431 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04388 to 0.04314, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0770 - acc: 0.9708 - val_loss: 0.0412 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.04314 to 0.04117, saving model to best.model\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0701 - acc: 0.9720 - val_loss: 0.0376 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04117 to 0.03764, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9715 - val_loss: 0.0369 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03764 to 0.03685, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9727 - val_loss: 0.0379 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03685\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0705 - acc: 0.9742 - val_loss: 0.0362 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03685 to 0.03621, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9769 - val_loss: 0.0362 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03621\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9737 - val_loss: 0.0359 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03621 to 0.03595, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9771 - val_loss: 0.0339 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03595 to 0.03386, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9791 - val_loss: 0.0341 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03386\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9771 - val_loss: 0.0352 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03386\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0613 - acc: 0.9764 - val_loss: 0.0328 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03386 to 0.03276, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9769 - val_loss: 0.0348 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03276\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9757 - val_loss: 0.0308 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03276 to 0.03084, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0613 - acc: 0.9769 - val_loss: 0.0284 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03084 to 0.02838, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9737 - val_loss: 0.0276 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02838 to 0.02760, saving model to best.model\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0609 - acc: 0.9764 - val_loss: 0.0284 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02760\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9813 - val_loss: 0.0343 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02760\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9739 - val_loss: 0.0339 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02760\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9798 - val_loss: 0.0296 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02760\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0628 - acc: 0.9769 - val_loss: 0.0262 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02760 to 0.02622, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9766 - val_loss: 0.0261 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02622 to 0.02615, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9778 - val_loss: 0.0284 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02615\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9776 - val_loss: 0.0267 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02615\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9771 - val_loss: 0.0241 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02615 to 0.02406, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9827 - val_loss: 0.0245 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02406\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9815 - val_loss: 0.0227 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02406 to 0.02270, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9776 - val_loss: 0.0240 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02270\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9810 - val_loss: 0.0217 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02270 to 0.02171, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9822 - val_loss: 0.0224 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02171\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9825 - val_loss: 0.0215 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02171 to 0.02149, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0529 - acc: 0.9815 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02149 to 0.02113, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9783 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02113 to 0.02038, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9776 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02038\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0443 - acc: 0.9820 - val_loss: 0.0224 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02038\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9817 - val_loss: 0.0196 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.02038 to 0.01958, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9813 - val_loss: 0.0198 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01958\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9822 - val_loss: 0.0203 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01958\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9827 - val_loss: 0.0190 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01958 to 0.01895, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9842 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01895 to 0.01768, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0438 - acc: 0.9834 - val_loss: 0.0174 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01768 to 0.01738, saving model to best.model\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9861 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01738\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9844 - val_loss: 0.0186 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01738\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9815 - val_loss: 0.0185 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01738\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0434 - acc: 0.9847 - val_loss: 0.0167 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01738 to 0.01674, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0424 - acc: 0.9839 - val_loss: 0.0147 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01674 to 0.01466, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9847 - val_loss: 0.0141 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01466 to 0.01412, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9847 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01412 to 0.01326, saving model to best.model\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01326\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0383 - acc: 0.9866 - val_loss: 0.0152 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01326\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9832 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01326\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9866 - val_loss: 0.0137 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01326\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9859 - val_loss: 0.0151 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01326\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 18s - loss: 0.8062 - acc: 0.5155 - val_loss: 0.6608 - val_acc: 0.7410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66080, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7500 - acc: 0.5408 - val_loss: 0.6278 - val_acc: 0.7692\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66080 to 0.62778, saving model to best.model\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.7073 - acc: 0.5632 - val_loss: 0.5788 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62778 to 0.57879, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6327 - acc: 0.6496 - val_loss: 0.5115 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57879 to 0.51149, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5604 - acc: 0.7197 - val_loss: 0.4601 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51149 to 0.46009, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.4989 - acc: 0.7672 - val_loss: 0.3980 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46009 to 0.39795, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4496 - acc: 0.8028 - val_loss: 0.3603 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39795 to 0.36026, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4101 - acc: 0.8281 - val_loss: 0.3329 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36026 to 0.33288, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3866 - acc: 0.8420 - val_loss: 0.3121 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33288 to 0.31213, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3764 - acc: 0.8515 - val_loss: 0.2958 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31213 to 0.29575, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3535 - acc: 0.8580 - val_loss: 0.2797 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29575 to 0.27973, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3386 - acc: 0.8714 - val_loss: 0.2674 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27973 to 0.26739, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3317 - acc: 0.8722 - val_loss: 0.2669 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.26739 to 0.26690, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3261 - acc: 0.8766 - val_loss: 0.2501 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26690 to 0.25010, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3078 - acc: 0.8858 - val_loss: 0.2423 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25010 to 0.24230, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3024 - acc: 0.8880 - val_loss: 0.2396 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24230 to 0.23959, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3024 - acc: 0.8860 - val_loss: 0.2309 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23959 to 0.23091, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2883 - acc: 0.8929 - val_loss: 0.2255 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23091 to 0.22553, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2792 - acc: 0.8936 - val_loss: 0.2212 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22553 to 0.22119, saving model to best.model\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2705 - acc: 0.8992 - val_loss: 0.2175 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22119 to 0.21748, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2726 - acc: 0.8960 - val_loss: 0.2119 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.21748 to 0.21188, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2663 - acc: 0.9053 - val_loss: 0.2081 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21188 to 0.20808, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2625 - acc: 0.9007 - val_loss: 0.2040 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20808 to 0.20396, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2546 - acc: 0.9087 - val_loss: 0.2013 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20396 to 0.20128, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2525 - acc: 0.9058 - val_loss: 0.1989 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20128 to 0.19892, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2465 - acc: 0.9133 - val_loss: 0.1944 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19892 to 0.19442, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2416 - acc: 0.9104 - val_loss: 0.1887 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19442 to 0.18875, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2386 - acc: 0.9119 - val_loss: 0.1856 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18875 to 0.18561, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2330 - acc: 0.9155 - val_loss: 0.1815 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.18561 to 0.18154, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2312 - acc: 0.9148 - val_loss: 0.1782 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18154 to 0.17824, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9150 - val_loss: 0.1772 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17824 to 0.17722, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2272 - acc: 0.9145 - val_loss: 0.1716 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17722 to 0.17160, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2163 - acc: 0.9204 - val_loss: 0.1677 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17160 to 0.16771, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2169 - acc: 0.9194 - val_loss: 0.1631 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16771 to 0.16315, saving model to best.model\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2190 - acc: 0.9167 - val_loss: 0.1596 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16315 to 0.15956, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2134 - acc: 0.9194 - val_loss: 0.1568 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15956 to 0.15685, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9243 - val_loss: 0.1548 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15685 to 0.15480, saving model to best.model\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2042 - acc: 0.9216 - val_loss: 0.1493 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15480 to 0.14931, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2082 - acc: 0.9226 - val_loss: 0.1460 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14931 to 0.14595, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1905 - acc: 0.9279 - val_loss: 0.1437 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14595 to 0.14368, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1916 - acc: 0.9277 - val_loss: 0.1409 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14368 to 0.14092, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1813 - acc: 0.9313 - val_loss: 0.1361 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14092 to 0.13609, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1892 - acc: 0.9282 - val_loss: 0.1342 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13609 to 0.13423, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1896 - acc: 0.9248 - val_loss: 0.1286 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13423 to 0.12860, saving model to best.model\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1787 - acc: 0.9308 - val_loss: 0.1248 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12860 to 0.12479, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1713 - acc: 0.9340 - val_loss: 0.1207 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12479 to 0.12074, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1697 - acc: 0.9357 - val_loss: 0.1207 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12074 to 0.12069, saving model to best.model\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1756 - acc: 0.9355 - val_loss: 0.1172 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.12069 to 0.11715, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1649 - acc: 0.9396 - val_loss: 0.1113 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11715 to 0.11128, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1663 - acc: 0.9382 - val_loss: 0.1111 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11128 to 0.11112, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1662 - acc: 0.9374 - val_loss: 0.1088 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11112 to 0.10878, saving model to best.model\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1503 - acc: 0.9416 - val_loss: 0.1058 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10878 to 0.10579, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1598 - acc: 0.9362 - val_loss: 0.1033 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10579 to 0.10327, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1506 - acc: 0.9421 - val_loss: 0.1005 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10327 to 0.10048, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1491 - acc: 0.9408 - val_loss: 0.0976 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10048 to 0.09763, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1428 - acc: 0.9452 - val_loss: 0.0917 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.09763 to 0.09171, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1374 - acc: 0.9472 - val_loss: 0.0896 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09171 to 0.08965, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1405 - acc: 0.9467 - val_loss: 0.0869 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08965 to 0.08691, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1335 - acc: 0.9501 - val_loss: 0.0853 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08691 to 0.08534, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1362 - acc: 0.9477 - val_loss: 0.0833 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08534 to 0.08330, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1338 - acc: 0.9474 - val_loss: 0.0808 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08330 to 0.08083, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9479 - val_loss: 0.0805 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08083 to 0.08045, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1227 - acc: 0.9523 - val_loss: 0.0788 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08045 to 0.07882, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1267 - acc: 0.9518 - val_loss: 0.0766 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07882 to 0.07662, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1290 - acc: 0.9486 - val_loss: 0.0752 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07662 to 0.07519, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1255 - acc: 0.9535 - val_loss: 0.0737 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07519 to 0.07367, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1109 - acc: 0.9610 - val_loss: 0.0701 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07367 to 0.07015, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1186 - acc: 0.9530 - val_loss: 0.0695 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07015 to 0.06952, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1154 - acc: 0.9552 - val_loss: 0.0681 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06952 to 0.06807, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1231 - acc: 0.9486 - val_loss: 0.0659 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06807 to 0.06586, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9547 - val_loss: 0.0660 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06586\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1110 - acc: 0.9584 - val_loss: 0.0624 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06586 to 0.06240, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1163 - acc: 0.9596 - val_loss: 0.0639 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06240\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1037 - acc: 0.9640 - val_loss: 0.0615 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06240 to 0.06146, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1057 - acc: 0.9603 - val_loss: 0.0593 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06146 to 0.05930, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0966 - acc: 0.9642 - val_loss: 0.0568 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05930 to 0.05684, saving model to best.model\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1080 - acc: 0.9564 - val_loss: 0.0549 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05684 to 0.05489, saving model to best.model\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0987 - acc: 0.9615 - val_loss: 0.0565 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05489\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0976 - acc: 0.9610 - val_loss: 0.0518 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05489 to 0.05185, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9581 - val_loss: 0.0502 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05185 to 0.05022, saving model to best.model\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9613 - val_loss: 0.0510 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05022\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0967 - acc: 0.9640 - val_loss: 0.0495 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05022 to 0.04950, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0936 - acc: 0.9618 - val_loss: 0.0486 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04950 to 0.04856, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0897 - acc: 0.9652 - val_loss: 0.0461 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04856 to 0.04605, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0925 - acc: 0.9625 - val_loss: 0.0448 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04605 to 0.04480, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0951 - acc: 0.9669 - val_loss: 0.0454 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04480\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9647 - val_loss: 0.0443 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04480 to 0.04427, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9606 - val_loss: 0.0440 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04427 to 0.04402, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0846 - acc: 0.9679 - val_loss: 0.0440 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04402 to 0.04397, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0848 - acc: 0.9693 - val_loss: 0.0417 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04397 to 0.04174, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0904 - acc: 0.9652 - val_loss: 0.0392 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.04174 to 0.03916, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9681 - val_loss: 0.0389 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03916 to 0.03888, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0807 - acc: 0.9681 - val_loss: 0.0414 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03888\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9688 - val_loss: 0.0373 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03888 to 0.03731, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9701 - val_loss: 0.0358 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03731 to 0.03584, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9698 - val_loss: 0.0353 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03584 to 0.03526, saving model to best.model\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9683 - val_loss: 0.0336 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03526 to 0.03355, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9725 - val_loss: 0.0328 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03355 to 0.03277, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9725 - val_loss: 0.0320 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03277 to 0.03202, saving model to best.model\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0759 - acc: 0.9720 - val_loss: 0.0318 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03202 to 0.03181, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9735 - val_loss: 0.0311 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03181 to 0.03108, saving model to best.model\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0693 - acc: 0.9727 - val_loss: 0.0321 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03108\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9720 - val_loss: 0.0314 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03108\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9735 - val_loss: 0.0334 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03108\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0712 - acc: 0.9727 - val_loss: 0.0314 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03108\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9737 - val_loss: 0.0295 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03108 to 0.02949, saving model to best.model\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9735 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.02949 to 0.02864, saving model to best.model\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9722 - val_loss: 0.0273 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02864 to 0.02730, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9759 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02730 to 0.02635, saving model to best.model\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9766 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02635 to 0.02493, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9693 - val_loss: 0.0290 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02493\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9769 - val_loss: 0.0258 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02493\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9752 - val_loss: 0.0254 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02493\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9771 - val_loss: 0.0236 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02493 to 0.02363, saving model to best.model\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0628 - acc: 0.9776 - val_loss: 0.0234 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02363 to 0.02335, saving model to best.model\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0660 - acc: 0.9764 - val_loss: 0.0233 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02335 to 0.02329, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9747 - val_loss: 0.0217 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02329 to 0.02165, saving model to best.model\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9781 - val_loss: 0.0210 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02165 to 0.02105, saving model to best.model\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9795 - val_loss: 0.0228 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02105\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0583 - acc: 0.9771 - val_loss: 0.0249 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02105\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9783 - val_loss: 0.0200 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02105 to 0.01997, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9771 - val_loss: 0.0198 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01997 to 0.01977, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9800 - val_loss: 0.0197 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01977 to 0.01970, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9815 - val_loss: 0.0186 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01970 to 0.01860, saving model to best.model\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9808 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01860 to 0.01816, saving model to best.model\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9827 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01816 to 0.01716, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9793 - val_loss: 0.0170 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01716 to 0.01697, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9788 - val_loss: 0.0176 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01697\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0536 - acc: 0.9808 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01697 to 0.01649, saving model to best.model\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9788 - val_loss: 0.0169 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01649\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0652 - acc: 0.9769 - val_loss: 0.0199 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01649\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9808 - val_loss: 0.0163 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01649 to 0.01627, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9798 - val_loss: 0.0169 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01627\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9808 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01627 to 0.01598, saving model to best.model\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0479 - acc: 0.9839 - val_loss: 0.0151 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01598 to 0.01510, saving model to best.model\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0536 - acc: 0.9827 - val_loss: 0.0150 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.01510 to 0.01496, saving model to best.model\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9827 - val_loss: 0.0150 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01496\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9795 - val_loss: 0.0148 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01496 to 0.01477, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0500 - acc: 0.9805 - val_loss: 0.0171 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01477\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9793 - val_loss: 0.0188 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01477\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9813 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01477\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9849 - val_loss: 0.0157 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01477\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9813 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01477 to 0.01432, saving model to best.model\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0479 - acc: 0.9815 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.01432 to 0.01426, saving model to best.model\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9825 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.01426 to 0.01357, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9847 - val_loss: 0.0131 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01357 to 0.01313, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9847 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.01313 to 0.01284, saving model to best.model\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0493 - acc: 0.9827 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01284\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9871 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01284\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9800 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01284\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9820 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01284\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0386 - acc: 0.9861 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01284 to 0.01175, saving model to best.model\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9844 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01175\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0557 - acc: 0.9803 - val_loss: 0.0132 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01175\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0491 - acc: 0.9817 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01175\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9810 - val_loss: 0.0128 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01175\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9813 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01175\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      " - 17s - loss: 0.8326 - acc: 0.5091 - val_loss: 0.6906 - val_acc: 0.4771\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69056, saving model to best.model\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.7826 - acc: 0.5177 - val_loss: 0.6823 - val_acc: 0.5229\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69056 to 0.68228, saving model to best.model\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.7204 - acc: 0.5644 - val_loss: 0.6144 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68228 to 0.61437, saving model to best.model\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6785 - acc: 0.6026 - val_loss: 0.5632 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61437 to 0.56320, saving model to best.model\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6191 - acc: 0.6664 - val_loss: 0.4983 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56320 to 0.49829, saving model to best.model\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5395 - acc: 0.7331 - val_loss: 0.4305 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49829 to 0.43049, saving model to best.model\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4873 - acc: 0.7775 - val_loss: 0.3860 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43049 to 0.38600, saving model to best.model\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.4492 - acc: 0.8069 - val_loss: 0.3418 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38600 to 0.34176, saving model to best.model\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4216 - acc: 0.8237 - val_loss: 0.3153 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34176 to 0.31527, saving model to best.model\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.4057 - acc: 0.8337 - val_loss: 0.2966 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31527 to 0.29663, saving model to best.model\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3830 - acc: 0.8434 - val_loss: 0.2939 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29663 to 0.29387, saving model to best.model\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3545 - acc: 0.8559 - val_loss: 0.2640 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29387 to 0.26400, saving model to best.model\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3411 - acc: 0.8671 - val_loss: 0.2536 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.26400 to 0.25360, saving model to best.model\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3327 - acc: 0.8690 - val_loss: 0.2438 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25360 to 0.24380, saving model to best.model\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3215 - acc: 0.8712 - val_loss: 0.2389 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24380 to 0.23886, saving model to best.model\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3104 - acc: 0.8878 - val_loss: 0.2346 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.23886 to 0.23461, saving model to best.model\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3010 - acc: 0.8887 - val_loss: 0.2253 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23461 to 0.22526, saving model to best.model\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2998 - acc: 0.8907 - val_loss: 0.2198 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22526 to 0.21976, saving model to best.model\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2928 - acc: 0.8887 - val_loss: 0.2234 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.21976\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2859 - acc: 0.8936 - val_loss: 0.2115 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21976 to 0.21146, saving model to best.model\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2835 - acc: 0.8941 - val_loss: 0.2082 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.21146 to 0.20821, saving model to best.model\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2751 - acc: 0.9016 - val_loss: 0.2048 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.20821 to 0.20479, saving model to best.model\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2721 - acc: 0.9011 - val_loss: 0.2016 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20479 to 0.20158, saving model to best.model\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2627 - acc: 0.9058 - val_loss: 0.1983 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20158 to 0.19826, saving model to best.model\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2591 - acc: 0.9104 - val_loss: 0.1952 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19826 to 0.19520, saving model to best.model\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2501 - acc: 0.9102 - val_loss: 0.1915 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19520 to 0.19149, saving model to best.model\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2535 - acc: 0.9084 - val_loss: 0.1881 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19149 to 0.18807, saving model to best.model\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2434 - acc: 0.9116 - val_loss: 0.1849 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18807 to 0.18487, saving model to best.model\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2448 - acc: 0.9097 - val_loss: 0.1820 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.18487 to 0.18201, saving model to best.model\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9160 - val_loss: 0.1791 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18201 to 0.17906, saving model to best.model\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2367 - acc: 0.9172 - val_loss: 0.1766 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.17906 to 0.17662, saving model to best.model\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2351 - acc: 0.9170 - val_loss: 0.1742 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17662 to 0.17424, saving model to best.model\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2320 - acc: 0.9153 - val_loss: 0.1714 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17424 to 0.17137, saving model to best.model\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2192 - acc: 0.9209 - val_loss: 0.1715 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.17137\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2196 - acc: 0.9211 - val_loss: 0.1661 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17137 to 0.16615, saving model to best.model\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9240 - val_loss: 0.1635 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16615 to 0.16349, saving model to best.model\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2151 - acc: 0.9270 - val_loss: 0.1686 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16349\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2184 - acc: 0.9218 - val_loss: 0.1583 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16349 to 0.15834, saving model to best.model\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2100 - acc: 0.9243 - val_loss: 0.1572 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15834 to 0.15725, saving model to best.model\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2071 - acc: 0.9262 - val_loss: 0.1530 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15725 to 0.15301, saving model to best.model\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1994 - acc: 0.9294 - val_loss: 0.1519 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15301 to 0.15191, saving model to best.model\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1997 - acc: 0.9316 - val_loss: 0.1479 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15191 to 0.14792, saving model to best.model\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1903 - acc: 0.9308 - val_loss: 0.1451 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14792 to 0.14511, saving model to best.model\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1910 - acc: 0.9352 - val_loss: 0.1453 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.14511\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1811 - acc: 0.9350 - val_loss: 0.1393 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14511 to 0.13932, saving model to best.model\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1845 - acc: 0.9326 - val_loss: 0.1376 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13932 to 0.13765, saving model to best.model\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1880 - acc: 0.9347 - val_loss: 0.1351 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13765 to 0.13511, saving model to best.model\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1826 - acc: 0.9367 - val_loss: 0.1346 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13511 to 0.13457, saving model to best.model\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1771 - acc: 0.9382 - val_loss: 0.1296 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13457 to 0.12959, saving model to best.model\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1752 - acc: 0.9345 - val_loss: 0.1266 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12959 to 0.12659, saving model to best.model\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1717 - acc: 0.9389 - val_loss: 0.1236 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.12659 to 0.12355, saving model to best.model\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1601 - acc: 0.9430 - val_loss: 0.1207 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12355 to 0.12068, saving model to best.model\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1598 - acc: 0.9459 - val_loss: 0.1157 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12068 to 0.11571, saving model to best.model\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1601 - acc: 0.9413 - val_loss: 0.1123 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.11571 to 0.11225, saving model to best.model\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1637 - acc: 0.9430 - val_loss: 0.1108 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11225 to 0.11081, saving model to best.model\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1530 - acc: 0.9438 - val_loss: 0.1068 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.11081 to 0.10684, saving model to best.model\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1586 - acc: 0.9438 - val_loss: 0.1023 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10684 to 0.10234, saving model to best.model\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1496 - acc: 0.9467 - val_loss: 0.1005 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10234 to 0.10045, saving model to best.model\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1497 - acc: 0.9459 - val_loss: 0.0962 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10045 to 0.09621, saving model to best.model\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1427 - acc: 0.9477 - val_loss: 0.0910 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09621 to 0.09096, saving model to best.model\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9525 - val_loss: 0.0868 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09096 to 0.08681, saving model to best.model\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1397 - acc: 0.9525 - val_loss: 0.0857 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08681 to 0.08567, saving model to best.model\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1311 - acc: 0.9518 - val_loss: 0.0806 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08567 to 0.08058, saving model to best.model\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1225 - acc: 0.9545 - val_loss: 0.0784 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08058 to 0.07839, saving model to best.model\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1271 - acc: 0.9552 - val_loss: 0.0762 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07839 to 0.07623, saving model to best.model\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1276 - acc: 0.9518 - val_loss: 0.0719 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07623 to 0.07186, saving model to best.model\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1224 - acc: 0.9571 - val_loss: 0.0708 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07186 to 0.07080, saving model to best.model\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1239 - acc: 0.9550 - val_loss: 0.0679 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07080 to 0.06790, saving model to best.model\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9610 - val_loss: 0.0652 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06790 to 0.06522, saving model to best.model\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1179 - acc: 0.9586 - val_loss: 0.0640 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06522 to 0.06402, saving model to best.model\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9584 - val_loss: 0.0616 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06402 to 0.06156, saving model to best.model\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1095 - acc: 0.9608 - val_loss: 0.0603 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06156 to 0.06028, saving model to best.model\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1107 - acc: 0.9601 - val_loss: 0.0594 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06028 to 0.05939, saving model to best.model\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1053 - acc: 0.9613 - val_loss: 0.0576 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05939 to 0.05762, saving model to best.model\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9623 - val_loss: 0.0549 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05762 to 0.05490, saving model to best.model\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1077 - acc: 0.9610 - val_loss: 0.0593 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05490\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1071 - acc: 0.9608 - val_loss: 0.0557 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05490\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0986 - acc: 0.9640 - val_loss: 0.0531 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05490 to 0.05312, saving model to best.model\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9635 - val_loss: 0.0495 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05312 to 0.04946, saving model to best.model\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0964 - acc: 0.9662 - val_loss: 0.0509 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04946\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0934 - acc: 0.9657 - val_loss: 0.0458 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04946 to 0.04580, saving model to best.model\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9662 - val_loss: 0.0431 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04580 to 0.04311, saving model to best.model\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0899 - acc: 0.9649 - val_loss: 0.0417 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04311 to 0.04170, saving model to best.model\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0906 - acc: 0.9691 - val_loss: 0.0411 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04170 to 0.04109, saving model to best.model\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9720 - val_loss: 0.0400 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04109 to 0.03999, saving model to best.model\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9683 - val_loss: 0.0417 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03999\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9666 - val_loss: 0.0384 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.03999 to 0.03845, saving model to best.model\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9691 - val_loss: 0.0370 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03845 to 0.03703, saving model to best.model\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0781 - acc: 0.9720 - val_loss: 0.0355 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03703 to 0.03545, saving model to best.model\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0850 - acc: 0.9691 - val_loss: 0.0348 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03545 to 0.03483, saving model to best.model\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0759 - acc: 0.9725 - val_loss: 0.0334 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03483 to 0.03336, saving model to best.model\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9657 - val_loss: 0.0317 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03336 to 0.03172, saving model to best.model\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9686 - val_loss: 0.0313 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03172 to 0.03130, saving model to best.model\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9764 - val_loss: 0.0311 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03130 to 0.03109, saving model to best.model\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0823 - acc: 0.9708 - val_loss: 0.0300 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03109 to 0.03002, saving model to best.model\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0809 - acc: 0.9713 - val_loss: 0.0303 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03002\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9795 - val_loss: 0.0297 - val_acc: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_loss improved from 0.03002 to 0.02975, saving model to best.model\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0722 - acc: 0.9737 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02975 to 0.02909, saving model to best.model\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0846 - acc: 0.9681 - val_loss: 0.0321 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02909\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9722 - val_loss: 0.0287 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02909 to 0.02873, saving model to best.model\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0718 - acc: 0.9727 - val_loss: 0.0255 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.02873 to 0.02546, saving model to best.model\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9708 - val_loss: 0.0279 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02546\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9720 - val_loss: 0.0245 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02546 to 0.02452, saving model to best.model\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0688 - acc: 0.9742 - val_loss: 0.0243 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02452 to 0.02432, saving model to best.model\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9742 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02432\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9744 - val_loss: 0.0247 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02432\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9757 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02432\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9761 - val_loss: 0.0223 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02432 to 0.02231, saving model to best.model\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0607 - acc: 0.9774 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02231\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0571 - acc: 0.9800 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02231 to 0.02078, saving model to best.model\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9783 - val_loss: 0.0204 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02078 to 0.02045, saving model to best.model\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9769 - val_loss: 0.0214 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02045\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9788 - val_loss: 0.0215 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02045\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0573 - acc: 0.9810 - val_loss: 0.0223 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02045\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9815 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02045\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9795 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02045 to 0.01965, saving model to best.model\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0530 - acc: 0.9813 - val_loss: 0.0205 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01965\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9757 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01965\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0634 - acc: 0.9757 - val_loss: 0.0184 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.01965 to 0.01841, saving model to best.model\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9834 - val_loss: 0.0184 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.01841 to 0.01836, saving model to best.model\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9800 - val_loss: 0.0179 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01836 to 0.01795, saving model to best.model\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0458 - acc: 0.9832 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01795 to 0.01686, saving model to best.model\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9795 - val_loss: 0.0166 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01686 to 0.01663, saving model to best.model\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0551 - acc: 0.9783 - val_loss: 0.0177 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01663\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9788 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01663\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9832 - val_loss: 0.0166 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01663 to 0.01656, saving model to best.model\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9803 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.01656 to 0.01563, saving model to best.model\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9815 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01563 to 0.01539, saving model to best.model\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9825 - val_loss: 0.0156 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01539\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9808 - val_loss: 0.0166 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01539\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9800 - val_loss: 0.0178 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01539\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9810 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01539 to 0.01496, saving model to best.model\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9822 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01496 to 0.01283, saving model to best.model\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9842 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01283\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9815 - val_loss: 0.0139 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01283\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9827 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01283\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9822 - val_loss: 0.0129 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01283\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9825 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01283 to 0.01253, saving model to best.model\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9817 - val_loss: 0.0125 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01253 to 0.01246, saving model to best.model\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0413 - acc: 0.9839 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.01246 to 0.01215, saving model to best.model\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9864 - val_loss: 0.0123 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01215\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9849 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01215\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01215\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0137 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01215\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9844 - val_loss: 0.0117 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.01215 to 0.01171, saving model to best.model\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9834 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01171 to 0.01149, saving model to best.model\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0393 - acc: 0.9871 - val_loss: 0.0152 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01149\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9834 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01149\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9861 - val_loss: 0.0112 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.01149 to 0.01119, saving model to best.model\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9864 - val_loss: 0.0105 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.01119 to 0.01053, saving model to best.model\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0377 - acc: 0.9851 - val_loss: 0.0108 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01053\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9854 - val_loss: 0.0101 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01053 to 0.01006, saving model to best.model\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9847 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01006 to 0.00994, saving model to best.model\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9861 - val_loss: 0.0105 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00994\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9854 - val_loss: 0.0106 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00994\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0381 - acc: 0.9856 - val_loss: 0.0092 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00994 to 0.00925, saving model to best.model\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9873 - val_loss: 0.0086 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00925 to 0.00858, saving model to best.model\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9861 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00858\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0381 - acc: 0.9849 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00858\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9847 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00858\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9871 - val_loss: 0.0108 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00858\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0346 - acc: 0.9878 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00858\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(50):\n",
    "    y_pred=train_nn_simple(train,X_val,y_val)\n",
    "    result.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new=np.array(result)\n",
    "result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new1=result_new.sum(axis=0)\n",
    "result_new1\n",
    "re=result_new1.tolist()\n",
    "re\n",
    "y_pred=[]\n",
    "for each in re:\n",
    "    if each>=25:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1068    4]\n",
      " [  13  946]]\n",
      "99.16297390448055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1072\n",
      "           1       1.00      0.99      0.99       959\n",
      "\n",
      "    accuracy                           0.99      2031\n",
      "   macro avg       0.99      0.99      0.99      2031\n",
      "weighted avg       0.99      0.99      0.99      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(y_val, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_val, y_pred) * 100) \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 50,  0, ...,  0, 50, 50])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
